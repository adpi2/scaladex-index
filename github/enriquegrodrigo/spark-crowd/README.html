<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a id="user-content-spark-crowd" class="anchor" href="https://github.com/enriquegrodrigo/spark-crowd#spark-crowd" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>spark-crowd</h1> 
  <p>A package for dealing with crowdsourced big data.</p> 
  <p>Crowdsourced data introduces new problems that need to be addressed by Machine learning algorithms. This illustration exemplifies the main problems of using this kind of data.</p> 
  <p><a href="https://raw.githubusercontent.com/enriquegrodrigo/spark-crowd/master/img/illustration.png" target="_blank"><img src="https://raw.githubusercontent.com/enriquegrodrigo/spark-crowd/master/img/illustration.png" alt="Crowdsourcing illustration" style="max-width:100%;"></a></p> 
  <h2><a id="user-content-installation" class="anchor" href="https://github.com/enriquegrodrigo/spark-crowd#installation" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Installation</h2> 
  <p>The package uses <a href="http://www.scala-sbt.org" target="_blank">sbt</a> for building the project, so we recommend installing this tool if you do not yet have it installed.</p> 
  <p>The simplest way to use the package is adding the next dependency directly into the <code>build.sbt</code> file of your project:</p> 
  <div class="highlight highlight-source-scala">
   <pre>libraryDependencies <span class="pl-k">+</span><span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>com.enriquegrodrigo<span class="pl-pds">"</span></span> <span class="pl-k">%%</span> <span class="pl-s"><span class="pl-pds">"</span>spark-crowd<span class="pl-pds">"</span></span> <span class="pl-k">%</span> <span class="pl-s"><span class="pl-pds">"</span>0.1<span class="pl-pds">"</span></span></pre>
  </div> 
  <p>If this is not a possibility, you can compile the project and create a <code>.jar</code> file or you can publish the project to a local repository, as explained below.</p> 
  <h3><a id="user-content-creating-a-jar-file-and-adding-it-to-a-new-project" class="anchor" href="https://github.com/enriquegrodrigo/spark-crowd#creating-a-jar-file-and-adding-it-to-a-new-project" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Creating a <code>.jar</code> file and adding it to a new project</h3> 
  <p>In the <code>spark-crowd</code> folder one should execute the command</p> 
  <pre><code>&gt; sbt package 
</code></pre> 
  <p>to create a <code>.jar</code> file which will be in <code>target/scala-2.11/spark-crowd_2.11-0.1.jar</code> normally.</p> 
  <p>This <code>.jar</code> can be added to new projects using this library. In <code>sbt</code> one can add <code>.jar</code> files to the <code>lib</code> folder.</p> 
  <h3><a id="user-content-publishing-to-a-local-repository" class="anchor" href="https://github.com/enriquegrodrigo/spark-crowd#publishing-to-a-local-repository" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Publishing to a local repository</h3> 
  <p>In the <code>spark-crowd</code> folder one should execute the command</p> 
  <pre><code>&gt; sbt publish-local 
</code></pre> 
  <p>to publish the library to a local Ivy repository. One then can use the library adding the following line to the <code>build.sbt</code> file of a new project:</p> 
  <div class="highlight highlight-source-scala">
   <pre>    libraryDependencies <span class="pl-k">+</span><span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>com.enriquegrodrigo<span class="pl-pds">"</span></span> <span class="pl-k">%%</span> <span class="pl-s"><span class="pl-pds">"</span>spark-crowd<span class="pl-pds">"</span></span> <span class="pl-k">%</span> <span class="pl-s"><span class="pl-pds">"</span>0.1<span class="pl-pds">"</span></span></pre>
  </div> 
  <h2><a id="user-content-usage" class="anchor" href="https://github.com/enriquegrodrigo/spark-crowd#usage" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Usage</h2> 
  <h3><a id="user-content-types" class="anchor" href="https://github.com/enriquegrodrigo/spark-crowd#types" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Types</h3> 
  <p>This package makes extensive use of Spark <em>DataFrame</em> an <em>Dataset</em> APIs. The last uses typed rows which is beneficial for debugging purposes, among other things. As the annotations datasets normally have a fixed structure the package includes types for three annotations datasets (binary, multiclass and real annotations), all of them with the following structure:</p> 
  <table> 
   <thead> 
    <tr> 
     <th>example</th> 
     <th>annotator</th> 
     <th>value</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td>1</td> 
     <td>1</td> 
     <td>0</td> 
    </tr> 
    <tr> 
     <td>1</td> 
     <td>2</td> 
     <td>1</td> 
    </tr> 
    <tr> 
     <td>2</td> 
     <td>2</td> 
     <td>0</td> 
    </tr> 
    <tr> 
     <td>...</td> 
     <td>...</td> 
     <td>...</td> 
    </tr>
   </tbody>
  </table> 
  <p>So the user needs to provide the annotations using this typed datasets to use the learning methods. This is usually simple if the user has all the information above in a Spark DataFrame:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.enriquegrodrigo.spark.crowd.types.</span><span class="pl-v">BinaryAnnotation</span>

<span class="pl-k">val</span> <span class="pl-en">df</span> <span class="pl-k">=</span> annotationDataFrame

<span class="pl-k">val</span> <span class="pl-en">converted</span> <span class="pl-k">=</span> fixed.map(x <span class="pl-k">=&gt;</span> <span class="pl-en">BinaryAnnotation</span>(x.getLong(<span class="pl-c1">0</span>), x.getLong(<span class="pl-c1">1</span>), x.getInt(<span class="pl-c1">2</span>)))
                     .as[<span class="pl-en">BinaryAnnotation</span>]</pre>
  </div> 
  <p>The process is similar for the other types of annotation data. The <code>converted</code> Spark Dataset is ready to be use with the methods commented in the <em>Methods</em> subsection.</p> 
  <p>In the case of the feature dataset, the requisites are that:</p> 
  <ul> 
   <li>Appart from the features, the data must have an <code>example</code> and a <code>class</code> columns</li> 
   <li>The example must be of type <code>Long</code></li> 
   <li>Class must be of type <code>Integer</code> or <code>Double</code>, depending on the type of class (discrete or continuous)</li> 
   <li>All features must be of type <code>Double</code></li> 
  </ul> 
  <h3><a id="user-content-methods" class="anchor" href="https://github.com/enriquegrodrigo/spark-crowd#methods" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Methods</h3> 
  <p>The methods implemented as well as the type of annotations that they support are summarised in the following table:</p> 
  <table> 
   <thead> 
    <tr> 
     <th align="center">Method</th> 
     <th align="center">Binary</th> 
     <th align="center">Multiclass</th> 
     <th align="center">Real</th> 
     <th align="center">Reference</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td align="center"><a href="https://enriquegrodrigo.github.io/spark-crowd/#com.enriquegrodrigo.spark.crowd.methods.MajorityVoting$" target="_blank">MajorityVoting</a></td> 
     <td align="center">
      <g-emoji alias="white_check_mark" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/2705.png" ios-version="6.0">
       ✅
      </g-emoji></td> 
     <td align="center">
      <g-emoji alias="white_check_mark" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/2705.png" ios-version="6.0">
       ✅
      </g-emoji></td> 
     <td align="center">
      <g-emoji alias="white_check_mark" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/2705.png" ios-version="6.0">
       ✅
      </g-emoji></td> 
     <td align="center"></td> 
    </tr> 
    <tr> 
     <td align="center"><a href="https://enriquegrodrigo.github.io/spark-crowd/#com.enriquegrodrigo.spark.crowd.methods.DawidSkene$" target="_blank">DawidSkene</a></td> 
     <td align="center">
      <g-emoji alias="white_check_mark" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/2705.png" ios-version="6.0">
       ✅
      </g-emoji></td> 
     <td align="center">
      <g-emoji alias="white_check_mark" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/2705.png" ios-version="6.0">
       ✅
      </g-emoji></td> 
     <td align="center"></td> 
     <td align="center"><a href="https://www.jstor.org/stable/2346806?seq=1#page_scan_tab_contents" target="_blank">JRSS</a></td> 
    </tr> 
    <tr> 
     <td align="center"><a href="https://enriquegrodrigo.github.io/spark-crowd/#com.enriquegrodrigo.spark.crowd.methods.Glad$" target="_blank">GLAD</a></td> 
     <td align="center">
      <g-emoji alias="white_check_mark" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/2705.png" ios-version="6.0">
       ✅
      </g-emoji></td> 
     <td align="center"></td> 
     <td align="center"></td> 
     <td align="center"><a href="https://papers.nips.cc/paper/3644-whose-vote-should-count-more-optimal-integration-of-labels-from-labelers-of-unknown-expertise" target="_blank">NIPS</a></td> 
    </tr> 
    <tr> 
     <td align="center"><a href="https://enriquegrodrigo.github.io/spark-crowd/#com.enriquegrodrigo.spark.crowd.methods.RaykarBinary$" target="_blank">Raykar</a></td> 
     <td align="center">
      <g-emoji alias="white_check_mark" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/2705.png" ios-version="6.0">
       ✅
      </g-emoji></td> 
     <td align="center"></td> 
     <td align="center"></td> 
     <td align="center"><a href="http://jmlr.csail.mit.edu/papers/v11/raykar10a.html" target="_blank">JMLR</a></td> 
    </tr> 
    <tr> 
     <td align="center"><a href="https://enriquegrodrigo.github.io/spark-crowd/#com.enriquegrodrigo.spark.crowd.methods.Kajino$" target="_blank">Kajino</a></td> 
     <td align="center">
      <g-emoji alias="white_check_mark" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/2705.png" ios-version="6.0">
       ✅
      </g-emoji></td> 
     <td align="center"></td> 
     <td align="center"></td> 
     <td align="center"><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/4919" target="_blank">AAAI</a></td> 
    </tr>
   </tbody>
  </table> 
  <p>The algorithm name links to the documentation of the implemented method in our application, as well as to the publication where the algorithm was published. As an example, the following code shows how to use the <code>DawidSkene</code> method:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.enriquegrodrigo.spark.crowd.methods.</span><span class="pl-v">DawidSkene</span>

<span class="pl-c"><span class="pl-c">//</span>Dataset of annotations</span>
<span class="pl-k">val</span> <span class="pl-en">df</span> <span class="pl-k">=</span> annotationDataset.as[<span class="pl-en">MulticlassAnnotation</span>]

<span class="pl-c"><span class="pl-c">//</span>Parameters for the method</span>
<span class="pl-k">val</span> <span class="pl-en">eMIters</span> <span class="pl-k">=</span> <span class="pl-c1">10</span>
<span class="pl-k">val</span> <span class="pl-en">eMThreshold</span> <span class="pl-k">=</span> <span class="pl-c1">0.01</span> 

<span class="pl-c"><span class="pl-c">//</span>Algorithm execution</span>
result <span class="pl-k">=</span> <span class="pl-en">DawidSkene</span>(df,eMIters, eMThreshold) 
annotatorReliability <span class="pl-k">=</span> result.params.pi
groundTruth <span class="pl-k">=</span> result.dataset</pre>
  </div> 
  <p>The information obtained from each algorithm as well as about the parameters needed by them can be found in the <a href="https://enriquegrodrigo.github.io/spark-crowd" target="_blank">documentation</a>.</p> 
  <h2><a id="user-content-credits" class="anchor" href="https://github.com/enriquegrodrigo/spark-crowd#credits" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Credits</h2> 
  <p>Author:</p> 
  <ul> 
   <li>Enrique G. Rodrigo</li> 
  </ul> 
  <p>Contributors:</p> 
  <ul> 
   <li>Juan A. Aledo</li> 
   <li>Jose A. Gamez</li> 
  </ul> 
  <h2><a id="user-content-license" class="anchor" href="https://github.com/enriquegrodrigo/spark-crowd#license" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>License</h2> 
  <p>MIT License</p> 
  <p>Copyright (c) 2017 Enrique González Rodrigo</p> 
  <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> 
  <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> 
  <p>THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p> 
 </article>
</div>