{
  "data":{
    "repository":{
      "issues":{
        "nodes":[
          {
            "number":190,
            "title":"What is the proper way to set the timezone of datetime columns in finagle-mysql?",
            "bodyText":"finagle-mysql writes DATETIME and TIMESTAMP columns in the current timezone and does not provide a way to specify a timezone (or force them to be in UTC).\nIs this intentional? Are there plans to provide a way to force them to be sent in UTC?",
            "url":"https://github.com/twitter/finagle/issues/190"
          },
          {
            "number":357,
            "title":"Don't mess with class loaders... or do it gently",
            "bodyText":"Issue is described in following thread:\nhttps://groups.google.com/forum/#!topic/finaglers/snRvOYwljbI\nBasically Play's auto-reloading breaks Finagle's reflection based API.\nAlso @jproper gives good explanation of what's going on and how to fix it here:\nplayframework/playframework#4159",
            "url":"https://github.com/twitter/finagle/issues/357"
          },
          {
            "number":360,
            "title":"Set finagle-redis tests integration tests up to run as integration tests in SBT and Travis CI",
            "bodyText":"We're currently excluding the finagle-redis integration tests in the SBT build. We should move them to the appropriate location, configure SBT to treat them as integration tests, and set up the Travis CI build to have a Redis server available to run them. (If this has a large impact on the Travis CI testing times we might need to turn them off there, but they currently run pretty quickly on my local machine.)",
            "url":"https://github.com/twitter/finagle/issues/360"
          },
          {
            "number":438,
            "title":"[finagle-mysql] finagle-mysql 6.25.0: Can not read UNSIGNED INT columns correctly",
            "bodyText":"Given this table:\nCREATE TABLE `batches` (\n  `id`         INT UNSIGNED NOT NULL AUTO_INCREMENT,\n  PRIMARY KEY (`id`)\n)\n  ENGINE = InnoDB\n  DEFAULT CHARSET = utf8\n  COLLATE = utf8_unicode_ci;\n\nwith this data:\nINSERT INTO `batches` (`id`)\nVALUES (4294967295);\n\nTrying to load that row with finagle mysql via pseudo code:\nPreparedStatementQuery(\"SELECT * FROM batches WHERE id = ?\").select(4294967295L)\n\nresults in this value being available in the pattern matching:\nIntValue(-1)\n\nIt looks like mysql-finagle does not understand UNSIGNED int's which should result in a LongValue() or at least a Long java/scala representation. It always parses an Int which MaxValue is:\nscala> Int.MaxValue\nres0: Int = 2147483647\n\nThe problematic code I guess is this:\nhttps://github.com/twitter/finagle/blob/develop/finagle-mysql/src/main/scala/com/twitter/finagle/mysql/Row.scala#L74\nExpected behaviuor would be the that I can successfully read the value 4294967295 back somehow.",
            "url":"https://github.com/twitter/finagle/issues/438"
          },
          {
            "number":526,
            "title":"Add com.twitter.finagle.zipkin.core.Endpoint.ipv6",
            "bodyText":"We currently support logging of only IPv4 addresses. Starting with Zipkin 1.4, endpoints can omit IPv4 (by setting Endpoint.ipv4 to 0), and optionally log Endpoint.ipv6 as the raw 16byte address.\nhttps://github.com/openzipkin/zipkin-api/blob/master/thrift/zipkinCore.thrift#L276\nIt looks like the most pivotal change is updating com.twitter.finagle.zipkin.core.Endpoint.ipv6\ncc @sveinnfannar",
            "url":"https://github.com/twitter/finagle/issues/526"
          },
          {
            "number":538,
            "title":"Streaming requests with a fixed content-length are received in one large chunk",
            "bodyText":"I'm trying to stream requests for certain routes in a Finatra server, in order to pipeline the contents to a downstream http service. But the streaming option has no practical effect because Finagle constructs a Netty HttpMessageDecoder that accumulates up to maxRequestSize bytes into a buffer before firing any events.\nExpected behavior\nIn a Finatra route callback, with Finagle's streaming option configured (by specifying Finatra's streamRequest option), I expect to be able to obtain com.twitter.io.Reader that fills a buffer with bytes as they are received.\nActual behavior\nWhen the Finatra route callback is called the entire contents of the request have always been read into the reader beforehand. A debugger session shows that Netty's HttpMessageDecoder does asynchronously receive bytes, but accumulates them into a buffer rather than immediately passing them up the pipeline.\nSteps to Reproduce\nI am developing a Finatra server (2.1.6, Finagle version 6.35.0). I set streaming to true by configuring the streamRequest option in the Finatra server. One particular route callback in the Finatra server is supposed to accept POSTed files from our client app and stream them to a downstream service, preferably without buffering the entire file in memory first.\nI can reproduce by uploading a largish (<5MB) file via curl to the Finatra route mentioned above. (So, a fixed-length request, like our client app would send, with a content-length header and no transfer-encoding: chunked header.) The buffer is always filled before the route callback is invoked.\nDiscussion\nAs far as I can tell, this is because when com.twitter.finagle.http.Http constructs a Netty pipeline, it passes maxRequestSize as the maxChunkSize argument of SafeHttpServerCodec. This amounts to inserting a Netty HttpMessageDecoder that does not detect a frame and emit a messageReceived event until the entire message has been received.\nSee \n  \n    \n      finagle/finagle-http/src/main/scala/com/twitter/finagle/http/Codec.scala\n    \n    \n         Line 291\n      in\n      3bd9661\n    \n    \n    \n    \n\n        \n          \n           pipeline.addLast(\"httpCodec\", new SafeHttpServerCodec(maxInitialLineLengthInBytes, maxHeaderSizeInBytes, maxRequestSizeInBytes)) \n        \n    \n  \n\n\nIs it possible to decouple the chunk size and request size concepts? It seems the HttpChunkAggregator, which is added to the pipeline when streaming is false, would handle aggregating smaller chunks into the completed message for the non-streaming case.\nNote: I'm mostly using Finagle via Finatra, and then at one remove via a Java wrapper library created at my company. I'm learning to read Scala, but not prepared to write any yet.",
            "url":"https://github.com/twitter/finagle/issues/538"
          },
          {
            "number":554,
            "title":"*** Finagle-mysql doesn't fully support stored procedures ***",
            "bodyText":"finagle-mysql fails when trying to execute a stored procedure that does queries.\nExpected behavior\nWhen calling a stored procedure, finagle should return the result set from all the queries being done inside the procedure.\nActual behavior\nFails with the following error:\ncom.twitter.finagle.mysql.ServerError: PROCEDURE db.st_test can't return a result set in the given context\nSteps to reproduce the behavior\nCreate a stored procedure that does queries (SELECT, UPDATE, etc)\nCall it with a mysql client using something like this:\nval future = client.select(\"CALL st_test(@msg)\") { row => row(\"message\").get }\nMore info about this can be found here: https://bugs.php.net/bug.php?id=42548\nThanks!",
            "url":"https://github.com/twitter/finagle/issues/554"
          },
          {
            "number":562,
            "title":"How to set Host header with LoadBalancing",
            "bodyText":"According to #560 you may be discussing but I got confused when using Finagle's load balancing feature.\nIn order to distribute requests to multiple servers, we instantiate a service via Http.Client#newService as follows,\nval client = Http.client.newService(\"hostA.org:80, hostB.org:80\")\nThen construct request,\nval request = Request(\"/path/to/service\")\nrequest.host = ???\n\nclient(request)\n\nWhat should we fill ??? with?\nMoreover, we're forced to pass the host addresses twice when the service creation and the building request. It's not DRY.\nAre there any reasons that the Host header automatically set that given to the Service?",
            "url":"https://github.com/twitter/finagle/issues/562"
          },
          {
            "number":616,
            "title":"ChannelStatsHandler \"connections\" gauge with negative values",
            "bodyText":"When netty starts closing connections ChannelStatsHandler doesn't not decrements connections gauge properly. When service is not used for long time connections gauge gets negative values\nExpected behavior\nProper connections count\nActual behavior\nWhen netty starts closing connections ChannelStatsHandler doesn't not decrements connections gauge properly. When service is not used for long time connections gauge gets negative values\nSteps to reproduce the behavior\n\nConfigure http client with stats receiver\nSend many concurrent requests in order to fill up connection pool\nDo not use prepared finagle service in order to allow netty to close connections",
            "url":"https://github.com/twitter/finagle/issues/616"
          }
        ]
      }
    }
  }
}