<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <p><a href="https://github.com/stripe/brushfire/blob/master/brushfire.png" target="_blank"><img src="https://github.com/stripe/brushfire/raw/master/brushfire.png" alt="Brushfire" style="max-width:100%;"></a></p> 
  <h1><a id="user-content-brushfire" class="anchor" href="https://github.com/stripe/brushfire#brushfire" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Brushfire</h1> 
  <p>Brushfire is a framework for distributed supervised learning of decision tree ensemble models in Scala.</p> 
  <p>The basic approach to distributed tree learning is inspired by Google's <a href="http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/36296.pdf" target="_blank">PLANET</a>, but considerably generalized thanks to Scala's type parameterization and Algebird's aggregation abstractions.</p> 
  <p>Brushfire currently supports:</p> 
  <ul> 
   <li>binary and multi-class classifiers</li> 
   <li>numeric features (discrete and continuous)</li> 
   <li>categorical features (including those with very high cardinality)</li> 
   <li>k-fold cross validation and random forests</li> 
   <li>chi-squared test as a measure of split quality</li> 
   <li>feature importance and brier scores</li> 
   <li>Scalding/Hadoop as a distributed computing platform</li> 
  </ul> 
  <p>In the future we plan to add support for:</p> 
  <ul> 
   <li>regression trees</li> 
   <li>CHAID-like multi-way splits</li> 
   <li>error-based pruning</li> 
   <li>many more ways to evaluate splits and trees</li> 
   <li>Spark and single-node in-memory platforms</li> 
  </ul> 
  <h1><a id="user-content-authors" class="anchor" href="https://github.com/stripe/brushfire#authors" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Authors</h1> 
  <ul> 
   <li>Avi Bryant <a href="http://twitter.com/avibryant" target="_blank">http://twitter.com/avibryant</a></li> 
  </ul> 
  <p>Thanks for assistance and contributions:</p> 
  <ul> 
   <li>Edwin Chen <a href="https://twitter.com/echen" target="_blank">https://twitter.com/echen</a></li> 
   <li>Dan Frank <a href="http://twitter.com/danielhfrank" target="_blank">http://twitter.com/danielhfrank</a></li> 
   <li>Nathan Howell <a href="https://twitter.com/nathanhowell" target="_blank">https://twitter.com/nathanhowell</a></li> 
   <li>Roban Kramer <a href="https://twitter.com/robanhk" target="_blank">https://twitter.com/robanhk</a></li> 
   <li>Colin Marc <a href="http://twitter.com/colinmarc" target="_blank">http://twitter.com/colinmarc</a></li> 
   <li>Steven Noble <a href="http://twitter.com/snoble" target="_blank">http://twitter.com/snoble</a></li> 
   <li>Erik Osheim <a href="http://twitter.com/d6" target="_blank">http://twitter.com/d6</a></li> 
   <li>Tom Switzer <a href="https://twitter.com/tixxit" target="_blank">https://twitter.com/tixxit</a></li> 
  </ul> 
  <h1><a id="user-content-quick-start" class="anchor" href="https://github.com/stripe/brushfire#quick-start" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Quick start</h1> 
  <pre><code>sbt brushfireScalding/assembly
cd example
./iris
cat iris.output/step_03
</code></pre> 
  <p>If it worked, you should see a JSON representation of 4 versions of a decision tree for classifying irises.</p> 
  <p>To use brushfire in your own SBT project, add the following to your <code>build.sbt</code>:</p> 
  <div class="highlight highlight-source-scala">
   <pre>libraryDependencies <span class="pl-k">+</span><span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>com.stripe<span class="pl-pds">"</span></span> <span class="pl-k">%%</span> <span class="pl-s"><span class="pl-pds">"</span>brushfire<span class="pl-pds">"</span></span> <span class="pl-k">%</span> <span class="pl-s"><span class="pl-pds">"</span>0.6.3<span class="pl-pds">"</span></span></pre>
  </div> 
  <p>To use brushfire as a jar in your own Maven project, add the following to your POM file:</p> 
  <pre><code>&lt;dependency&gt;
  &lt;groupId&gt;com.stripe&lt;/groupId&gt;
  &lt;artifactId&gt;brushfire_${scala.binary.version}&lt;/artifactId&gt;
  &lt;version&gt;0.6.3&lt;/version&gt;
&lt;/dependency&gt;
</code></pre> 
  <h1><a id="user-content-using-brushfire-with-scalding" class="anchor" href="https://github.com/stripe/brushfire#using-brushfire-with-scalding" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Using Brushfire with Scalding</h1> 
  <p>The only distributed computing platform that Brushfire currently supports is <a href="http://github.com/twitter/scalding" target="_blank">Scalding</a>, version 0.12 or later.</p> 
  <p>The simplest way to use Brushfire with Scalding is by subclassing <a href="http://stripe.github.io/brushfire/#com.stripe.brushfire.scalding.TrainerJob" target="_blank">TrainerJob</a> and overriding <code>trainer</code> to return an instance of <a href="http://stripe.github.io/brushfire/#com.stripe.brushfire.scalding.Trainer" target="_blank">Trainer</a>. Example:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.stripe.brushfire.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">com.stripe.brushfire.scalding.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">com.twitter.scalding.</span><span class="pl-v">_</span>

<span class="pl-k">class</span> <span class="pl-en">MyJob</span>(<span class="pl-v">args</span>: <span class="pl-en">Args</span>) <span class="pl-k">extends</span> <span class="pl-e">TrainerJob</span>(args) {
  <span class="pl-k">import</span> <span class="pl-v">JsonInjections.</span><span class="pl-v">_</span>

  <span class="pl-k">def</span> <span class="pl-en">trainer</span> <span class="pl-k">=</span> <span class="pl-k">???</span>
}
```

<span class="pl-en">You</span> should <span class="pl-k">import</span> <span class="pl-v">either `JsonInjections` or `KryoInjections` to specify serialization in either JSON or base64-encoded Kryo, respectively</span>; the former has the advantage of being human readable, the latter is more efficient, which can be important <span class="pl-k">for</span> very large trees.

<span class="pl-en">To</span> construct a `<span class="pl-en">Trainer</span>`, you need to pass it training data as a <span class="pl-en">Scalding</span> `<span class="pl-en">TypedPipe</span>` of <span class="pl-en">Brushfire</span> [<span class="pl-en">Instance</span>[<span class="pl-en">K</span>, <span class="pl-en">V</span>,<span class="pl-en">T</span>]](http<span class="pl-k">:</span><span class="pl-c"><span class="pl-c">//</span>stripe.github.io/brushfire/#com.stripe.brushfire.Instance) objects. `Instance` looks like this:</span>

````scala
<span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">Instance</span>[<span class="pl-en">K</span>, <span class="pl-en">V</span>, <span class="pl-en">T</span>](<span class="pl-v">id</span>: <span class="pl-k">String</span>, <span class="pl-v">timestamp</span>: <span class="pl-k">Long</span>, <span class="pl-v">features</span>: <span class="pl-en">Map</span>[<span class="pl-en">K</span>, <span class="pl-en">V</span>], <span class="pl-v">target</span>: <span class="pl-en">T</span>)</pre>
  </div> 
  <ul> 
   <li>The <code>id</code> should be unique for each instance.</li> 
   <li>If there's an associated observation time, it should be the <code>timestamp</code>. (Otherwise <code>0L</code> is fine)</li> 
   <li><code>features</code> is a <code>Map</code> from feature name (type K, usually String) to some value of type V. There's built-in implicit support for <code>Int</code>, <code>Double</code>, <code>Boolean</code>, and <code>String</code> types (with the assumption for <code>Int</code> and <code>String</code> that there is a small, finite number of possible values). If, as is common, you need to mix different feature types, see the section on <code>Dispatched</code> below.</li> 
   <li>the only built-in support for <code>target</code> currently is for <code>Map[L,Long]</code>, where <code>L</code> represents some label type (for example <code>Boolean</code> for a binary classifier or <code>String</code> for multi-class). The <code>Long</code> values represent the weight for the instance, which is usually 1.</li> 
  </ul> 
  <p>Example:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-en">Instance</span>(<span class="pl-s"><span class="pl-pds">"</span>AS-2014<span class="pl-pds">"</span></span>, <span class="pl-c1">1416168857L</span>, <span class="pl-en">Map</span>(<span class="pl-s"><span class="pl-pds">"</span>lat<span class="pl-pds">"</span></span> <span class="pl-k">-</span><span class="pl-k">&gt;</span> <span class="pl-c1">49.2</span>, <span class="pl-s"><span class="pl-pds">"</span>long<span class="pl-pds">"</span></span> <span class="pl-k">-</span><span class="pl-k">&gt;</span> <span class="pl-c1">37.1</span>, <span class="pl-s"><span class="pl-pds">"</span>altitude<span class="pl-pds">"</span></span> <span class="pl-k">-</span><span class="pl-k">&gt;</span> <span class="pl-c1">35000.0</span>), <span class="pl-en">Map</span>(<span class="pl-c1">true</span> <span class="pl-k">-</span><span class="pl-k">&gt;</span> <span class="pl-c1">1L</span>))</pre>
  </div> 
  <p>You also need to pass it a <a href="http://stripe.github.io/brushfire/#com.stripe.brushfire.Sampler" target="_blank">Sampler</a>. Here are some samplers you might use:</p> 
  <ul> 
   <li><a href="http://stripe.github.io/brushfire/#com.stripe.brushfire.SingleTreeSampler$" target="_blank">SingleTreeSampler</a> will use the entirety of the training data to construct a single tree.</li> 
   <li><a href="http://stripe.github.io/brushfire/#com.stripe.brushfire.KFoldSampler" target="_blank">KFoldSampler(numTrees: Int)</a> will construct k different trees, each excluding a random 1/k of the data, for use in cross-validation.</li> 
   <li><a href="http://stripe.github.io/brushfire/#com.stripe.brushfire.RFSampler" target="_blank">RFSampler(numTrees: Int, featureRate: Double, samplingRate: Double)</a> will construct multiple trees, each using a separate bootstrap sample (using <code>samplingRate</code>, which defaults to <code>1.0</code>). Each node in the tree will also only consider a random <code>featureRate</code> sample of the features available. (This is the approach used for random forests).</li> 
  </ul> 
  <p>One you have constructed a <code>Trainer</code>, you most likely want to call <code>expandTimes(base: String, times: Int)</code>. This will build a new ensemble of trees from the training data and expand them <code>times</code> times, to depth <code>times</code>. At each step, the trees will be serialized to a directory (on HDFS, unless you're running in local mode) under <code>base</code>.</p> 
  <p>Fuller example:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.stripe.brushfire.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">com.stripe.brushfire.scalding.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">com.twitter.scalding.</span><span class="pl-v">_</span>

<span class="pl-k">class</span> <span class="pl-en">MyJob</span>(<span class="pl-v">args</span>: <span class="pl-en">Args</span>) <span class="pl-k">extends</span> <span class="pl-e">TrainerJob</span>(args) {
  <span class="pl-k">import</span> <span class="pl-v">JsonInjections.</span><span class="pl-v">_</span>

  <span class="pl-k">def</span> <span class="pl-en">trainingData</span><span class="pl-k">:</span> <span class="pl-en">TypedPipe</span>[<span class="pl-en">Instance</span>[<span class="pl-en">K</span>, <span class="pl-en">V</span>,<span class="pl-en">T</span>]] <span class="pl-k">=</span> <span class="pl-k">???</span>
  <span class="pl-k">def</span> <span class="pl-en">trainer</span> <span class="pl-k">=</span> <span class="pl-en">Trainer</span>(trainingData, <span class="pl-en">KFoldSampler</span>(<span class="pl-c1">4</span>)).expandTimes(args(<span class="pl-s"><span class="pl-pds">"</span>output<span class="pl-pds">"</span></span>), <span class="pl-c1">5</span>)
}</pre>
  </div> 
  <p>#In Memory Expansion</p> 
  <p>Having expanded as deep as you want using the distributed algorithm, you may wish to ask for further, in-memory expansion of any nodes that are sufficiently small at this point by calling <code>expandSmallNodes(path: String, times: Int)</code>. By default, this will downsample every node to at most 10,000 instances of training data, and expand until they have fewer than 10 instances. You may need to tune this value, which you do by setting an implicit <code>Stopper</code>:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">val</span> <span class="pl-en">implicit</span> stopper <span class="pl-k">=</span> <span class="pl-en">FrequencyStopper</span>(<span class="pl-c1">10000</span>, <span class="pl-c1">10</span>)
trainer.expandInMemory(args(<span class="pl-s"><span class="pl-pds">"</span>output<span class="pl-pds">"</span></span>) <span class="pl-k">+</span> <span class="pl-s"><span class="pl-pds">"</span>/mem<span class="pl-pds">"</span></span>, <span class="pl-c1">100</span>)
```

<span class="pl-en">Note</span> that the distributed algorithm will <span class="pl-k">*</span>stop<span class="pl-k">*</span> expanding at the same instance count that the in<span class="pl-k">-</span>memory algorithm wants, ie, <span class="pl-c1">10</span>,<span class="pl-c1">000</span> instances by default.

# <span class="pl-en">Dispatched</span>

<span class="pl-en">If</span> you have mixed features, the recommended value <span class="pl-k">type</span> <span class="pl-en">is</span> `<span class="pl-en">Dispatched</span>[<span class="pl-k">Int</span>,<span class="pl-k">String</span>,<span class="pl-k">Double</span>,<span class="pl-k">String</span>]`, which requires your feature values to <span class="pl-k">match</span> any one of these four <span class="pl-v">cases</span>:

<span class="pl-k">*</span> `<span class="pl-en">Ordinal</span>(<span class="pl-v">v</span>: <span class="pl-k">Int</span>)` <span class="pl-k">for</span> numeric features <span class="pl-k">with</span> <span class="pl-e">a</span> reasonably small number of possible values
<span class="pl-k">*</span> `<span class="pl-en">Nominal</span>(<span class="pl-v">v</span>: <span class="pl-k">String</span>)` <span class="pl-k">for</span> categorical features <span class="pl-k">with</span> <span class="pl-e">a</span> reasonably small number of possible values
<span class="pl-k">*</span> `<span class="pl-en">Continuous</span>(<span class="pl-v">v</span>: <span class="pl-k">Double</span>)` <span class="pl-k">for</span> numeric features <span class="pl-k">with</span> <span class="pl-e">a</span> large or infinite number of possible values
<span class="pl-k">*</span> `<span class="pl-en">Sparse</span>(<span class="pl-v">v</span>: <span class="pl-k">String</span>)` <span class="pl-k">for</span> categorical features <span class="pl-k">with</span> <span class="pl-e">a</span> large or infinite number of possible values

<span class="pl-en">Note</span> that using `<span class="pl-en">Sparse</span>` and especially `<span class="pl-en">Continuous</span>` features will currently slow learning down considerably. (<span class="pl-en">But</span> on the other hand, <span class="pl-k">if</span> you <span class="pl-k">try</span> to use `<span class="pl-en">Ordinal</span>` or `<span class="pl-en">Nominal</span>` <span class="pl-k">with</span> <span class="pl-e">a</span> feature that has hundreds of thousands of unique values, it will be even slower, and then fail).

<span class="pl-en">Example</span> of a features <span class="pl-v">map</span>:

````scala
<span class="pl-en">Map</span>(<span class="pl-s"><span class="pl-pds">"</span>age<span class="pl-pds">"</span></span> <span class="pl-k">-</span><span class="pl-k">&gt;</span> <span class="pl-en">Ordinal</span>(<span class="pl-c1">35</span>), <span class="pl-s"><span class="pl-pds">"</span>gender<span class="pl-pds">"</span></span> <span class="pl-k">-</span><span class="pl-k">&gt;</span> <span class="pl-en">Nominal</span>(<span class="pl-s"><span class="pl-pds">"</span>male<span class="pl-pds">"</span></span>), <span class="pl-s"><span class="pl-pds">"</span>weight<span class="pl-pds">"</span></span> <span class="pl-k">-</span><span class="pl-k">&gt;</span> <span class="pl-en">Continuous</span>(<span class="pl-c1">130.23</span>), <span class="pl-s"><span class="pl-pds">"</span>name<span class="pl-pds">"</span></span> <span class="pl-k">-</span><span class="pl-k">&gt;</span> <span class="pl-en">Sparse</span>(<span class="pl-s"><span class="pl-pds">"</span>John<span class="pl-pds">"</span></span>))</pre>
  </div> 
  <h1><a id="user-content-extending-brushfire" class="anchor" href="https://github.com/stripe/brushfire#extending-brushfire" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Extending Brushfire</h1> 
  <p>Brushfire is designed to be extremely pluggable. Some ways you might want to extend it are (from simplest to most involved):</p> 
  <ul> 
   <li>Adding a new sampling strategy, to get finer grained control over how instances are allocated to trees, or between the training set and the test set: define a new <a href="http://stripe.github.io/brushfire/#com.stripe.brushfire.Sampler" target="_blank">Sampler</a></li> 
   <li>Add a new evaluation strategy (such as log-likelihood or entropy): define a new <a href="http://stripe.github.io/brushfire/#com.stripe.brushfire.Evaluator" target="_blank">Evaluator</a></li> 
   <li>Adding a new feature type, or a new way of binning an existing feature type (such as log-binning real numbers): define a new <a href="http://stripe.github.io/brushfire/#com.stripe.brushfire.Splitter" target="_blank">Splitter</a></li> 
   <li>Adding a new target type (such as real-valued targets for regression trees): define a new <a href="http://stripe.github.io/brushfire/#com.stripe.brushfire.Evaluator" target="_blank">Evaluator</a>, a new <a href="http://stripe.github.io/brushfire/#com.stripe.brushfire.Stopper" target="_blank">Stopper</a> and quite likely also define a new <a href="http://stripe.github.io/brushfire/#com.stripe.brushfire.Splitter" target="_blank">Splitter</a> for any continuous or sparse feature types you want to be able to use.</li> 
   <li>Add a new distributed computation platform: define a new equivalent of <a href="http://stripe.github.io/brushfire/#com.stripe.brushfire.scalding.Trainer" target="_blank">Trainer</a>, idiomatically to the platform you're using. (There's no specific interface this should implement.)</li> 
  </ul> 
 </article>
</div>