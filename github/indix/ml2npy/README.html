<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a id="user-content-ml2npy---export-spark-ml-sparsevectors-as-numpy-csr-matrix" class="anchor" href="https://github.com/indix/ml2npy#ml2npy---export-spark-ml-sparsevectors-as-numpy-csr-matrix" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>ml2npy - Export spark ml SparseVectors as numpy csr matrix</h1> 
  <p><a href="https://app.snap-ci.com/indix/ml2npy/branch/master" target="_blank"><img src="https://camo.githubusercontent.com/8c7a30a999fe1af5c6090c9cd18e080569736414/68747470733a2f2f6170702e736e61702d63692e636f6d2f696e6469782f6d6c326e70792f6272616e63682f6d61737465722f6275696c645f696d616765" alt="Build Status" data-canonical-src="https://app.snap-ci.com/indix/ml2npy/branch/master/build_image" style="max-width:100%;"></a></p> 
  <p><a href="https://maven-badges.herokuapp.com/maven-central/com.indix/ml2npy_2.11" target="_blank"><img src="https://camo.githubusercontent.com/180d9a25a979aebd0b005caf931efbc34a3aa9ef/68747470733a2f2f6d6176656e2d6261646765732e6865726f6b756170702e636f6d2f6d6176656e2d63656e7472616c2f636f6d2e696e6469782f6d6c326e70795f322e31312f62616467652e737667" alt="Maven Central" data-canonical-src="https://maven-badges.herokuapp.com/maven-central/com.indix/ml2npy_2.11/badge.svg" style="max-width:100%;"></a></p> 
  <p>The aim of this project is to provide that tools that efficiently implement the components that are required for large scale text mining. </p> 
  <p>The idea for this project came out from experience,</p> 
  <ol> 
   <li>Most of time it is data preprocessing that is expensive and demanding</li> 
   <li>Distributed algorithm implementations are not still as effective as Multicore/sequential implementations.</li> 
  </ol> 
  <p>This project intends to leverage the best of both worlds. In case of text mining, a traditional powerful approach is to use <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" target="_blank">TF-IDF</a> as numerical representation of the document. This enables a vareity of machine learning techniques to be readily applied on the data. Converting a document in to TF-IDF or any other numerical format is compute intensive and once a numerical representation is available, we could try out various algorithms and models on the preprocessed data. </p> 
  <p>Numerical representation of text tends to be very sparse. By choosing <a href="https://en.wikipedia.org/wiki/Sparse_matrix" target="_blank">sparse matrix formats</a> to save this data, we could save memory and disk usage. ml2npy provides tools and utilities to load a large corpus of text and save its numerical respresentation as CSR Matrix in <a href="https://docs.scipy.org/doc/numpy/neps/npy-format.html" target="_blank">numpy format</a></p> 
  <h3><a id="user-content-why-npy-format" class="anchor" href="https://github.com/indix/ml2npy#why-npy-format" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Why Npy format?</h3> 
  <p>Python and scikit-learn ecosystem has made machine learning a lot more accessible. By being able to load data in to python, means a lot of algorithms could be easily applied.</p> 
 </article>
</div>