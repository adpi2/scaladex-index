<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a id="user-content-memsql-spark-20-connector" class="anchor" href="https://github.com/memsql/memsql-spark-connector#memsql-spark-20-connector" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>MemSQL Spark 2.0 Connector</h1> 
  <p>The MemSQL 2.0 Spark connector enables users to load data from MemSQL tables into Spark Dataframes, and write Spark Dataframes to MemSQL tables.</p> 
  <h2><a id="user-content-requirements" class="anchor" href="https://github.com/memsql/memsql-spark-connector#requirements" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Requirements</h2> 
  <p>This library requires Spark 2.0+ and has been primarily tested against Spark version 2.0.2. For support with Spark 1.x, please check the <a href="https://github.com/memsql/memsql-spark-connector/tree/1.3.3" target="_blank">1.x branch</a>.</p> 
  <h2><a id="user-content-documentation" class="anchor" href="https://github.com/memsql/memsql-spark-connector#documentation" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Documentation</h2> 
  <p>You can find Scala documentation for everything exposed in this repo here: <a href="http://memsql.github.io/memsql-spark-connector" target="_blank">memsql.github.io/memsql-spark-connector</a></p> 
  <h2><a id="user-content-installation" class="anchor" href="https://github.com/memsql/memsql-spark-connector#installation" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Installation</h2> 
  <p>Inside a project definition you can depend on the MemSQL Connector using sbt:</p> 
  <pre><code>libraryDependencies  += "com.memsql" %% "memsql-connector" % "2.0.0"
</code></pre> 
  <p>or Maven:</p> 
  <div class="highlight highlight-text-xml">
   <pre>&lt;<span class="pl-ent">dependency</span>&gt;
    &lt;<span class="pl-ent">groupId</span>&gt;com.memsql&lt;/<span class="pl-ent">groupId</span>&gt;
    &lt;<span class="pl-ent">artifactId</span>&gt;memsql-connector_2.11&lt;/<span class="pl-ent">artifactId</span>&gt;
    &lt;<span class="pl-ent">version</span>&gt;2.0.0&lt;/<span class="pl-ent">version</span>&gt;
&lt;/<span class="pl-ent">dependency</span>&gt;</pre>
  </div> 
  <h2><a id="user-content-usage" class="anchor" href="https://github.com/memsql/memsql-spark-connector#usage" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Usage</h2> 
  <p>MemSQL Spark Connector leverages Spark SQL's Data Sources API. The connection to MemSQL relies on the following Spark configuration settings.</p> 
  <table>
   <thead> 
    <tr> 
     <th>Setting name</th> 
     <th>Default value if not specified</th> 
    </tr> 
   </thead>
   <tbody> 
    <tr> 
     <td>spark.memsql.host</td> 
     <td>localhost</td> 
    </tr> 
    <tr> 
     <td>spark.memsql.port</td> 
     <td>3306</td> 
    </tr> 
    <tr> 
     <td>spark.memsql.user</td> 
     <td>root</td> 
    </tr> 
    <tr> 
     <td>spark.memsql.password</td> 
     <td>None</td> 
    </tr> 
    <tr> 
     <td>spark.memsql.defaultDB</td> 
     <td>None</td> 
    </tr> 
    <tr> 
     <td>spark.memsql.defaultSaveMode</td> 
     <td>"error" (see description below)</td> 
    </tr> 
   </tbody>
  </table> 
  <h3><a id="user-content-loading-data-from-memsql" class="anchor" href="https://github.com/memsql/memsql-spark-connector#loading-data-from-memsql" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Loading data from MemSQL</h3> 
  <p>The following example creates a Dataframe from the table "illinois" in the database "customers". To use the library, pass in "com.memsql.spark.connector" as the <code>format</code> parameter so Spark will call the MemSQL Spark Connector code. The option <code>path</code> is the full path of the table using the syntax "$database_name.$table_name". If there is only a table name, the connector will look for the table in the default database set in the configuration.</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">org.apache.spark.</span><span class="pl-v">SparkConf</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.spark.sql.</span><span class="pl-v">SparkSession</span>

<span class="pl-k">val</span> <span class="pl-en">conf</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">SparkConf</span>().setAppName(<span class="pl-s"><span class="pl-pds">"</span>MemSQL Spark Connector Example<span class="pl-pds">"</span></span>).set(<span class="pl-s"><span class="pl-pds">"</span>spark.memsql.host<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>10.0.0.190<span class="pl-pds">"</span></span>).set(<span class="pl-s"><span class="pl-pds">"</span>spark.memsql.password<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>foobar<span class="pl-pds">"</span></span>)
<span class="pl-k">val</span> <span class="pl-en">spark</span> <span class="pl-k">=</span> <span class="pl-en">SparkSession</span>.builder().config(conf).getOrCreate()

<span class="pl-k">val</span> <span class="pl-en">customersFromIllinois</span> <span class="pl-k">=</span> spark
    .read
    .format(<span class="pl-s"><span class="pl-pds">"</span>com.memsql.spark.connector<span class="pl-pds">"</span></span>)
    .options(<span class="pl-en">Map</span>(<span class="pl-s"><span class="pl-pds">"</span>path<span class="pl-pds">"</span></span> <span class="pl-k">-</span><span class="pl-k">&gt;</span> (<span class="pl-s"><span class="pl-pds">"</span>customers.illinois<span class="pl-pds">"</span></span>)))
    .load()
<span class="pl-c"><span class="pl-c">//</span> customersFromIllinois is now a Spark DataFrame which represents the specified MemSQL table</span>
<span class="pl-c"><span class="pl-c">//</span> and can be queried using Spark DataFrame query functions</span>

<span class="pl-c"><span class="pl-c">//</span> count the number of rows</span>
println(s<span class="pl-s"><span class="pl-pds">"</span>The number of customers from Illinois is ${customersFromIllinois.count()}<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">//</span> print out the DataFrame</span>
customersFromIllinois.show()</pre>
  </div> 
  <p>Instead of specifying a MemSQL table as the <code>path</code> in the options, the user can opt to create a DataFrame from a SQL query with the option <code>query</code>. This can minimize the amount of data transferred from MemSQL to Spark, and push down distributed computations to MemSQL instead of Spark.</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">org.apache.spark.</span><span class="pl-v">SparkConf</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.spark.sql.</span><span class="pl-v">SparkSession</span>

<span class="pl-k">val</span> <span class="pl-en">conf</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">SparkConf</span>().setAppName(<span class="pl-s"><span class="pl-pds">"</span>MemSQL Spark Connector Example<span class="pl-pds">"</span></span>).set(<span class="pl-s"><span class="pl-pds">"</span>spark.memsql.host<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>10.0.0.190<span class="pl-pds">"</span></span>).set(<span class="pl-s"><span class="pl-pds">"</span>spark.memsql.password<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>foobar<span class="pl-pds">"</span></span>)
<span class="pl-k">val</span> <span class="pl-en">spark</span> <span class="pl-k">=</span> <span class="pl-en">SparkSession</span>.builder().config(conf).getOrCreate()

<span class="pl-k">val</span> <span class="pl-en">customersFromIllinois</span> <span class="pl-k">=</span> spark
    .read
    .format(<span class="pl-s"><span class="pl-pds">"</span>com.memsql.spark.connector<span class="pl-pds">"</span></span>)
    .options(<span class="pl-en">Map</span>(<span class="pl-s"><span class="pl-pds">"</span>query<span class="pl-pds">"</span></span> <span class="pl-k">-</span><span class="pl-k">&gt;</span> (<span class="pl-s"><span class="pl-pds">"</span>select age_group, count(*) from customers.illinois where number_of_orders &gt; 3 GROUP BY age_group<span class="pl-pds">"</span></span>)))
    .load()

customersFromIllinois.show()
<span class="pl-c"><span class="pl-c">//</span> +-----------+---------+</span>
<span class="pl-c"><span class="pl-c">//</span> | age_group | count(*)|</span>
<span class="pl-c"><span class="pl-c">//</span> +-----------+---------+</span>
<span class="pl-c"><span class="pl-c">//</span> |  13-18    |   128   |</span>
<span class="pl-c"><span class="pl-c">//</span> |  19-25    |   150   |</span>
<span class="pl-c"><span class="pl-c">//</span> |  26+      |   140   |</span>
<span class="pl-c"><span class="pl-c">//</span> +-----------+---------+</span></pre>
  </div> 
  <h3><a id="user-content-saving-data-to-memsql" class="anchor" href="https://github.com/memsql/memsql-spark-connector#saving-data-to-memsql" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Saving data to MemSQL</h3> 
  <p>Similarly, use Spark SQL's Data Sources API to save a DataFrame to MemSQL. To save a DataFrame in the MemSQL table "students":</p> 
  <div class="highlight highlight-source-scala">
   <pre>...

<span class="pl-k">val</span> <span class="pl-en">rdd</span> <span class="pl-k">=</span> sc.parallelize(<span class="pl-en">Array</span>(<span class="pl-en">Row</span>(<span class="pl-s"><span class="pl-pds">"</span>John Smith<span class="pl-pds">"</span></span>, <span class="pl-c1">12</span>), <span class="pl-en">Row</span>(<span class="pl-s"><span class="pl-pds">"</span>Jane Doe<span class="pl-pds">"</span></span>, <span class="pl-c1">13</span>)))
<span class="pl-k">val</span> <span class="pl-en">schema</span> <span class="pl-k">=</span> <span class="pl-en">StructType</span>(<span class="pl-en">Seq</span>(<span class="pl-en">StructField</span>(<span class="pl-s"><span class="pl-pds">"</span>Name<span class="pl-pds">"</span></span>, <span class="pl-en">StringType</span>, <span class="pl-c1">false</span>),
                            <span class="pl-en">StructField</span>(<span class="pl-s"><span class="pl-pds">"</span>Age<span class="pl-pds">"</span></span>, <span class="pl-en">IntegerType</span>, <span class="pl-c1">false</span>)))
<span class="pl-k">val</span> <span class="pl-en">df</span> <span class="pl-k">=</span> sqlContext.createDataFrame(rdd, schema)
df
    .write
    .format(<span class="pl-s"><span class="pl-pds">"</span>com.memsql.spark.connector<span class="pl-pds">"</span></span>)
    .mode(<span class="pl-s"><span class="pl-pds">"</span>error<span class="pl-pds">"</span></span>)
    .save(<span class="pl-s"><span class="pl-pds">"</span>people.students<span class="pl-pds">"</span></span>)</pre>
  </div> 
  <p>The <code>mode</code> specifies how to handle duplicate keys when the MemSQL table has a primary key. The default, if unspecified, is "error", which means that if a row with the same primary key already exists in MemSQL's people.students table, an error is to be thrown. Other save modes:</p> 
  <table>
   <thead> 
    <tr> 
     <th>Save mode string</th> 
     <th>Description</th> 
    </tr> 
   </thead>
   <tbody> 
    <tr> 
     <td>"error"</td> 
     <td>MemSQL will error when encountering a record with duplicate keys</td> 
    </tr> 
    <tr> 
     <td>"ignore"</td> 
     <td>MemSQL will ignore records with duplicate keys and, without rolling back, continue inserting records with unique keys.</td> 
    </tr> 
    <tr> 
     <td>"overwrite"</td> 
     <td>MemSQL will replace the existing record with the new record</td> 
    </tr> 
   </tbody>
  </table> 
  <p>The second interface to save data to MemSQL is via the <code>saveToMemSQL</code> implicit function on a DataFrame you wish to save:</p> 
  <div class="highlight highlight-source-scala">
   <pre>...

<span class="pl-k">val</span> <span class="pl-en">rdd</span> <span class="pl-k">=</span> sc.parallelize(<span class="pl-en">Array</span>(<span class="pl-en">Row</span>(<span class="pl-s"><span class="pl-pds">"</span>John Smith<span class="pl-pds">"</span></span>, <span class="pl-c1">12</span>), <span class="pl-en">Row</span>(<span class="pl-s"><span class="pl-pds">"</span>Jane Doe<span class="pl-pds">"</span></span>, <span class="pl-c1">13</span>)))
<span class="pl-k">val</span> <span class="pl-en">schema</span> <span class="pl-k">=</span> <span class="pl-en">StructType</span>(<span class="pl-en">Seq</span>(<span class="pl-en">StructField</span>(<span class="pl-s"><span class="pl-pds">"</span>Name<span class="pl-pds">"</span></span>, <span class="pl-en">StringType</span>, <span class="pl-c1">false</span>),
                            <span class="pl-en">StructField</span>(<span class="pl-s"><span class="pl-pds">"</span>Age<span class="pl-pds">"</span></span>, <span class="pl-en">IntegerType</span>, <span class="pl-c1">false</span>)))
<span class="pl-k">val</span> <span class="pl-en">df</span> <span class="pl-k">=</span> sqlContext.createDataFrame(rdd, schema)
df.saveToMemSQL(<span class="pl-s"><span class="pl-pds">"</span>people.students<span class="pl-pds">"</span></span>)  
      <span class="pl-c"><span class="pl-c">//</span> The database name can be omitted if "spark.memsql.defaultDatabase" is set </span>
      <span class="pl-c"><span class="pl-c">//</span> in the Spark configuration df.sqlContext.sparkContext.getConf.getAll</span></pre>
  </div> 
  <h2><a id="user-content-building-and-testing" class="anchor" href="https://github.com/memsql/memsql-spark-connector#building-and-testing" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Building and Testing</h2> 
  <p>You can use SBT to compile the library</p> 
  <pre><code>sbt build
</code></pre> 
  <p>All unit tests can be run via sbt. They will also run at build time automatically.</p> 
  <pre><code>sbt test
</code></pre> 
 </article>
</div>