<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a id="user-content-kafka-hadoop-consumer" class="anchor" href="https://github.com/soid/kafka-hadoop-consumer#kafka-hadoop-consumer" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Kafka Hadoop Consumer</h1> 
  <p><a href="https://travis-ci.org/soid/kafka-hadoop-consumer" target="_blank"><img src="https://camo.githubusercontent.com/c41a90ee87a829c2bf76831af6861dd8553a4c0a/68747470733a2f2f7472617669732d63692e6f72672f736f69642f6b61666b612d6861646f6f702d636f6e73756d65722e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/soid/kafka-hadoop-consumer.svg?branch=master" style="max-width:100%;"></a></p> 
  <p>This is a fork of Conductor's [Kangaroo project] (<a href="https://github.com/Conductor/kangaroo" target="_blank">https://github.com/Conductor/kangaroo</a>). The main goal of the project is to provide updated Hadoop consumer for the new Kafka versions (0.8 and later), and maintain it, because the authors of the original project were not responsive to pull requests or messages for months. In this project Hadoop Input Format code has been decoupled from other unrelated code in Kangaroo, and integration tests introduced, among other improvements. The package has been changed from com.conductor to com.baynote, so the artifact can be published in Maven Central by the author of the fork.</p> 
  <h1><a id="user-content-versions" class="anchor" href="https://github.com/soid/kafka-hadoop-consumer#versions" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Versions</h1> 
  <table> 
   <thead> 
    <tr> 
     <th>Kafka Hadoop Consumer Version</th> 
     <th>Kafka Version</th> 
     <th>Scala Version</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td>0.8</td> 
     <td>0.8.2.1</td> 
     <td>2.11</td> 
    </tr> 
    <tr> 
     <td>0.8_2.11</td> 
     <td>0.8.2.1</td> 
     <td>2.11</td> 
    </tr>
   </tbody>
  </table> 
  <h1><a id="user-content-maven-central" class="anchor" href="https://github.com/soid/kafka-hadoop-consumer#maven-central" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Maven Central</h1> 
  <p>TODO</p> 
  <h3><a id="user-content-create-a-mapper" class="anchor" href="https://github.com/soid/kafka-hadoop-consumer#create-a-mapper" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Create a Mapper</h3> 
  <div class="highlight highlight-source-java">
   <pre><span class="pl-k">public</span> <span class="pl-k">static</span> <span class="pl-k">class</span> <span class="pl-en">MyMapper</span> <span class="pl-k">extends</span> <span class="pl-e">Mapper&lt;<span class="pl-smi">LongWritable</span>, <span class="pl-smi">BytesWritable</span>, <span class="pl-smi">KEY_OUT</span>, <span class="pl-smi">VALUE_OUT</span>&gt;</span> {

    <span class="pl-k">@Override</span>
    <span class="pl-k">protected</span> <span class="pl-k">void</span> <span class="pl-en">map</span>(<span class="pl-k">final</span> <span class="pl-smi">LongWritable</span> <span class="pl-v">key</span>, <span class="pl-k">final</span> <span class="pl-smi">BytesWritable</span> <span class="pl-v">value</span>, <span class="pl-k">final</span> <span class="pl-smi">Context</span> <span class="pl-v">context</span>) <span class="pl-k">throws</span> <span class="pl-smi">IOException</span>, <span class="pl-smi">InterruptedException</span> {
        <span class="pl-c"><span class="pl-c">//</span> implementation</span>
    }
}</pre>
  </div> 
  <ul> 
   <li>The <code>BytesWritable</code> value is the raw bytes of a single Kafka message.</li> 
   <li>The <code>LongWritable</code> key is the Kafka offset of the message.</li> 
  </ul> 
  <h3><a id="user-content-single-topic" class="anchor" href="https://github.com/soid/kafka-hadoop-consumer#single-topic" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Single topic</h3> 
  <div class="highlight highlight-source-java">
   <pre><span class="pl-c"><span class="pl-c">//</span> Create a new job</span>
<span class="pl-k">final</span> <span class="pl-smi">Job</span> job <span class="pl-k">=</span> <span class="pl-smi">Job</span><span class="pl-k">.</span>getInstance(getConf(), <span class="pl-s"><span class="pl-pds">"</span>my_job<span class="pl-pds">"</span></span>);

<span class="pl-c"><span class="pl-c">//</span> Set the InputFormat</span>
job<span class="pl-k">.</span>setInputFormatClass(<span class="pl-smi">KafkaInputFormat</span><span class="pl-k">.</span>class);

<span class="pl-c"><span class="pl-c">//</span> Set your Zookeeper connection string</span>
<span class="pl-smi">KafkaInputFormat</span><span class="pl-k">.</span>setZkConnect(job, <span class="pl-s"><span class="pl-pds">"</span>zookeeper-1.xyz.com:2181<span class="pl-pds">"</span></span>);

<span class="pl-c"><span class="pl-c">//</span> Set the topic you want to consume</span>
<span class="pl-smi">KafkaInputFormat</span><span class="pl-k">.</span>setTopic(job, <span class="pl-s"><span class="pl-pds">"</span>my_topic<span class="pl-pds">"</span></span>);

<span class="pl-c"><span class="pl-c">//</span> Set the consumer group associated with this job</span>
<span class="pl-smi">KafkaInputFormat</span><span class="pl-k">.</span>setConsumerGroup(job, <span class="pl-s"><span class="pl-pds">"</span>my_consumer_group<span class="pl-pds">"</span></span>);

<span class="pl-c"><span class="pl-c">//</span> Set the mapper that will consume the data</span>
job<span class="pl-k">.</span>setMapperClass(<span class="pl-smi">MyMapper</span><span class="pl-k">.</span>class);

<span class="pl-c"><span class="pl-c">//</span> (Optional) Only commit offsets if the job is successful</span>
<span class="pl-k">if</span> (job<span class="pl-k">.</span>waitForCompletion(<span class="pl-c1">true</span>)) {
    <span class="pl-k">final</span> <span class="pl-smi">ZkUtils</span> zk <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">ZkUtils</span>(job<span class="pl-k">.</span>getConfiguration());
    zk<span class="pl-k">.</span>commit(<span class="pl-s"><span class="pl-pds">"</span>my_consumer_group<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>my_topic<span class="pl-pds">"</span></span>);
    zk<span class="pl-k">.</span>close();
}</pre>
  </div> 
  <h3><a id="user-content-multiple-topics" class="anchor" href="https://github.com/soid/kafka-hadoop-consumer#multiple-topics" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Multiple topics</h3> 
  <div class="highlight highlight-source-java">
   <pre><span class="pl-c"><span class="pl-c">//</span> Create a new job</span>
<span class="pl-k">final</span> <span class="pl-smi">Job</span> job <span class="pl-k">=</span> <span class="pl-smi">Job</span><span class="pl-k">.</span>getInstance(getConf(), <span class="pl-s"><span class="pl-pds">"</span>my_job<span class="pl-pds">"</span></span>);

<span class="pl-c"><span class="pl-c">//</span> Set the InputFormat</span>
job<span class="pl-k">.</span>setInputFormatClass(<span class="pl-smi">MultipleKafkaInputFormat</span><span class="pl-k">.</span>class);

<span class="pl-c"><span class="pl-c">//</span> Set your Zookeeper connection string</span>
<span class="pl-smi">KafkaInputFormat</span><span class="pl-k">.</span>setZkConnect(job, <span class="pl-s"><span class="pl-pds">"</span>zookeeper-1.xyz.com:2181<span class="pl-pds">"</span></span>);

<span class="pl-c"><span class="pl-c">//</span> Add as many queue inputs as you'd like</span>
<span class="pl-smi">MultipleKafkaInputFormat</span><span class="pl-k">.</span>addTopic(job, <span class="pl-s"><span class="pl-pds">"</span>my_first_topic<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>my_consumer_group<span class="pl-pds">"</span></span>, <span class="pl-smi">MyMapper</span><span class="pl-k">.</span>class);
<span class="pl-smi">MultipleKafkaInputFormat</span><span class="pl-k">.</span>addTopic(job, <span class="pl-s"><span class="pl-pds">"</span>my_second_topic<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>my_consumer_group<span class="pl-pds">"</span></span>, <span class="pl-smi">MyMapper</span><span class="pl-k">.</span>class);
<span class="pl-c"><span class="pl-c">//</span> ...</span>

<span class="pl-c"><span class="pl-c">//</span> (Optional) Only commit offsets if the job is successful</span>
<span class="pl-k">if</span> (job<span class="pl-k">.</span>waitForCompletion(<span class="pl-c1">true</span>)) {
    <span class="pl-k">final</span> <span class="pl-smi">ZkUtils</span> zk <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">ZkUtils</span>(job<span class="pl-k">.</span>getConfiguration());
    <span class="pl-c"><span class="pl-c">//</span> commit the offsets for each topic</span>
    zk<span class="pl-k">.</span>commit(<span class="pl-s"><span class="pl-pds">"</span>my_consumer_group<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>my_first_topic<span class="pl-pds">"</span></span>);
    zk<span class="pl-k">.</span>commit(<span class="pl-s"><span class="pl-pds">"</span>my_consumer_group<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>my_second_topic<span class="pl-pds">"</span></span>);
    <span class="pl-c"><span class="pl-c">//</span> ...</span>
    zk<span class="pl-k">.</span>close();
}</pre>
  </div> 
  <h3><a id="user-content-customize-your-job" class="anchor" href="https://github.com/soid/kafka-hadoop-consumer#customize-your-job" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Customize Your Job</h3> 
  <p>Our Kafka input format allows you to limit the number of splits consumed in a single job:</p> 
  <ul> 
   <li>By consuming data created approximately on or after a timestamp.</li> 
  </ul> 
  <div class="highlight highlight-source-java">
   <pre><span class="pl-c"><span class="pl-c">//</span> Consume Kafka partition files with were last modified on or after October 13th, 2014</span>
<span class="pl-smi">KafkaInputFormat</span><span class="pl-k">.</span>setIncludeOffsetsAfterTimestamp(job, <span class="pl-c1">1413172800000</span>);</pre>
  </div> 
  <ul> 
   <li>By consuming a maximum number of Kafka partition files (splits), per Kafka partition.</li> 
  </ul> 
  <div class="highlight highlight-source-java">
   <pre><span class="pl-c"><span class="pl-c">//</span> Consume the oldest five unconsumed Kafka files per partition</span>
<span class="pl-smi">KafkaInputFormat</span><span class="pl-k">.</span>setMaxSplitsPerPartition(job, <span class="pl-c1">5</span>);</pre>
  </div> 
  <h3><a id="user-content-static-access-to-inputsplits" class="anchor" href="https://github.com/soid/kafka-hadoop-consumer#static-access-to-inputsplits" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Static Access to InputSplits</h3> 
  <p>Our Kafka input format exposes static access to a hypothetical job's <code>KafkaInputSplits</code>. We've found this information useful when estimating the number of reducers for certain jobs. This calculation is pretty fast; for a topic with 30 partitions on a 10-node Kafka cluster, this calculation took about 1 second.</p> 
  <div class="highlight highlight-source-java">
   <pre><span class="pl-k">final</span> <span class="pl-smi">Configuration</span> conf <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">Configuration</span>();
conf<span class="pl-k">.</span>set(<span class="pl-s"><span class="pl-pds">"</span>kafka.zk.connect<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>zookeeper-1.xyz.com:2181<span class="pl-pds">"</span></span>);

<span class="pl-c"><span class="pl-c">//</span> Get all splits for "my_topic"</span>
<span class="pl-k">final</span> <span class="pl-k">List&lt;<span class="pl-smi">InputSplit</span>&gt;</span> allTopicSplits <span class="pl-k">=</span> <span class="pl-smi">KafkaInputFormat</span><span class="pl-k">.</span>getAllSplits(conf, <span class="pl-s"><span class="pl-pds">"</span>my_topic<span class="pl-pds">"</span></span>);
<span class="pl-c"><span class="pl-c">//</span> Get all of "my_consumer_group"'s splits for "my_topic"</span>
<span class="pl-k">final</span> <span class="pl-k">List&lt;<span class="pl-smi">InputSplit</span>&gt;</span> consumerSplits <span class="pl-k">=</span> <span class="pl-smi">KafkaInputFormat</span><span class="pl-k">.</span>getSplits(conf, <span class="pl-s"><span class="pl-pds">"</span>my_topic<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>my_consumer_group<span class="pl-pds">"</span></span>);

<span class="pl-c"><span class="pl-c">//</span> Do some interesting calculations...</span>
<span class="pl-k">long</span> totalInputBytesOfJob <span class="pl-k">=</span> <span class="pl-c1">0</span>;
<span class="pl-k">for</span> (<span class="pl-k">final</span> <span class="pl-smi">InputSplit</span> split <span class="pl-k">:</span> consumerSplits) {
    totalInputBytesOfJob <span class="pl-k">+=</span> split<span class="pl-k">.</span>getLength();
}</pre>
  </div> 
 </article>
</div>