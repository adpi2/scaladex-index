<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a id="user-content-async-crawler" class="anchor" href="https://github.com/nisshiee/async-crawler#async-crawler" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>async-crawler</h1> 
  <p><a href="https://jenkins.nisshiee.org/job/async-crawler/" target="_blank"><img src="https://camo.githubusercontent.com/f58ef471f2a4525e22931291516c3a29e4ef8461/68747470733a2f2f6a656e6b696e732e6e697373686965652e6f72672f6275696c645374617475732f69636f6e3f6a6f623d6173796e632d637261776c6572" alt="Build Status" data-canonical-src="https://jenkins.nisshiee.org/buildStatus/icon?job=async-crawler" style="max-width:100%;"></a></p> 
  <p>async-crawlerは一発稼働系クローラーを簡単に作成するサポートをするライブラリです。</p> 
  <p>主なコンセプトは以下の通りです。</p> 
  <ul> 
   <li>一定のSleepタイムを強制的に挟むことでDos攻撃にならないよう調整を自動で入れる</li> 
   <li>Futureを用いた非同期リクエスト</li> 
   <li>レスポンスの柔軟な解析と解析部分の高いモジュラリティ</li> 
   <li>ScalazのMonad型クラスと連携してfor, map, flatMap等を用いたコーディングを実現</li> 
  </ul> 
  <h2><a id="user-content-how-to-use" class="anchor" href="https://github.com/nisshiee/async-crawler#how-to-use" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>How to use</h2> 
  <h3><a id="user-content-sbt" class="anchor" href="https://github.com/nisshiee/async-crawler#sbt" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>sbt</h3> 
  <pre><code>libraryDependencies += "org.nisshiee" %% "async-crawler" % "1.0.0"

// 各種解析補助モジュールを利用する場合は以下のモジュールを利用できます

libraryDependencies += "org.nisshiee" %% "async-crawler-jsoup" % "1.0.0"

libraryDependencies += "org.nisshiee" %% "async-crawler-json4s" % "1.0.0"

libraryDependencies += "org.nisshiee" %% "async-crawler-filedl" % "1.0.0"
</code></pre> 
  <h3><a id="user-content-coding-example" class="anchor" href="https://github.com/nisshiee/async-crawler#coding-example" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>coding example</h3> 
  <p>Jsoupを使ってTextNodeを抽出する例</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">org.nisshiee.crawler.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">org.nisshiee.crawler.jsoup.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">org.jsoup.nodes.</span><span class="pl-v">Document</span>
<span class="pl-k">import</span> <span class="pl-v">scalaz.</span><span class="pl-v">_, </span><span class="pl-v">Scalaz.</span><span class="pl-v">_</span>

<span class="pl-k">val</span> <span class="pl-en">f</span><span class="pl-k">:</span> <span class="pl-en">Fv</span>[<span class="pl-k">String</span>] <span class="pl-k">=</span> <span class="pl-en">Crawler</span>(<span class="pl-s"><span class="pl-pds">"</span>http://example.com<span class="pl-pds">"</span></span>) { <span class="pl-v">doc</span>: <span class="pl-en">Document</span> <span class="pl-k">=&gt;</span>
  doc.select(<span class="pl-s"><span class="pl-pds">"</span>h1<span class="pl-pds">"</span></span>).first.text successNel
}

f.result() <span class="pl-c"><span class="pl-c">//</span> =&gt; Success("Example Domain")</span>

<span class="pl-en">Crawler</span>.shutdown</pre>
  </div> 
  <p>深さ2までリンク辿ってURLリストを抽出する例</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">scala.collection.JavaConverters.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">org.nisshiee.crawler.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">org.nisshiee.crawler.jsoup.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">org.jsoup.nodes.</span><span class="pl-v">Document</span>
<span class="pl-k">import</span> <span class="pl-v">scalaz.</span><span class="pl-v">_, </span><span class="pl-v">Scalaz.</span><span class="pl-v">_</span>

<span class="pl-k">def</span> <span class="pl-en">links</span>(<span class="pl-v">url</span>: <span class="pl-k">String</span>)<span class="pl-k">:</span> <span class="pl-en">Fv</span>[<span class="pl-en">List</span>[<span class="pl-k">String</span>]] <span class="pl-k">=</span> <span class="pl-en">Crawler</span>(url) { <span class="pl-v">doc</span>: <span class="pl-en">Document</span> <span class="pl-k">=&gt;</span>
  doc.select(<span class="pl-s"><span class="pl-pds">"</span>a[href]<span class="pl-pds">"</span></span>).asScala.toList map { _.attr(<span class="pl-s"><span class="pl-pds">"</span>href<span class="pl-pds">"</span></span>) } successNel
}

<span class="pl-k">val</span> <span class="pl-en">f</span><span class="pl-k">:</span> <span class="pl-en">Fv</span>[<span class="pl-en">List</span>[<span class="pl-k">String</span>]] <span class="pl-k">=</span> (<span class="pl-k">for</span> {
  url1 <span class="pl-k">&lt;</span><span class="pl-k">-</span> <span class="pl-en">ListT</span>(links(<span class="pl-s"><span class="pl-pds">"</span>http://example.com<span class="pl-pds">"</span></span>))
  url2 <span class="pl-k">&lt;</span><span class="pl-k">-</span> <span class="pl-en">ListT</span>(links(url1))
} <span class="pl-k">yield</span> url2) underlying

f.result() <span class="pl-c"><span class="pl-c">//</span> =&gt; Success(List(...))</span>

<span class="pl-en">Crawler</span>.shutdown</pre>
  </div> 
  <h2><a id="user-content-license" class="anchor" href="https://github.com/nisshiee/async-crawler#license" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>License</h2> 
  <p>MIT</p> 
 </article>
</div>