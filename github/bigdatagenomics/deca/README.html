<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a id="user-content-deca-distributed-exome-cnv-analyzer" class="anchor" href="https://github.com/bigdatagenomics/deca#deca-distributed-exome-cnv-analyzer" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>DECA: Distributed Exome CNV Analyzer</h1> 
  <h1><a id="user-content-introduction" class="anchor" href="https://github.com/bigdatagenomics/deca#introduction" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Introduction</h1> 
  <p>DECA is a distributed re-implementation of the <a href="https://atgu.mgh.harvard.edu/xhmm/" target="_blank">XHMM</a> exome CNV caller using ADAM and Apache Spark.</p> 
  <h1><a id="user-content-getting-started" class="anchor" href="https://github.com/bigdatagenomics/deca#getting-started" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Getting Started</h1> 
  <h2><a id="user-content-installation" class="anchor" href="https://github.com/bigdatagenomics/deca#installation" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Installation</h2> 
  <p><strong>Note</strong>: These instructions are shared with other tools that build on <a href="https://github.com/bigdatagenomics/adam" target="_blank">ADAM</a>.</p> 
  <h3><a id="user-content-building-from-source" class="anchor" href="https://github.com/bigdatagenomics/deca#building-from-source" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Building from Source</h3> 
  <p>You will need to have <a href="http://maven.apache.org/" target="_blank">Maven</a> installed in order to build DECA.</p> 
  <blockquote> 
   <p><strong>Note:</strong> The default configuration is for Hadoop 2.7.3. If building against a different version of Hadoop, please edit the build configuration in the <code>&lt;properties&gt;</code> section of the <code>pom.xml</code> file.</p> 
  </blockquote> 
  <pre lang="dtd"><code>$ git clone https://github.com/.../deca.git
$ cd deca
$ export MAVEN_OPTS="-Xmx512m"
$ mvn clean package
</code></pre> 
  <h3><a id="user-content-installing-spark" class="anchor" href="https://github.com/bigdatagenomics/deca#installing-spark" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Installing Spark</h3> 
  <p>You'll need to have a Spark release on your system and the <code>$SPARK_HOME</code> environment variable pointing at it; prebuilt binaries can be downloaded from the <a href="http://spark.apache.org/downloads.html" target="_blank">Spark website</a>. DECA has been developed and tested with <a href="http://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz" target="_blank">Spark 2.1.0 built against Hadoop 2.7 with Scala 2.11</a>, but any more recent Spark distribution should likely work.</p> 
  <h2><a id="user-content-helpful-scripts" class="anchor" href="https://github.com/bigdatagenomics/deca#helpful-scripts" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Helpful Scripts</h2> 
  <p>The <code>bin/deca-submit</code> script wraps the <code>spark-submit</code> commands to set up and launch DECA.</p> 
  <h2><a id="user-content-commands" class="anchor" href="https://github.com/bigdatagenomics/deca#commands" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Commands</h2> 
  <pre lang="dtd"><code>$ deca-submit

Usage: deca-submit [&lt;spark-args&gt; --] &lt;deca-args&gt; [-version]

Choose one of the following commands:

             normalize : Normalize XHMM read-depth matrix
              coverage : Generate XHMM read depth matrix from read data
              discover : Call CNVs from normalized read matrix
normalize_and_discover : Normalize XHMM read-depth matrix and discover CNVs
                   cnv : Discover CNVs from raw read data

</code></pre> 
  <p>You can learn more about a command, by calling it without arguments or with <code>--help</code>, e.g.</p> 
  <pre lang="dtd"><code>$ deca-submit normalize_and_discover --help
 -I VAL                   : The XHMM read depth matrix
 -cnv_rate N              : CNV rate (p). Defaults to 1e-8.
 -exclude_targets STRING  : Path to file of targets (chr:start-end) to be excluded from analysis
 -fixed_pc_toremove INT   : Fixed number of principal components to remove if defined. Defaults to undefined.
 -h (-help, --help, -?)   : Print help
 -initial_k_fraction N    : Set initial k to fraction of max components. Defaults to 0.10.
 -max_sample_mean_RD N    : Maximum sample mean read depth prior to normalization. Defaults to 200.
 -max_sample_sd_RD N      : Maximum sample standard deviation of the read depth prior to normalization. Defaults to 150.
 -max_target_length N     : Maximum target length. Defaults to 10000.
 -max_target_mean_RD N    : Maximum target mean read depth prior to normalization. Defaults to 500.
 -max_target_sd_RD_star N : Maximum target standard deviation of the read depth after normalization. Defaults to 30.
 -mean_target_distance N  : Mean within-CNV target distance (D). Defaults to 70000.
 -mean_targets_cnv N      : Mean targets per CNV (T). Defaults to 6.
 -min_partitions INT      : Desired minimum number of partitions to be created when reading in XHMM matrix
 -min_sample_mean_RD N    : Minimum sample mean read depth prior to normalization. Defaults to 25.
 -min_some_quality N      : Min Q_SOME to discover a CNV. Defaults to 30.0.
 -min_target_length N     : Minimum target length. Defaults to 10.
 -min_target_mean_RD N    : Minimum target mean read depth prior to normalization. Defaults to 10.
 -o VAL                   : Path to write discovered CNVs as GFF3 file
 -print_metrics           : Print metrics to the log on completion
 -save_zscores STRING     : Path to write XHMM normalized, filtered, Z score matrix
 -zscore_threshold N      : Depth Z score threshold (M). Defaults to 3.
</code></pre> 
  <h2><a id="user-content-using-native-library-algebra-libraries" class="anchor" href="https://github.com/bigdatagenomics/deca#using-native-library-algebra-libraries" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Using native library algebra libraries</h2> 
  <p>Apache Spark includes the <a href="https://github.com/fommil/netlib-java" target="_blank">Netlib-Java</a> library for high-performance linear algebra. Netlib-Java can invoke optimized BLAS and Lapack system libraries if available; however, many Spark distributions are built without Netlib-Java system library support. You may be able to use system libraries by including the DECA jar on the Spark driver classpath, e.g.</p> 
  <pre lang="dtd"><code>deca-submit --driver-class-path $DECA_JAR ...
</code></pre> 
  <p>or you may need to rebuild Spark as described in the <a href="http://spark.apache.org/docs/2.1.0/ml-guide.html" target="_blank">Spark MLlib guide</a>.</p> 
  <p>If you see the following warning messages in the log file, you have not successfully invoked the system libraries:</p> 
  <pre lang="dtd"><code>WARN  BLAS:61 - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
WARN  BLAS:61 - Failed to load implementation from: com.github.fommil.neltlib.NativeRefARPACK
</code></pre> 
  <h1><a id="user-content-example-usage" class="anchor" href="https://github.com/bigdatagenomics/deca#example-usage" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Example Usage</h1> 
  <h2><a id="user-content-running-deca-in-stand-alone-mode-on-a-workstation" class="anchor" href="https://github.com/bigdatagenomics/deca#running-deca-in-stand-alone-mode-on-a-workstation" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Running DECA in "stand-alone" mode on a workstation</h2> 
  <p>A small dataset (30 samples by 300 targets) is distributed as part of the <a href="http://atgu.mgh.harvard.edu/xhmm/tutorial.shtml" target="_blank">XHMM tutorial</a>. Using <a href="http://atgu.mgh.harvard.edu/xhmm/RUN.zip" target="_blank">pre-computed read-depth matrix and related files</a> the DECA command to call CNVs (on a 16-core workstation with 128 GB RAM) is:</p> 
  <pre lang="dtd"><code>deca-submit \
--master local[16] \
--driver-class-path $DECA_JAR \
--conf spark.local.dir=/data/scratch/$USER \
--conf spark.driver.maxResultSize=0 \
--conf spark.kryo.registrationRequired=true \
--executor-memory 96G --driver-memory 16G \
-- normalize_and_discover \
-min_some_quality 29.5 \
-exclude_targets exclude_targets.txt \
-I DATA.RD.txt \
-o DECA.gff3
</code></pre> 
  <p>The resulting <a href="https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md" target="_blank">GFF3</a> file should contain</p> 
  <pre lang="dtd"><code>22      HG00121 DEL     18898402        18913235        9.167771318038923       .       .       END_TARGET=117;START_TARGET=104;Q_SOME=90;Q_START=8;Q_STOP=4;Q_EXACT=9;Q_NON_DIPLOID=90
22      HG00113 DUP     17071768        17073440        25.32122306047942       .       .       END_TARGET=11;START_TARGET=4;Q_SOME=99;Q_START=53;Q_STOP=25;Q_EXACT=25;Q_NON_DIPLOID=99
</code></pre> 
  <p>The <code>exlude_targets.txt</code> file is the unique combination of the <code>extreme_gc_targets.txt</code> and <code>low_complexity_targets.txt</code> files provided in the tutorial data. The <code>min_some_quality</code> parameter is set to 29.5 to mimic XHMM behavior which uses a default minimum SOME quality of 30 <em>after</em> rounding (while DECA applies the filter prior to rounding). Depending on your particular computing environment, you may need to modify the <a href="https://spark.apache.org/docs/latest/submitting-applications.html" target="_blank">spark-submit</a> <a href="https://spark.apache.org/docs/latest/configuration.html" target="_blank">configuration parameters</a>. <code>spark.driver.maxResultSize</code> is set to 0 (unlimited) to address errors collecting larger amounts of data to the driver.</p> 
  <p>The corresponding xcnv output from XHMM is:</p> 
  <pre lang="dtd"><code>SAMPLE  CNV     INTERVAL        KB      CHR     MID_BP  TARGETS NUM_TARG        Q_EXACT Q_SOME  Q_NON_DIPLOID   Q_START Q_STOP  MEAN_RD MEAN_ORIG_RD
HG00121 DEL     22:18898402-18913235    14.83   22      18905818        104..117        14      9       90      90      8       4       -2.51   37.99
HG00113 DUP     22:17071768-17073440    1.67    22      17072604        4..11   8       25      99      99      53      25      4.00    197.73
</code></pre> 
  <p>To call CNVs from the original <a href="http://atgu.mgh.harvard.edu/xhmm/EXAMPLE_BAMS.zip" target="_blank">BAM files</a>:</p> 
  <pre lang="dtd"><code>deca-submit \
--master local[16] \
--driver-class-path $DECA_JAR \
--conf spark.local.dir=/data/scratch/$USER \
--conf spark.driver.maxResultSize=0 \
--conf spark.kryo.registrationRequired=true \
--executor-memory 96G --driver-memory 16G \
-- coverage \
-L EXOME.interval_list \
-I *.bam 
-o DECA.RD.txt
</code></pre> 
  <p>followed by the <code>normalize_and_discovery</code> command above (with <code>DECA.RD.txt</code> as the input). DECA's coverage calculation is designed to match the output of the GATK DepthOfCoverage command specified in the XHMM protocol, i.e. count fragment depth with zero minimum base quality.</p> 
  <h2><a id="user-content-running-deca-on-a-yarn-cluster" class="anchor" href="https://github.com/bigdatagenomics/deca#running-deca-on-a-yarn-cluster" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Running DECA on a YARN cluster</h2> 
  <p>The equivalent example command to call CNVs on a YARN cluster with Spark dynamic allocation would be:</p> 
  <pre><code>deca-submit \
	--master yarn \
	--deploy-mode cluster \
	--num-executors 1 \
	--executor-memory 72G \
	--executor-cores 5 \
	--driver-memory 72G \
	--driver-cores 5 \
	--conf spark.driver.maxResultSize=0 \
	--conf spark.yarn.executor.memoryOverhead=4096 \
	--conf spark.yarn.driver.memoryOverhead=4096 \
	--conf spark.kryo.registrationRequired=true \
	--conf spark.hadoop.mapreduce.input.fileinputformat.split.minsize=$(( 8 * 1024 * 1024 )) \
	--conf spark.default.parallelism=10 \
	--conf spark.dynamicAllocation.enabled=true \
	-- normalize_and_discover \
	-min_partitions 10 \
	-exclude_targets &lt;path-to-exclude-file&gt; \
	-min_some_quality 29.5 \
	-I &lt;path-to-read-depth-matrix&gt; \
	-o &lt;path-to-save-cnv-calls&gt;
</code></pre> 
  <p>Note that many of the parameters above, e.g. driver and executor cores and memory, are specific to a particular cluster environment and would likely need to be modified for other environments.</p> 
  <h2><a id="user-content-running-deca-using-toil-on-a-workstation-or-aws" class="anchor" href="https://github.com/bigdatagenomics/deca#running-deca-using-toil-on-a-workstation-or-aws" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Running DECA using Toil on a workstation or AWS</h2> 
  <p>We provide <a href="http://www.ncbi.nlm.nih.gov/pubmed/28398314" target="_blank">Toil</a> workflows that allow DECA to be run either on a local computer or on a cluster on the Amazon Web Services (AWS) cloud. These workflows are written in Python and package DECA, Apache Spark, and Apache Hadoop using Docker containers. This packaging automates the setup of Apache Spark, reducing the barrier-to-entry for using DECA. To run either workflow, the user will need to <a href="http://toil.readthedocs.io/en/3.10.1/gettingStarted/install.html#basic-installation" target="_blank">install Toil</a>. To run the AWS workflow, the user will additionally need to follow the AWS setup instructions.</p> 
  <h3><a id="user-content-installing-the-deca-workflows" class="anchor" href="https://github.com/bigdatagenomics/deca#installing-the-deca-workflows" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Installing the DECA Workflows</h3> 
  <p>Once Toil has been installed, the user will need to download and install the <a href="https://github.com/bigdatagenomics/workflows" target="_blank">bdgenomics.workflows</a> package, which contains the DECA workflows. To install this package, run "make deploy":</p> 
  <pre><code>git clone https://github.com/bigdatagenomics/workflows
cd workflows
make develop
</code></pre> 
  <p>This step should be run inside of a Python virtualenv. If run locally, this step should be run inside of the same virtualenv that Toil was installed into. If run on AWS, this step should be run inside of a virtualenv that was created on the Toil AWS autoscaling cluster.</p> 
  <h3><a id="user-content-input-files" class="anchor" href="https://github.com/bigdatagenomics/deca#input-files" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Input Files</h3> 
  <p>The DECA workflow takes two inputs:</p> 
  <ol> 
   <li>A feature file that defines the regions over which to call copy number variants. This file can be formatted using any of the BED, GTF/GFF2, GFF3, Interval List, or NarrowPeak formats. In the AWS workflow, the ADAM Parquet Feature format is also supported.</li> 
   <li>A manifest file that contains paths to a set of sorted BAM files. Each file must have a scheme listed. In local mode, the file://, http://, and ftp:// schemes are supported. On AWS, the s3a://, http://, and ftp:// schemes are supported. S3a is an overlay over the AWS Simple Storage System (S3) cloud data store which is provided by Apache Hadoop.</li> 
  </ol> 
  <h3><a id="user-content-running-locally" class="anchor" href="https://github.com/bigdatagenomics/deca#running-locally" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Running Locally</h3> 
  <p>To run locally, we invoke the following command:</p> 
  <pre><code>bdg-deca \
  --targets &lt;regions&gt; \
  --samples &lt;manifest&gt; \
  --output-dir &lt;path-to-save&gt; \
  --memory &lt;memory-in-GB&gt; \
  --run-local \
  file:&lt;toil-jobstore-path&gt;
</code></pre> 
  <p>This command will run in Toil’s single machine mode, and will save the CNV calls to <code>&lt;path-to-save&gt;/cnvs.gff</code>. <code>&lt;toil-jobstore-path&gt;</code> is the path to a temporary directory where Toil will save intermediate files. The <code>&lt;memory-in-GB&gt;</code> parameter should be specified without units; e.g., to allocate 20GB of memory, pass "--memory 20".</p> 
  <h3><a id="user-content-running-on-aws" class="anchor" href="https://github.com/bigdatagenomics/deca#running-on-aws" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Running on AWS</h3> 
  <p>To run on AWS, we rely on Toil’s AWS provisioner, which starts a cluster on the AWS cloud. Toil’s AWS provisioner runs on top of <a href="https://mesos.apache.org" target="_blank">Apache Mesos</a> and supports dynamically scaling the number of nodes in the cluster to the amount of tasks being run. First, <a href="http://toil.readthedocs.io/en/3.10.1/running/amazon.html" target="_blank">create a Toil cluster on AWS</a>.</p> 
  <p>Once the Toil cluster has launched, SSH onto the cluster, following the instructions provided in the Toil/AWS documentation. To install bdgenomics.workflows, run:</p> 
  <pre><code>apt-get update
apt-get install git
git clone https://github.com/bigdatagenomics/workflows.git
cd workflows
virtualenv --system-site-packages venv
. venv/bin/activate
make develop
</code></pre> 
  <p>To run the DECA workflow, invoke the following command:</p> 
  <pre><code>bdg-deca \
  --targets &lt;regions&gt; \
  --samples &lt;manifest&gt; \
  --output-dir &lt;path-to-save&gt; \
  --memory &lt;memory-in-GB&gt; \
  --provisioner aws \
  --batchSystem mesos \
  --mesosMaster $(hostname -i):5050 \
  --nodeType &lt;type&gt; \
  --num-nodes &lt;spark-workers + 1&gt; \
  --minNodes &lt;spark-workers + 2&gt; \
  aws:&lt;region&gt;:&lt;toil-jobstore&gt;
</code></pre> 
  <p>Toil will launch a cluster with <code>spark-workers + 2</code> worker nodes to run this workflow. For optimal performance, we recommend choosing a number of Apache Spark worker nodes such that you have no less than 256MB of data per core. All file paths used in AWS mode must be files stored in AWS’s S3 storage system, and must have an s3a:// URI scheme.</p> 
  <h1><a id="user-content-license" class="anchor" href="https://github.com/bigdatagenomics/deca#license" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>License</h1> 
  <p>DECA is released under an <a href="https://github.com/bigdatagenomics/deca/blob/master/LICENSE.txt" target="_blank">Apache 2.0 license</a>.</p> 
 </article>
</div>