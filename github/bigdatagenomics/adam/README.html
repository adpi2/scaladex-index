<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a id="user-content-adam" class="anchor" href="https://github.com/bigdatagenomics/adam#adam" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>ADAM</h1> 
  <h1><a id="user-content-introduction" class="anchor" href="https://github.com/bigdatagenomics/adam#introduction" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Introduction</h1> 
  <p>ADAM is a genomics analysis platform with specialized file formats built using <a href="http://avro.apache.org" target="_blank">Apache Avro</a>, <a href="https://spark.apache.org/" target="_blank">Apache Spark</a> and <a href="https://parquet.apache.org/" target="_blank">Apache Parquet</a>. Apache 2 licensed. Some quick links: </p> 
  <ul> 
   <li><a href="https://twitter.com/bigdatagenomics/" target="_blank">Follow our Twitter account</a>.</li> 
   <li><a href="https://gitter.im/bigdatagenomics/adam" target="_blank">Chat with ADAM developers in Gitter</a>.</li> 
   <li><a href="http://bdgenomics.org/mail/" target="_blank">Join our mailing list</a>.</li> 
   <li><a href="https://amplab.cs.berkeley.edu/jenkins/view/Big%20Data%20Genomics/" target="_blank">Checkout the current build status</a>.</li> 
   <li><a href="https://github.com/bigdatagenomics/adam/releases" target="_blank">Download official releases</a>.</li> 
   <li><a href="http://search.maven.org/#search%7Cga%7C1%7Corg.bdgenomics" target="_blank">View our software artifacts on Maven Central</a> (<a href="https://oss.sonatype.org/index.html#nexus-search;quick%7Ebdgenomics" target="_blank">â€¦including snapshots</a>).</li> 
   <li><a href="https://github.com/bigdatagenomics/adam/blob/master/CHANGES.md" target="_blank">Look at our CHANGES file</a>.</li> 
  </ul> 
  <h2><a id="user-content-why-adam" class="anchor" href="https://github.com/bigdatagenomics/adam#why-adam" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Why ADAM?</h2> 
  <p>Over the last decade, DNA and RNA sequencing has evolved from an expensive, labor intensive method to a cheap commodity. The consequence of this is generation of <em>massive amounts of genomic and transcriptomic data</em>. Typically, tools to process and interpret these data are developed at academic labs, with a focus on excellence of the results generated, not on <strong>scalability</strong> and <strong>interoperability</strong>. A typical <em>sequencing pipeline</em> consists of a string of tools going from quality control, mapping, mapped read preprocessing, to variant calling or quantification, depending on the application at hand. Concretely, this usually means that such a pipeline is a string of tools, glued together by scripts or workflow engines, with data written to files in each step. This approach entails three main bottlenecks: </p> 
  <ol> 
   <li><strong>scaling the pipeline</strong> comes down to scaling each of the individual tools, </li> 
   <li>the <strong>stability of the pipeline</strong> heavily depends on the consistency of the intermediate file formats, and </li> 
   <li><strong>writing to and reading</strong> from disk is a major slow-down.</li> 
  </ol> 
  <p>We propose here a transformative solution for these problems, by replacing ad-hoc pipelines by the <a href="http://bdgenomics.org/" target="_blank">ADAM framework</a>, developed in the <a href="http://spark.apache.org/" target="_blank">Apache Spark</a> ecosystem. ADAM provides specialized file formats for the standard data structures used in genomics analysis: <em>mapped reads</em> (typically stored as <code>.bam</code> files), <em>representation of genomic regions</em> (<code>.bed</code> files), and <em>variants</em> (<code>.vcf</code> files), using <a href="https://avro.apache.org/" target="_blank">Avro</a> and <a href="http://parquet.apache.org/" target="_blank">Parquet</a>. This allows to use the in-memory cluster computing functionality of Apache Spark, ensuring efficient and fault-tolerant distribution based on data parallelism, without the intermediate disk operations required in classical distributed approaches.</p> 
  <p>Furthermore, the ADAM-Spark approach comes with an additional benefit. Typically, the endpoint of a sequencing pipeline is a file with processed data for a single sample: e.g. variants for DNA sequencing, read counts for RNA sequencing, etc. The real endpoint. however, of a sequencing experiment initiated by an investigator is <strong>interpretation</strong> of these data in a certain context. This usually translates into (statistical) analysis of multiple samples, connection with (clinical) metadata, interactive visualization, using data science tools such as R, Python, Tableau and Spotfire. In addition to scalable distributed processing, Spark also allows such <strong>interactive data analysis</strong> in the form of analysis notebooks (Spark Notebook or Zeppelin), or direct connection to the data in R and Python.</p> 
  <h2><a id="user-content-hello-world-counting-k-mers" class="anchor" href="https://github.com/bigdatagenomics/adam#hello-world-counting-k-mers" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Hello World: Counting K-mers</h2> 
  <p>Here's an example ADAM CLI command that will count 10-mers in <a href="https://github.com/bigdatagenomics/adam/blob/master/adam-core/src/test/resources/small.sam" target="_blank">a test <code>.sam</code> file that lives in this repository</a>:</p> 
  <div class="highlight highlight-source-shell">
   <pre>$ adam-submit count_kmers /tmp/small.adam /tmp/kmers.adam 10
$ head /tmp/kmers.adam/part-<span class="pl-k">*</span>
(AATTGGCACT,1)
(TTCCGATTTT,1)
(GAGCAGCCTT,1)
(CCTGCTGTAT,1)
(TTTTAAGGTT,1)
(GGCCAGGACT,1)
(GCAGTCCCTC,1)
(AACTTTGAAT,1)
(GATGACGTGG,1)
(CTGTCCCTGT,1)</pre>
  </div> 
  <h2><a id="user-content-more-than-k-mer-counting" class="anchor" href="https://github.com/bigdatagenomics/adam#more-than-k-mer-counting" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>More than K-mer Counting</h2> 
  <p>ADAM does much more than just k-mer counting. Running the ADAM CLI without arguments or with <code>--help</code> will display available commands, e.g.</p> 
  <pre><code>$ adam-submit

       e         888~-_          e             e    e
      d8b        888   \        d8b           d8b  d8b
     /Y88b       888    |      /Y88b         d888bdY88b
    /  Y88b      888    |     /  Y88b       / Y88Y Y888b
   /____Y88b     888   /     /____Y88b     /   YY   Y888b
  /      Y88b    888_-~     /      Y88b   /          Y888b

Usage: adam-submit [&lt;spark-args&gt; --] &lt;adam-args&gt;

Choose one of the following commands:

ADAM ACTIONS
               depth : Calculate the depth from a given ADAM file, at each variant in a VCF
         count_kmers : Counts the k-mers/q-mers from a read dataset.
  count_contig_kmers : Counts the k-mers/q-mers from a read dataset.
           transform : Convert SAM/BAM to ADAM format and optionally perform read pre-processing transformations
          adam2fastq : Convert BAM to FASTQ files
             flatten : Convert a ADAM format file to a version with a flattened schema, suitable for querying with tools like Impala
         mergeShards : Merges the shards of a file

CONVERSION OPERATIONS
            vcf2adam : Convert a VCF file to the corresponding ADAM format
            adam2vcf : Convert an ADAM variant to the VCF ADAM format
           anno2adam : Convert a annotation file (in VCF format) to the corresponding ADAM format
          fasta2adam : Converts a text FASTA sequence file into an ADAMNucleotideContig Parquet file which represents assembled sequences.
          adam2fasta : Convert ADAM nucleotide contig fragments to FASTA files
   transformFeatures : Convert a file with sequence features into corresponding ADAM format and vice versa
          wigfix2bed : Locally convert a wigFix file to BED format
     fragments2reads : Convert alignment records into fragment records.
     reads2fragments : Convert alignment records into fragment records.
      reads2coverage : Calculate the coverage from a given ADAM file

PRINT
               print : Print an ADAM formatted file
            flagstat : Print statistics on reads in an ADAM file (similar to samtools flagstat)
            listdict : Print the contents of an ADAM sequence dictionary
         allelecount : Calculate Allele frequencies
                view : View certain reads from an alignment-record file.
</code></pre> 
  <p>You can learn more about a command, by calling it without arguments or with <code>--help</code>, e.g.</p> 
  <pre><code>$ adam-submit transform --help
 INPUT                                                           : The ADAM, BAM or SAM file to apply the transforms to
 OUTPUT                                                          : Location to write the transformed data in ADAM/Parquet format
 -add_md_tags VAL                                                : Add MD Tags to reads based on the FASTA (or equivalent) file passed to this option.
 -aligned_read_predicate                                         : Only load aligned reads. Only works for Parquet files.
 -cache                                                          : Cache data to avoid recomputing between stages.
 -coalesce N                                                     : Set the number of partitions written to the ADAM output directory
 -concat VAL                                                     : Concatenate this file with &lt;INPUT&gt; and write the result to &lt;OUTPUT&gt;
 -defer_merging                                                  : Defers merging single file output
 -dump_observations VAL                                          : Local path to dump BQSR observations to. Outputs CSV format.
 -force_load_bam                                                 : Forces Transform to load from BAM/SAM.
 -force_load_fastq                                               : Forces Transform to load from unpaired FASTQ.
 -force_load_ifastq                                              : Forces Transform to load from interleaved FASTQ.
 -force_load_parquet                                             : Forces Transform to load from Parquet.
 -force_shuffle_coalesce                                         : Even if the repartitioned RDD has fewer partitions, force a shuffle.
 -h (-help, --help, -?)                                          : Print help
 -known_indels VAL                                               : VCF file including locations of known INDELs. If none is provided, default
                                                                   consensus model will be used.
 -known_snps VAL                                                 : Sites-only VCF giving location of known SNPs
 -limit_projection                                               : Only project necessary fields. Only works for Parquet files.
 -log_odds_threshold N                                           : The log-odds threshold for accepting a realignment. Default value is 5.0.
 -mark_duplicate_reads                                           : Mark duplicate reads
 -max_consensus_number N                                         : The maximum number of consensus to try realigning a target region to. Default
                                                                   value is 30.
 -max_indel_size N                                               : The maximum length of an INDEL to realign to. Default value is 500.
 -max_target_size N                                              : The maximum length of a target region to attempt realigning. Default length is
                                                                   3000.
 -md_tag_fragment_size N                                         : When adding MD tags to reads, load the reference in fragments of this size.
 -md_tag_overwrite                                               : When adding MD tags to reads, overwrite existing incorrect tags.
 -paired_fastq VAL                                               : When converting two (paired) FASTQ files to ADAM, pass the path to the second file
                                                                   here.
 -parquet_block_size N                                           : Parquet block size (default = 128mb)
 -parquet_compression_codec [UNCOMPRESSED | SNAPPY | GZIP | LZO] : Parquet compression codec
 -parquet_disable_dictionary                                     : Disable dictionary encoding
 -parquet_logging_level VAL                                      : Parquet logging level (default = severe)
 -parquet_page_size N                                            : Parquet page size (default = 1mb)
 -print_metrics                                                  : Print metrics to the log on completion
 -realign_indels                                                 : Locally realign indels present in reads.
 -recalibrate_base_qualities                                     : Recalibrate the base quality scores (ILLUMINA only)
 -record_group VAL                                               : Set converted FASTQs' record-group names to this value; if empty-string is passed,
                                                                   use the basename of the input file, minus the extension.
 -repartition N                                                  : Set the number of partitions to map data to
 -single                                                         : Saves OUTPUT as single file
 -sort_fastq_output                                              : Sets whether to sort the FASTQ output, if saving as FASTQ. False by default.
                                                                   Ignored if not saving as FASTQ.
 -sort_lexicographically                                         : Sort the reads lexicographically by contig name, instead of by index.
 -sort_reads                                                     : Sort the reads by referenceId and read position
 -storage_level VAL                                              : Set the storage level to use for caching.
 -stringency VAL                                                 : Stringency level for various checks; can be SILENT, LENIENT, or STRICT. Defaults
                                                                   to LENIENT
</code></pre> 
  <p>The ADAM <code>transform</code> command allows you to mark duplicates, run base quality score recalibration (BQSR) and other pre-processing steps on your data.</p> 
  <h1><a id="user-content-getting-started" class="anchor" href="https://github.com/bigdatagenomics/adam#getting-started" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Getting Started</h1> 
  <h2><a id="user-content-installation" class="anchor" href="https://github.com/bigdatagenomics/adam#installation" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Installation</h2> 
  <h3><a id="user-content-binary-distributions" class="anchor" href="https://github.com/bigdatagenomics/adam#binary-distributions" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Binary Distributions</h3> 
  <p>Bundled release binaries can be found on our <a href="https://github.com/bigdatagenomics/adam/releases" target="_blank">releases</a> page.</p> 
  <h3><a id="user-content-building-from-source" class="anchor" href="https://github.com/bigdatagenomics/adam#building-from-source" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Building from Source</h3> 
  <p>You will need to have <a href="http://maven.apache.org/" target="_blank">Maven</a> installed in order to build ADAM.</p> 
  <blockquote> 
   <p><strong>Note:</strong> The default configuration is for Hadoop 2.6.0. If building against a different version of Hadoop, please edit the build configuration in the <code>&lt;properties&gt;</code> section of the <code>pom.xml</code> file.</p> 
  </blockquote> 
  <pre><code>$ git clone https://github.com/bigdatagenomics/adam.git
$ cd adam
$ export MAVEN_OPTS="-Xmx512m -XX:MaxPermSize=256m"
$ mvn clean package -DskipTests
...
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 9.647s
[INFO] Finished at: Thu May 23 15:50:42 PDT 2013
[INFO] Final Memory: 19M/81M
[INFO] ------------------------------------------------------------------------
</code></pre> 
  <p>You might want to take a peek at the <code>scripts/jenkins-test</code> script and give it a run. It will fetch a mouse chromosome, encode it to ADAM reads and pileups, run flagstat, etc. We use this script to test that ADAM is working correctly.</p> 
  <h3><a id="user-content-installing-spark" class="anchor" href="https://github.com/bigdatagenomics/adam#installing-spark" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Installing Spark</h3> 
  <p>You'll need to have a Spark release on your system and the <code>$SPARK_HOME</code> environment variable pointing at it; prebuilt binaries can be downloaded from the <a href="http://spark.apache.org/downloads.html" target="_blank">Spark website</a>. Currently, our continuous builds default to <a href="http://d3kbcqa49mib13.cloudfront.net/spark-1.6.1-bin-hadoop2.6.tgz" target="_blank">Spark 1.6.1 built against Hadoop 2.6</a>, but any more recent Spark distribution should also work.</p> 
  <h3><a id="user-content-helpful-aliases" class="anchor" href="https://github.com/bigdatagenomics/adam#helpful-aliases" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Helpful Aliases</h3> 
  <p>You might want to add the following to your <code>.bashrc</code> to make running ADAM easier:</p> 
  <pre><code>alias adam-submit="${ADAM_HOME}/bin/adam-submit"
alias adam-shell="${ADAM_HOME}/bin/adam-shell"
</code></pre> 
  <p><code>$ADAM_HOME</code> should be the path to a <a href="https://github.com/bigdatagenomics/adam/releases" target="_blank">binary release</a> or a clone of this repository on your local filesystem. </p> 
  <p>These aliases call scripts that wrap the <code>spark-submit</code> and <code>spark-shell</code> commands to set up ADAM.Once they are in place, you can run adam by simply typing <code>adam-submit</code> at the command line, <a href="https://github.com/bigdatagenomics/adam/blob/master/README.md#more-than-k-mer-counting" target="_blank">as demonstrated above</a>.</p> 
  <h2><a id="user-content-running-adam" class="anchor" href="https://github.com/bigdatagenomics/adam#running-adam" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Running ADAM</h2> 
  <p>Now you can try running some simple ADAM commands:</p> 
  <h3><a id="user-content-transform" class="anchor" href="https://github.com/bigdatagenomics/adam#transform" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a><code>transform</code></h3> 
  <p>Make your first <code>.adam</code> file like this:</p> 
  <pre><code>adam-submit transform $ADAM_HOME/adam-core/src/test/resources/small.sam /tmp/small.adam
</code></pre> 
  <p>If you didn't obtain your copy of adam from github, you can <a href="https://raw.githubusercontent.com/bigdatagenomics/adam/master/adam-core/src/test/resources/small.sam" target="_blank">grab <code>small.sam</code> here</a>.</p> 
  <h3><a id="user-content-flagstat" class="anchor" href="https://github.com/bigdatagenomics/adam#flagstat" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a><code>flagstat</code></h3> 
  <p>Once you have data converted to ADAM, you can gather statistics from the ADAM file using <code>flagstat</code>. This command will output stats identically to the samtools <code>flagstat</code> command.</p> 
  <p>If you followed along above, now try gathering some statistics:</p> 
  <pre><code>$ adam-submit flagstat /tmp/small.adam
20 + 0 in total (QC-passed reads + QC-failed reads)
0 + 0 primary duplicates
0 + 0 primary duplicates - both read and mate mapped
0 + 0 primary duplicates - only read mapped
0 + 0 primary duplicates - cross chromosome
0 + 0 secondary duplicates
0 + 0 secondary duplicates - both read and mate mapped
0 + 0 secondary duplicates - only read mapped
0 + 0 secondary duplicates - cross chromosome
20 + 0 mapped (100.00%:0.00%)
0 + 0 paired in sequencing
0 + 0 read1
0 + 0 read2
0 + 0 properly paired (0.00%:0.00%)
0 + 0 with itself and mate mapped
0 + 0 singletons (0.00%:0.00%)
0 + 0 with mate mapped to a different chr
0 + 0 with mate mapped to a different chr (mapQ&gt;=5)
</code></pre> 
  <p>In practice, you'll find that the ADAM <code>flagstat</code> command takes orders of magnitude less time than samtools to compute these statistics. For example, on a MacBook Pro <code>flagstat NA12878_chr20.bam</code> took 17 seconds to run while <code>samtools flagstat NA12878_chr20.bam</code> took 55 seconds. On larger files, the difference in speed is even more dramatic. ADAM is faster because it's multi-threaded and distributed and uses a columnar storage format (with a projected schema that only materializes the read flags instead of the whole read). </p> 
  <h3><a id="user-content-adam-shell" class="anchor" href="https://github.com/bigdatagenomics/adam#adam-shell" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a><code>adam-shell</code></h3> 
  <p>The <code>adam-shell</code> command opens an interpreter that you can run ad-hoc ADAM commands in.</p> 
  <p>For example, the following code snippet will generate a result similar to <a href="https://github.com/bigdatagenomics/adam/blob/master/README.md#hello-world-counting-k-mers" target="_blank">the k-mer-counting example above</a>, but with the k-mers sorted in descending order of their number of occurrences. To use this, save the code snippet as <code>kmer.scala</code> and run <code>adam-shell -i kmer.scala</code>.</p> 
  <p><code>kmer.scala</code></p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">org.bdgenomics.adam.rdd.ADAMContext.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">org.bdgenomics.adam.projections.</span>{ <span class="pl-v">AlignmentRecordField</span>, <span class="pl-v">Projection</span> }

<span class="pl-c">// Load alignments from disk</span>
<span class="pl-k">val</span> <span class="pl-en">reads</span> <span class="pl-k">=</span> sc.loadAlignments(
  <span class="pl-s"><span class="pl-pds">"</span>/data/NA21144.chrom11.ILLUMINA.adam<span class="pl-pds">"</span></span>,
  projection <span class="pl-k">=</span> <span class="pl-en">Some</span>(
    <span class="pl-en">Projection</span>(
      <span class="pl-en">AlignmentRecordField</span>.sequence,
      <span class="pl-en">AlignmentRecordField</span>.readMapped,
      <span class="pl-en">AlignmentRecordField</span>.mapq
    )
  )
)

<span class="pl-c">// Generate, count and sort 21-mers</span>
<span class="pl-k">val</span> <span class="pl-en">kmers</span> <span class="pl-k">=</span>
  reads
    .rdd
    .flatMap(_.getSequence.sliding(<span class="pl-c1">21</span>).map(k <span class="pl-k">=&gt;</span> (k, <span class="pl-c1">1L</span>)))
    .reduceByKey(_ <span class="pl-k">+</span> _)
    .map(_.swap)
    .sortByKey(ascending <span class="pl-k">=</span> <span class="pl-c1">false</span>)

<span class="pl-c">// Print the top 10 most common 21-mers</span>
kmers.take(<span class="pl-c1">10</span>).foreach(println)</pre>
  </div> 
  <p><code>adam-shell -i kmer.scala</code></p> 
  <pre><code>$ adam-shell -i kmer.scala
â€¦
(121771,TTTTTTTTTTTTTTTTTTTTT)
(44317,ACACACACACACACACACACA)
(44023,TGTGTGTGTGTGTGTGTGTGT)
(42474,CACACACACACACACACACAC)
(42095,GTGTGTGTGTGTGTGTGTGTG)
(33797,TAATCCCAGCACTTTGGGAGG)
(33081,AATCCCAGCACTTTGGGAGGC)
(32775,TGTAATCCCAGCACTTTGGGA)
(32484,CCTCCCAAAGTGCTGGGATTA)
â€¦
</code></pre> 
  <h1><a id="user-content-running-on-a-cluster" class="anchor" href="https://github.com/bigdatagenomics/adam#running-on-a-cluster" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Running on a cluster</h1> 
  <p>The <code>adam-submit</code> and <code>adam-shell</code> commands can also be used to submit ADAM jobs to a Spark cluster, or to run ADAM interactively. Cluster mode can be enabled by passing <a href="https://spark.apache.org/docs/1.5.2/submitting-applications.html#launching-applications-with-spark-submit" target="_blank">the same flags you'd pass to Spark</a>, e.g. <code>--master yarn --deploy-mode client</code>.</p> 
  <h1><a id="user-content-under-the-hood" class="anchor" href="https://github.com/bigdatagenomics/adam#under-the-hood" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Under the Hood</h1> 
  <p>ADAM relies on several open-source technologies to make genomic analyses fast and massively parallelizableâ€¦</p> 
  <h2><a id="user-content-apache-spark" class="anchor" href="https://github.com/bigdatagenomics/adam#apache-spark" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Apache Spark</h2> 
  <p><a href="https://spark.apache.org/" target="_blank">Apache Spark</a> allows developers to write algorithms in succinct code that can run fast locally, on an in-house cluster or on Amazon, Google or Microsoft clouds. </p> 
  <h2><a id="user-content-apache-parquet" class="anchor" href="https://github.com/bigdatagenomics/adam#apache-parquet" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Apache Parquet</h2> 
  <p><a href="https://parquet.apache.org/" target="_blank">Apache Parquet</a> is a columnar storage format available to any project in the Hadoop ecosystem, regardless of the choice of data processing framework, data model or programming language.</p> 
  <ul> 
   <li>Parquet compresses legacy genomic formats using standard columnar techniques (e.g. RLE, dictionary encoding). ADAM files are typically ~20% smaller than compressed BAM files.</li> 
   <li>Parquet integrates with: 
    <ul> 
     <li><strong>Query engines</strong>: Hive, Impala, HAWQ, IBM Big SQL, Drill, Tajo, Pig, Presto</li> 
     <li><strong>Frameworks</strong>: Spark, MapReduce, Cascading, Crunch, Scalding, Kite</li> 
     <li><strong>Data models</strong>: Avro, Thrift, ProtocolBuffers, POJOs</li> 
    </ul></li> 
   <li>Parquet is simply a file format which makes it easy to sync and share data using tools like <code>distcp</code>, <code>rsync</code>, etc</li> 
   <li>Parquet provides a command-line tool, <code>parquet.hadoop.PrintFooter</code>, which reports useful compression statistics </li> 
  </ul> 
  <p>In the counting k-mers example above, you can see there is a defined <em>predicate</em> and <em>projection</em>. The <em>predicate</em> allows rapid filtering of rows while a <em>projection</em> allows you to efficiently materialize only specific columns for analysis. For this k-mer counting example, we filter out any records that are not mapped or have a <code>MAPQ</code> less than 20 using a <code>predicate</code> and only materialize the <code>Sequence</code>, <code>ReadMapped</code> flag and <code>MAPQ</code> columns and skip over all other fields like <code>Reference</code> or <code>Start</code> position, e.g.</p> 
  <table>
   <thead> 
    <tr> 
     <th>Sequence</th> 
     <th>ReadMapped</th> 
     <th>MAPQ</th> 
     <th><del>Reference</del></th> 
     <th><del>Start</del></th> 
     <th>...</th> 
    </tr> 
   </thead>
   <tbody> 
    <tr> 
     <td><del>GGTCCAT</del></td> 
     <td><del>false</del></td> 
     <td>-</td> 
     <td><del>chrom1</del></td> 
     <td>-</td> 
     <td>...</td> 
    </tr> 
    <tr> 
     <td>TACTGAA</td> 
     <td>true</td> 
     <td>30</td> 
     <td><del>chrom1</del></td> 
     <td><del>34232</del></td> 
     <td>...</td> 
    </tr> 
    <tr> 
     <td><del>TTGAATG</del></td> 
     <td><del>true</del></td> 
     <td><del>17</del></td> 
     <td><del>chrom1</del></td> 
     <td><del>309403</del></td> 
     <td>...</td> 
    </tr> 
   </tbody>
  </table> 
  <h2><a id="user-content-apache-avro" class="anchor" href="https://github.com/bigdatagenomics/adam#apache-avro" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Apache Avro</h2> 
  <ul> 
   <li><a href="http://avro.apache.org" target="_blank">Apache Avro</a> is a data serialization system.</li> 
   <li>All Big Data Genomics schemas are published at <a href="https://github.com/bigdatagenomics/bdg-formats" target="_blank">https://github.com/bigdatagenomics/bdg-formats</a>.</li> 
   <li>Having explicit schemas and self-describing data makes integrating, sharing and evolving formats easier.</li> 
  </ul> 
  <p>Our Avro schemas are directly converted into source code using Avro tools. Avro supports a number of computer languages. ADAM uses Java; you could just as easily use this Avro IDL description as the basis for a Python project. Avro currently supports c, c++, csharp, java, javascript, php, python and ruby. </p> 
  <h1><a id="user-content-downstream-applications" class="anchor" href="https://github.com/bigdatagenomics/adam#downstream-applications" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Downstream Applications</h1> 
  <p>There are a number of projects built on ADAM, e.g.</p> 
  <ul> 
   <li><a href="https://github.com/bigdatagenomics/rice" target="_blank">RNAdam</a> provides an RNA pipeline on top of ADAM with isoform quantification and fusion transcription detection</li> 
   <li><a href="https://github.com/bigdatagenomics/avocado" target="_blank">Avocado</a> is a variant caller built on top of ADAM for germline and somatic calling</li> 
   <li><a href="https://github.com/bigdatagenomics/PacMin" target="_blank">PacMin</a> is an assembler for PacBio reads</li> 
   <li>A <code>Mutect</code> port is nearly feature complete</li> 
   <li>Read error correction</li> 
   <li>a graphing and genome visualization library</li> 
   <li><a href="https://github.com/bigdatagenomics/bdg-services" target="_blank">BDG-Services</a> is a library for accessing a running Spark cluster through web-services or a <a href="https://thrift.apache.org/" target="_blank">Thrift</a>- interface</li> 
   <li><a href="https://github.com/fnothaft/xASSEMBLEx" target="_blank">Short read assembly</a></li> 
   <li>Variant filtration (train model via <code>MLlib</code>)</li> 
  </ul> 
  <h1><a id="user-content-license" class="anchor" href="https://github.com/bigdatagenomics/adam#license" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>License</h1> 
  <p>ADAM is released under an <a href="https://github.com/bigdatagenomics/adam/blob/master/LICENSE.txt" target="_blank">Apache 2.0 license</a>.</p> 
 </article>
</div>