<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <p>#Description This is a simple sbt plugin, which will simplify your life to submit your spark code. By filling the --jar option of the spark-submit command.</p> 
  <p>#Usage In your build.sbt specifty your sparkHome directory</p> 
  <pre><code>sparkHome := "/toto/titi"
</code></pre> 
  <p>warn : This spark home will not set your other 'sparkHome' env ( maybe in a next version )</p> 
  <p>In your plugin.sbt add the plugin</p> 
  <pre><code>addSbtPlugin("com.github.crakjie" % "sbt-spark-plugin" % "1.1.0")
</code></pre> 
  <p>Execute the submit command.</p> 
  <pre><code>sbt clean package submit
</code></pre> 
  <h2><a id="user-content-params" class="anchor" href="https://github.com/crakjie/sbt-spark-plugin#params" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Params</h2> 
  <p>You can add others submit params by setting directly</p> 
  <pre><code>submitOptions := "--master local[8]  --executor-memory 20G --verbose --conf 'spark.executor.extraJavaOptions=-XX:+PrintGCDetails -XX:+PrintGCTimeStamps'"
</code></pre> 
  <p>#See your submit cmd If you ever want to see your command submit</p> 
  <pre><code>logLevel := Level.Debug
submitLogLevel := Level.Debug
</code></pre> 
  <p>#Send params to your spark program. Give params space separated. And they will be usable from your main args array.</p> 
  <pre><code>sbt package "submit &lt;arg1&gt; &lt;arg2&gt;"
</code></pre> 
  <p>#Why it's good This plugin use the command spark-submit without making an Ã¼ber jar, witch is relatively fastest.</p> 
  <p>#Why it's could be better Because the plugin push all your classpath . But however it's still faster than create an assambly.</p> 
  <p>#How it's work</p> 
  <p>The plugin will fill the --jar option of spark-submit with the class path generated by sbt.</p> 
  <p>#Send param to you main.</p> 
  <pre><code>sbt package "submit arg1 arg2"
</code></pre> 
  <p>#Spark 2 In spark package jars are not lib but in jars directory. Sbt load lib directory by default you can fallow this <a href="http://www.scala-sbt.org/1.0/docs/Library-Dependencies.html#Unmanaged+dependencies" target="_blank">http://www.scala-sbt.org/1.0/docs/Library-Dependencies.html#Unmanaged+dependencies</a> or copy the content of the jars directory in lib. Warning Unmanaged dependencies have precedence over managed dependencies so be carefull if you are using the same lib than spark, for exemple guava.</p> 
 </article>
</div>