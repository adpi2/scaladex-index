<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <p><a href="https://travis-ci.org/clulab/processors" target="_blank"><img src="https://camo.githubusercontent.com/e7c07f6a0283bee30b159c661464659fce631fcd/68747470733a2f2f7472617669732d63692e6f72672f636c756c61622f70726f636573736f72732e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/clulab/processors.svg?branch=master" style="max-width:100%;"></a></p> 
  <h1><a href="https://github.com/clulab/processors#what-is-it" aria-hidden="true" class="anchor" id="user-content-what-is-it" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>What is it?</h1> 
  <p>This is the main public code repository of the Computational Language Understanding (CLU) Lab led by <a href="http://surdeanu.info/mihai/" target="_blank">Mihai Surdeanu</a> at <a href="http://www.arizona.edu" target="_blank">University of Arizona</a>. This repository contains (in descending order of novelty):</p> 
  <ul> 
   <li>A rule-based event extraction (EE) framework called Odin (Open Domain INformer) in the <code>org.clulab.odin</code> package. See <a href="https://github.com/clulab/processors/wiki/ODIN-(Open-Domain-INformer)" target="_blank">Odin's Wiki page</a> for more details.</li> 
   <li>Two full-fledged Rhetorical Structure Theory (RST) discourse parsers. The discourse parsers are transparently included in our natural language (NL) processors (see below). The version in <code>CoreNLPProcessor</code> relies on constituent syntax, whereas the one in <code>FastNLPProcessor</code> uses dependency syntax. They perform approximately the same, but the latter is much faster.</li> 
   <li>A machine learning (ML) package (<code>org.clulab.learning</code>), which includes implementations for common ML algorithms (e.g., Perceptron, Logistic Regression, Support Vector Machines, Random Forests) for both classification and ranking.</li> 
   <li>A suite of NL processors in the <code>org.clulab.processors</code> package. We currently provide the following APIs: 
    <ul> 
     <li><code>CoreNLPProcessor</code> - a wrapper for <a href="http://nlp.stanford.edu/software/corenlp.shtml" target="_blank">Stanford's CoreNLP</a>, using its constituent parser;</li> 
     <li><code>FastNLPProcessor</code> - a wrapper for Stanford's CoreNLP, but using its neural-network dependency parser;</li> 
     <li><code>BioNLPProcessor</code> - a version of <code>CoreNLPProcessor</code> tuned for the biomedical domain: better tokenization for biomedical texts, improved POS tagging for the bio domain, and a custom NER for this domain that recognizes entities relevant in this domain such as proteins, chemical, and biological processes;</li> 
     <li><code>FastBioNLPProcessor</code> - a version of <code>FastNLPProcessor</code> tuned for the biomedical domain, similarly to <code>BioNLPProcessor</code>;</li> 
     <li><code>CluProcessor</code> - an in-house processor (licensed under the Apache license) that contains: tokenization (using <a href="http://www.antlr.org" target="_blank">Antlr</a>), lemmatization (using <a href="https://search.maven.org/#artifactdetails%7Cedu.washington.cs.knowitall.nlptools%7Cnlptools-stem-morpha_2.10%7C2.4.5%7Cjar" target="_blank">MorphaStemmer</a>), POS tagging (using an in-house bidirectional maximum entropy Markov model), and syntax (using an ensemble of models built with <a href="http://mallet.cs.umass.edu" target="_blank">maltparser</a>), which supports both basic and enhanced dependencies. Performance is comparable to <code>FastNLPProcessor</code>, under a more permissive license. Additionally, the memory footprint of <code>CluProcessor</code> is smaller than that of <code>FastNLPProcessor</code>, so it may be more appropriate for older machines.</li> 
     <li><code>BioCluProcessor</code> - a version of <code>CluProcessor</code> tuned for the biomedical domain.</li> 
    </ul> </li> 
  </ul> 
  <p>This software requires Java 1.8, Scala 2.11, and CoreNLP 3.x or higher.</p> 
  <p>Our code is licensed as follows:</p> 
  <ul> 
   <li><strong><code>main, odin, modelsmain</code></strong> - Apache License Version 2.0. Please note that these subprojects do not interact with the <code>corenlp</code> subproject below.</li> 
   <li><strong><code>corenlp, modelscorenlp</code></strong> - GLP Version 3 or higher, due to the dependency on <a href="http://stanfordnlp.github.io/CoreNLP/" target="_blank">Stanford's CoreNLP</a>. If you use only <code>CluProcessor</code>, these dependencies do not have to be included in your project.</li> 
  </ul> 
  <p>(c) Mihai Surdeanu, 2013 -</p> 
  <p>Authors: <a href="http://surdeanu.info/mihai/" target="_blank">Mihai Surdeanu</a>, <a href="https://github.com/marcovzla" target="_blank">Marco Valenzuela</a>, <a href="https://github.com/myedibleenso" target="_blank">Gustave Hahn-Powell</a>, Peter Jansen, <a href="http://www.cs.arizona.edu/%7Edfried/" target="_blank">Daniel Fried</a>, Dane Bell, and Tom Hicks.</p> 
  <h1><a href="https://github.com/clulab/processors#changes" aria-hidden="true" class="anchor" id="user-content-changes" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Changes</h1> 
  <ul> 
   <li><a href="https://github.com/clulab/processors/blob/master/CHANGES.md" target="_blank">Please see the CHANGES file</a></li> 
  </ul> 
  <h1><a href="https://github.com/clulab/processors#citations" aria-hidden="true" class="anchor" id="user-content-citations" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Citations</h1> 
  <p>If you use one of our discourse parsers, please cite this paper:</p> 
  <p>Mihai Surdeanu, Thomas Hicks, and Marco A. Valenzuela-Escarcega. Two Practical Rhetorical Structure Theory Parsers. In <em>Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies: Software Demonstrations (NAACL HLT)</em>, 2015. <a href="http://surdeanu.info/mihai/papers/naacl2015-discourse.pdf" target="_blank">[pdf]</a> <a href="http://surdeanu.info/mihai/papers/naacl2015-discourse.bib" target="_blank">[bib]</a></p> 
  <p>If you use Odin, our event extraction framework, please cite this paper:</p> 
  <p>Marco A. Valenzuela-Escarcega, Gustave Hahn-Powell, Thomas Hicks, and Mihai Surdeanu. A Domain-independent Rule-based Framework for Event Extraction. In <em>Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing: Software Demonstrations (ACL-IJCNLP)</em>, 2015. <a href="http://surdeanu.info/mihai/papers/acl2015.pdf" target="_blank">[pdf]</a> <a href="http://surdeanu.info/mihai/papers/acl2015.bib" target="_blank">[bib]</a></p> 
  <p>If you use <code>CoreNLPProcessor</code>, please cite Stanford's paper:</p> 
  <p>Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J. Bethard, and David McClosky. The Stanford CoreNLP Natural Language Processing Toolkit. In <em>Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2014. <a href="http://surdeanu.info/mihai/papers/acl2014-corenlp.pdf" target="_blank">[pdf]</a> <a href="http://surdeanu.info/mihai/papers/acl2014-corenlp.bib" target="_blank">[bib]</a></p> 
  <p>If you use <code>CluProcessor</code>, please cite this paper:</p> 
  <p>Mihai Surdeanu and Christopher D. Manning. Ensemble Models for Dependency Parsing: Cheap and Good? In <em>Proceedings of the North American Chapter of the Association for Computational Linguistics Conference (NAACL-2010)</em>, 2010. <a href="http://surdeanu.info/mihai/papers/naacl10-parsing.pdf" target="_blank">[pdf]</a> <a href="http://surdeanu.info/mihai/papers/naacl10-parsing-surdeanu.bib" target="_blank">[bib]</a></p> 
  <p>If you use anything else in this package, please link to this github page.</p> 
  <h1><a href="https://github.com/clulab/processors#installation" aria-hidden="true" class="anchor" id="user-content-installation" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Installation</h1> 
  <p>This software is available on Maven Central. To use, simply add the following dependencies to your <code>pom.xml</code>:</p> 
  <div class="highlight highlight-text-xml">
   <pre>&lt;<span class="pl-ent">dependency</span>&gt;
   &lt;<span class="pl-ent">groupId</span>&gt;org.clulab&lt;/<span class="pl-ent">groupId</span>&gt;
   &lt;<span class="pl-ent">artifactId</span>&gt;processors-corenlp_2.11&lt;/<span class="pl-ent">artifactId</span>&gt;
   &lt;<span class="pl-ent">version</span>&gt;6.1.3&lt;/<span class="pl-ent">version</span>&gt;
&lt;/<span class="pl-ent">dependency</span>&gt;
&lt;<span class="pl-ent">dependency</span>&gt;
   &lt;<span class="pl-ent">groupId</span>&gt;org.clulab&lt;/<span class="pl-ent">groupId</span>&gt;
   &lt;<span class="pl-ent">artifactId</span>&gt;processors-main_2.11&lt;/<span class="pl-ent">artifactId</span>&gt;
   &lt;<span class="pl-ent">version</span>&gt;6.1.3&lt;/<span class="pl-ent">version</span>&gt;
&lt;/<span class="pl-ent">dependency</span>&gt;
&lt;<span class="pl-ent">dependency</span>&gt;
   &lt;<span class="pl-ent">groupId</span>&gt;org.clulab&lt;/<span class="pl-ent">groupId</span>&gt;
   &lt;<span class="pl-ent">artifactId</span>&gt;processors-odin_2.11&lt;/<span class="pl-ent">artifactId</span>&gt;
   &lt;<span class="pl-ent">version</span>&gt;6.1.3&lt;/<span class="pl-ent">version</span>&gt;
&lt;/<span class="pl-ent">dependency</span>&gt;
&lt;<span class="pl-ent">dependency</span>&gt;
   &lt;<span class="pl-ent">groupId</span>&gt;org.clulab&lt;/<span class="pl-ent">groupId</span>&gt;
   &lt;<span class="pl-ent">artifactId</span>&gt;processors-modelsmain_2.11&lt;/<span class="pl-ent">artifactId</span>&gt;
   &lt;<span class="pl-ent">version</span>&gt;6.1.3&lt;/<span class="pl-ent">version</span>&gt;
&lt;/<span class="pl-ent">dependency</span>&gt;
&lt;<span class="pl-ent">dependency</span>&gt;
   &lt;<span class="pl-ent">groupId</span>&gt;org.clulab&lt;/<span class="pl-ent">groupId</span>&gt;
   &lt;<span class="pl-ent">artifactId</span>&gt;processors-modelscorenlp_2.11&lt;/<span class="pl-ent">artifactId</span>&gt;
   &lt;<span class="pl-ent">version</span>&gt;6.1.3&lt;/<span class="pl-ent">version</span>&gt;
&lt;/<span class="pl-ent">dependency</span>&gt;
</pre>
  </div> 
  <p>The equivalent SBT dependencies are:</p> 
  <div class="highlight highlight-source-scala">
   <pre>libraryDependencies <span class="pl-k">++</span><span class="pl-k">=</span> {
  <span class="pl-k">val</span> <span class="pl-en">procVer</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>6.1.3<span class="pl-pds">"</span></span>

  <span class="pl-en">Seq</span>(
    <span class="pl-s"><span class="pl-pds">"</span>org.clulab<span class="pl-pds">"</span></span> <span class="pl-k">%%</span> <span class="pl-s"><span class="pl-pds">"</span>processors-main<span class="pl-pds">"</span></span> <span class="pl-k">%</span> procVer,
    <span class="pl-s"><span class="pl-pds">"</span>org.clulab<span class="pl-pds">"</span></span> <span class="pl-k">%%</span> <span class="pl-s"><span class="pl-pds">"</span>processors-corenlp<span class="pl-pds">"</span></span> <span class="pl-k">%</span> procVer,
    <span class="pl-s"><span class="pl-pds">"</span>org.clulab<span class="pl-pds">"</span></span> <span class="pl-k">%%</span> <span class="pl-s"><span class="pl-pds">"</span>processors-odin<span class="pl-pds">"</span></span> <span class="pl-k">%</span> procVer,
    <span class="pl-s"><span class="pl-pds">"</span>org.clulab<span class="pl-pds">"</span></span> <span class="pl-k">%%</span> <span class="pl-s"><span class="pl-pds">"</span>processors-modelsmain<span class="pl-pds">"</span></span> <span class="pl-k">%</span> procVer,
    <span class="pl-s"><span class="pl-pds">"</span>org.clulab<span class="pl-pds">"</span></span> <span class="pl-k">%%</span> <span class="pl-s"><span class="pl-pds">"</span>processors-modelscorenlp<span class="pl-pds">"</span></span> <span class="pl-k">%</span> procVer,
  )
}</pre>
  </div> 
  <h1><a href="https://github.com/clulab/processors#external-dependencies" aria-hidden="true" class="anchor" id="user-content-external-dependencies" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>External Dependencies</h1> 
  <p>Most of the <code>processors</code> dependencies are captured in the build file. However, a few <code>processors</code> unit tests depend also on <code>svm-rank</code>, which should be installed separately. Simply installing the <code>svm-rank</code> binaries to <code>/usr/local/bin</code> (or another generic location on your OS) solves the problem:</p> 
  <p><a href="https://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html" target="_blank">https://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html</a></p> 
  <h2><a href="https://github.com/clulab/processors#installing-external-dependencies-on-mac-os-x-via-homebrew" aria-hidden="true" class="anchor" id="user-content-installing-external-dependencies-on-mac-os-x-via-homebrew" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Installing external dependencies on Mac OS X via <code>homebrew</code></h2> 
  <div class="highlight highlight-source-shell">
   <pre>brew tap myedibleenso/nlp
brew install svmlight svmrank</pre>
  </div> 
  <h2><a href="https://github.com/clulab/processors#skipping-tests-involving-external-dependencies" aria-hidden="true" class="anchor" id="user-content-skipping-tests-involving-external-dependencies" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Skipping tests involving external dependencies</h2> 
  <p>Alternatively, you can run just the unit tests that do not require external binaries with the following command:</p> 
  <p><code>sbt 'test-only -- -l NeedsExternalBinary'</code></p> 
  <h1><a href="https://github.com/clulab/processors#why-you-should-use-this-code" aria-hidden="true" class="anchor" id="user-content-why-you-should-use-this-code" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Why you should use this code</h1> 
  <ul> 
   <li><strong>Simple API</strong> - the APIs provided are, at least in my opinion, simpler than those provided for the original code. For example, when using CoreNLP you won't have to deal with hash maps that take class objects as keys. Instead, we use mostly arrays of integers or strings, which are self explanatory.</li> 
   <li><strong>Memory efficient</strong> - arrays are more memory efficient than hash maps. Furthermore, we used our own implementation to intern strings (i.e., avoiding the storage of duplicated strings multiple times). Due to these changes, I measured up to 99% decrease in memory for the annotations corresponding to a typical natural language text, when compared to the original CoreNLP code. (Note: this reduction takes effect only <em>after</em> CoreNLP finishes its work.)</li> 
   <li><strong>Faster access</strong> - again, because we use arrays instead of hash maps, access to the NL annotations (once constructed) is considerably faster than in the original Stanford code.</li> 
   <li><strong>Tool-independent API</strong> - we support multiple NL and machine learning tools. If you use this code, you will have to change your code only minimally (i.e., only the constructor for the <code>Processor</code> object).</li> 
   <li><strong>Discourse parsing</strong> - we include a complete RST parser; simply instantiate <code>CoreNLPProcessor</code> with <code>withDiscourse = true</code>.</li> 
   <li><strong>Biomedical tools</strong> - we now include tools to process biomedical texts, which can be used under the same simple interface. We also offer event extraction tools for the biomedical domain.</li> 
   <li><strong>Rule-based event extraction</strong> - we include Odin, an event extraction framework, which can be customized to various domains.</li> 
   <li><strong>Apache license</strong> - our <code>CluProcessor</code> replicates most functionality of Stanford's CoreNLP (tokenization, POS tagging, dependency parsing, more soon!) under the more permissive Apache license.</li> 
  </ul> 
  <h1><a href="https://github.com/clulab/processors#how-to-compile-the-source-code" aria-hidden="true" class="anchor" id="user-content-how-to-compile-the-source-code" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>How to compile the source code</h1> 
  <p>This is a standard sbt project, so use the usual commands, e.g., <code>sbt compile</code>, <code>sbt assembly</code>, to compile. Add the generated jar files under <code>target/</code> to your $CLASSPATH, along with the other necessary dependency jars. Take a look at <code>build.sbt</code> to see which dependencies are necessary at runtime.</p> 
  <h1><a href="https://github.com/clulab/processors#how-to-use-it" aria-hidden="true" class="anchor" id="user-content-how-to-use-it" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>How to use it</h1> 
  <h2><a href="https://github.com/clulab/processors#common-scenarios" aria-hidden="true" class="anchor" id="user-content-common-scenarios" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Common scenarios</h2> 
  <p>Most of the examples here use Scala. However, this software can be used as is from Java as well! Scroll down towards the end of this document to see a Java usage example.</p> 
  <h3><a href="https://github.com/clulab/processors#annotating-entire-documents" aria-hidden="true" class="anchor" id="user-content-annotating-entire-documents" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Annotating entire documents</h3> 
  <p>(see <a href="https://github.com/clulab/processors/blob/master/corenlp/src/main/scala/org/clulab/processors/examples/ProcessorExample.scala" target="_blank"><code>corenlp/src/main/scala/org/clulab/processors/examples/ProcessorExample.scala</code></a> for a complete running example)</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">org.clulab.processors.corenlp.</span><span class="pl-v">CoreNLPProcessor</span>
<span class="pl-k">import</span> <span class="pl-v">org.clulab.processors.shallownlp.</span><span class="pl-v">ShallowNLPProcessor</span>
<span class="pl-k">import</span> <span class="pl-v">org.clulab.processors.</span>{<span class="pl-v">Document</span>, <span class="pl-v">Processor</span>}
<span class="pl-k">import</span> <span class="pl-v">org.clulab.struct.</span><span class="pl-v">DirectedGraphEdgeIterator</span>

<span class="pl-c"><span class="pl-c">//</span> create the processor</span>
<span class="pl-c"><span class="pl-c">//</span> any processor works here! Try FastNLPProcessor, BioNLPProcessor, or our own CluProcessor</span>
<span class="pl-c"><span class="pl-c">//</span> use no arguments in the c'tor if you don't need the discourse parser</span>
<span class="pl-k">val</span> <span class="pl-en">proc</span><span class="pl-k">:</span><span class="pl-en">Processor</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">CoreNLPProcessor</span>(<span class="pl-en">ShallowNLPProcessor</span>.<span class="pl-en">WITH_DISCOURSE</span>) 

<span class="pl-c"><span class="pl-c">//</span> the actual work is done here</span>
<span class="pl-k">val</span> <span class="pl-en">doc</span> <span class="pl-k">=</span> proc.annotate(<span class="pl-s"><span class="pl-pds">"</span>John Smith went to China. He visited Beijing, on January 10th, 2013.<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">//</span> you are basically done. the rest of this code simply prints out the annotations</span>

<span class="pl-c"><span class="pl-c">//</span> let's print the sentence-level annotations</span>
<span class="pl-k">var</span> <span class="pl-en">sentenceCount</span> <span class="pl-k">=</span> <span class="pl-c1">0</span>
<span class="pl-k">for</span> (sentence <span class="pl-k">&lt;</span><span class="pl-k">-</span> doc.sentences) {
  println(<span class="pl-s"><span class="pl-pds">"</span>Sentence #<span class="pl-pds">"</span></span> <span class="pl-k">+</span> sentenceCount <span class="pl-k">+</span> <span class="pl-s"><span class="pl-pds">"</span>:<span class="pl-pds">"</span></span>)
  println(<span class="pl-s"><span class="pl-pds">"</span>Tokens: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> sentence.words.mkString(<span class="pl-s"><span class="pl-pds">"</span> <span class="pl-pds">"</span></span>))
  println(<span class="pl-s"><span class="pl-pds">"</span>Start character offsets: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> sentence.startOffsets.mkString(<span class="pl-s"><span class="pl-pds">"</span> <span class="pl-pds">"</span></span>))
  println(<span class="pl-s"><span class="pl-pds">"</span>End character offsets: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> sentence.endOffsets.mkString(<span class="pl-s"><span class="pl-pds">"</span> <span class="pl-pds">"</span></span>))

  <span class="pl-c"><span class="pl-c">//</span> these annotations are optional, so they are stored using Option objects, hence the foreach statement</span>
  sentence.lemmas.foreach(lemmas <span class="pl-k">=&gt;</span> println(s<span class="pl-s"><span class="pl-pds">"</span>Lemmas: ${lemmas.mkString(<span class="pl-pds">"</span></span> <span class="pl-s"><span class="pl-pds">"</span>)}<span class="pl-pds">"</span></span>))
  sentence.tags.foreach(tags <span class="pl-k">=&gt;</span> println(s<span class="pl-s"><span class="pl-pds">"</span>POS tags: ${tags.mkString(<span class="pl-pds">"</span></span> <span class="pl-s"><span class="pl-pds">"</span>)}<span class="pl-pds">"</span></span>))
  sentence.chunks.foreach(chunks <span class="pl-k">=&gt;</span> println(s<span class="pl-s"><span class="pl-pds">"</span>Chunks: ${chunks.mkString(<span class="pl-pds">"</span></span> <span class="pl-s"><span class="pl-pds">"</span>)}<span class="pl-pds">"</span></span>))
  sentence.entities.foreach(entities <span class="pl-k">=&gt;</span> println(s<span class="pl-s"><span class="pl-pds">"</span>Named entities: ${entities.mkString(<span class="pl-pds">"</span></span> <span class="pl-s"><span class="pl-pds">"</span>)}<span class="pl-pds">"</span></span>))
  sentence.norms.foreach(norms <span class="pl-k">=&gt;</span> println(s<span class="pl-s"><span class="pl-pds">"</span>Normalized entities: ${norms.mkString(<span class="pl-pds">"</span></span> <span class="pl-s"><span class="pl-pds">"</span>)}<span class="pl-pds">"</span></span>))
  sentence.dependencies.foreach(dependencies <span class="pl-k">=&gt;</span> {
    println(<span class="pl-s"><span class="pl-pds">"</span>Syntactic dependencies:<span class="pl-pds">"</span></span>)
    <span class="pl-k">val</span> <span class="pl-en">iterator</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">DirectedGraphEdgeIterator</span>[<span class="pl-k">String</span>](dependencies)
    <span class="pl-k">while</span>(iterator.hasNext) {
      <span class="pl-k">val</span> <span class="pl-en">dep</span> <span class="pl-k">=</span> iterator.next
      <span class="pl-c"><span class="pl-c">//</span> note that we use offsets starting at 0 (unlike CoreNLP, which uses offsets starting at 1)</span>
      println(<span class="pl-s"><span class="pl-pds">"</span> head:<span class="pl-pds">"</span></span> <span class="pl-k">+</span> dep._1 <span class="pl-k">+</span> <span class="pl-s"><span class="pl-pds">"</span> modifier:<span class="pl-pds">"</span></span> <span class="pl-k">+</span> dep._2 <span class="pl-k">+</span> <span class="pl-s"><span class="pl-pds">"</span> label:<span class="pl-pds">"</span></span> <span class="pl-k">+</span> dep._3)
    }
  })
  sentence.syntacticTree.foreach(tree <span class="pl-k">=&gt;</span> {
    println(<span class="pl-s"><span class="pl-pds">"</span>Constituent tree: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> tree)
    <span class="pl-c"><span class="pl-c">//</span> see the org.clulab.utils.Tree class for more information</span>
    <span class="pl-c"><span class="pl-c">//</span> on syntactic trees, including access to head phrases/words</span>
  })

  sentenceCount <span class="pl-k">+</span><span class="pl-k">=</span> <span class="pl-c1">1</span>
  println(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\n</span><span class="pl-pds">"</span></span>)
}

<span class="pl-c"><span class="pl-c">//</span> let's print the coreference chains</span>
doc.coreferenceChains.foreach(chains <span class="pl-k">=&gt;</span> {
  <span class="pl-k">for</span> (chain <span class="pl-k">&lt;</span><span class="pl-k">-</span> chains.getChains) {
    println(<span class="pl-s"><span class="pl-pds">"</span>Found one coreference chain containing the following mentions:<span class="pl-pds">"</span></span>)
    <span class="pl-k">for</span> (mention <span class="pl-k">&lt;</span><span class="pl-k">-</span> chain) {
      <span class="pl-c"><span class="pl-c">//</span> note that all these offsets start at 0 too</span>
      println(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\t</span>sentenceIndex:<span class="pl-pds">"</span></span> <span class="pl-k">+</span> mention.sentenceIndex <span class="pl-k">+</span>
        <span class="pl-s"><span class="pl-pds">"</span> headIndex:<span class="pl-pds">"</span></span> <span class="pl-k">+</span> mention.headIndex <span class="pl-k">+</span>
        <span class="pl-s"><span class="pl-pds">"</span> startTokenOffset:<span class="pl-pds">"</span></span> <span class="pl-k">+</span> mention.startOffset <span class="pl-k">+</span>
        <span class="pl-s"><span class="pl-pds">"</span> endTokenOffset:<span class="pl-pds">"</span></span> <span class="pl-k">+</span> mention.endOffset <span class="pl-k">+</span>
        <span class="pl-s"><span class="pl-pds">"</span> text: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> doc.sentences(mention.sentenceIndex).words.slice(mention.startOffset, mention.endOffset).mkString(<span class="pl-s"><span class="pl-pds">"</span>[<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span> <span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>]<span class="pl-pds">"</span></span>))
    }
  }
})

<span class="pl-c"><span class="pl-c">//</span> let's print the discourse tree</span>
doc.discourseTree.foreach(dt <span class="pl-k">=&gt;</span> {
  println(<span class="pl-s"><span class="pl-pds">"</span>Document-wide discourse tree:<span class="pl-pds">"</span></span>)
  println(dt.toString())
})</pre>
  </div> 
  <p>The above code generates the following output:</p> 
  <pre><code>Sentence #0:
Tokens: John Smith went to China .
Start character offsets: 0 5 11 16 19 24
End character offsets: 4 10 15 18 24 25
Lemmas: John Smith go to China .
POS tags: NNP NNP VBD TO NNP .
Chunks: B-NP I-NP B-VP B-PP B-NP O
Named entities: PERSON PERSON O O LOCATION O
Normalized entities: O O O O O O
Syntactic dependencies:
  head:1 modifier:0 label:nn
  head:2 modifier:1 label:nsubj
  head:2 modifier:4 label:prep_to
Constituent tree: (ROOT (S (NP (NNP John) (NNP Smith)) (VP (VBD went) (PP (TO to) (NP (NNP China)))) (. .)))


Sentence #1:
Tokens: He visited Beijing , on January 10th , 2013 .
Start character offsets: 26 29 37 44 46 49 57 61 63 67
End character offsets: 28 36 44 45 48 56 61 62 67 68
Lemmas: he visit Beijing , on January 10th , 2013 .
POS tags: PRP VBD NNP , IN NNP JJ , CD .
Chunks: B-NP B-VP B-NP O B-PP B-NP I-NP I-NP I-NP O
Named entities: O O LOCATION O O DATE DATE DATE DATE O
Normalized entities: O O O O O 2013-01-10 2013-01-10 2013-01-10 2013-01-10 O
Syntactic dependencies:
  head:1 modifier:0 label:nsubj
  head:1 modifier:2 label:dobj
  head:1 modifier:8 label:tmod
  head:2 modifier:5 label:prep_on
  head:5 modifier:6 label:amod
Constituent tree: (ROOT (S (NP (PRP He)) (VP (VBD visited) (NP (NP (NNP Beijing)) (, ,) (PP (IN on) (NP (NNP January) (JJ 10th))) (, ,)) (NP-TMP (CD 2013))) (. .)))


Found one coreference chain containing the following mentions:
  sentenceIndex:1 headIndex:2 startTokenOffset:2 endTokenOffset:3 text: [Beijing]
Found one coreference chain containing the following mentions:
  sentenceIndex:1 headIndex:0 startTokenOffset:0 endTokenOffset:1 text: [He]
  sentenceIndex:0 headIndex:1 startTokenOffset:0 endTokenOffset:2 text: [John Smith]
Found one coreference chain containing the following mentions:
  sentenceIndex:1 headIndex:5 startTokenOffset:5 endTokenOffset:9 text: [January 10th , 2013]
Found one coreference chain containing the following mentions:
  sentenceIndex:0 headIndex:4 startTokenOffset:4 endTokenOffset:5 text: [China]

Document-wide discourse tree:
elaboration (LeftToRight)
  TEXT:John Smith went to China .
  TEXT:He visited Beijing , on January 10th , 2013 .
</code></pre> 
  <p>For more details about the annotation data structures, please see the <code>org/clulab/processor/Document.scala</code> file.</p> 
  <p>Changing processors is trivial: just replace the first line in the above example with:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">val</span> <span class="pl-en">proc</span><span class="pl-k">:</span><span class="pl-en">Processor</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">FastNLPProcessor</span>()
<span class="pl-c"><span class="pl-c">//</span> everything else stays the same</span></pre>
  </div> 
  <p><code>FastNLPProcessor</code> uses the Stanford tokenizer, POS tagger, and NER, but replaces its parser with maltparser, trained to generated Stanford "basic" (rather than "collapsed") dependencies. This means that this annotator does not produce constituent trees and coreference chains. However, because of the faster parser, you should see a speedup increase of at least one order of magnitude. The output of the above code with <code>FastNLPProcessor</code> is:</p> 
  <pre><code>Sentence #0:
Tokens: John Smith went to China .
Start character offsets: 0 5 11 16 19 24
End character offsets: 4 10 15 18 24 25
Lemmas: John Smith go to China .
POS tags: NNP NNP VBD TO NNP .
Chunks: B-NP I-NP B-VP B-PP B-NP O
Named entities: PERSON PERSON O O LOCATION O
Normalized entities: O O O O O O
Syntactic dependencies:
 head:1 modifier:0 label:nn
 head:2 modifier:1 label:nsubj
 head:2 modifier:3 label:prep
 head:2 modifier:5 label:punct
 head:3 modifier:4 label:pobj


Sentence #1:
Tokens: He visited Beijing , on January 10th , 2013 .
Start character offsets: 26 29 37 44 46 49 57 61 63 67
End character offsets: 28 36 44 45 48 56 61 62 67 68
Lemmas: he visit Beijing , on January 10th , 2013 .
POS tags: PRP VBD NNP , IN NNP JJ , CD .
Chunks: B-NP B-VP B-NP O B-PP B-NP I-NP I-NP I-NP O
Named entities: O O LOCATION O O DATE DATE DATE DATE O
Normalized entities: O O O O O 2013-01-10 2013-01-10 2013-01-10 2013-01-10 O
Syntactic dependencies:
 head:1 modifier:0 label:nsubj
 head:1 modifier:2 label:dobj
 head:1 modifier:3 label:punct
 head:1 modifier:4 label:prep
 head:1 modifier:9 label:punct
 head:4 modifier:5 label:pobj
 head:5 modifier:6 label:amod
 head:5 modifier:7 label:punct
 head:5 modifier:8 label:num
</code></pre> 
  <h3><a href="https://github.com/clulab/processors#annotating-documents-already-split-into-sentences" aria-hidden="true" class="anchor" id="user-content-annotating-documents-already-split-into-sentences" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Annotating documents already split into sentences</h3> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">val</span> <span class="pl-en">doc</span> <span class="pl-k">=</span> proc.annotateFromSentences(<span class="pl-en">List</span>(<span class="pl-s"><span class="pl-pds">"</span>John Smith went to China.<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>He visited Beijing.<span class="pl-pds">"</span></span>))
<span class="pl-c"><span class="pl-c">//</span> everything else stays the same</span></pre>
  </div> 
  <h3><a href="https://github.com/clulab/processors#annotating-documents-already-split-into-sentences-and-tokenized" aria-hidden="true" class="anchor" id="user-content-annotating-documents-already-split-into-sentences-and-tokenized" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Annotating documents already split into sentences and tokenized</h3> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">val</span> <span class="pl-en">doc</span> <span class="pl-k">=</span> annotateFromTokens(<span class="pl-en">List</span>(
  <span class="pl-en">List</span>(<span class="pl-s"><span class="pl-pds">"</span>John<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>Smith<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>went<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>to<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>China<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>.<span class="pl-pds">"</span></span>),
  <span class="pl-en">List</span>(<span class="pl-s"><span class="pl-pds">"</span>There<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>,<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>he<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>visited<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>Beijing<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>.<span class="pl-pds">"</span></span>)))
<span class="pl-c"><span class="pl-c">//</span> everything else stays the same</span></pre>
  </div> 
  <h2><a href="https://github.com/clulab/processors#using-individual-annotators" aria-hidden="true" class="anchor" id="user-content-using-individual-annotators" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Using individual annotators</h2> 
  <p>You can of course use only some of the annotators provided by CoreNLP by calling them individually. To illustrate, the <code>Processor.annotate()</code> method is implemented as follows:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">def</span> <span class="pl-en">annotate</span>(doc<span class="pl-k">:</span><span class="pl-en">Document</span>)<span class="pl-k">:</span> <span class="pl-en">Document</span> <span class="pl-k">=</span> {
  tagPartsOfSpeech(doc)
  lemmatize(doc)
  recognizeNamedEntities(doc)
  parse(doc)
  chunking(doc)
  labelSemanticRoles(doc)
  resolveCoreference(doc)
  discourse(doc)
  doc.clear()
  doc
}</pre>
  </div> 
  <p>(Note that CoreNLP currently does not support semantic role labeling.) You can use just a few of these annotators. For example, if you need just POS tags, lemmas and named entities, you could use the following code:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">val</span> <span class="pl-en">doc</span> <span class="pl-k">=</span> proc.mkDocument(<span class="pl-s"><span class="pl-pds">"</span>John Smith went to China. He visited Beijing, on January 10th, 2013.<span class="pl-pds">"</span></span>)
proc.tagPartsOfSpeech(doc)
proc.lemmatize(doc)
proc.recognizeNamedEntities(doc)
doc.clear()</pre>
  </div> 
  <p>Note that the last method called (<code>doc.clear()</code>) clears the internal structures created by the actual CoreNLP annotators. This saves a lot of memory, so, although it is not strictly necessary, I recommend you call it.</p> 
  <h2><a href="https://github.com/clulab/processors#serialization" aria-hidden="true" class="anchor" id="user-content-serialization" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Serialization</h2> 
  <p>This package also offers serialization code for the generated annotations. The two scenarios currently supported are:</p> 
  <h3><a href="https://github.com/clulab/processors#serialization-tofrom-streams" aria-hidden="true" class="anchor" id="user-content-serialization-tofrom-streams" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Serialization to/from streams</h3> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> saving to a PrintWriter, pw</span>
<span class="pl-k">val</span> <span class="pl-en">someAnnotation</span> <span class="pl-k">=</span> proc.annotate(someText)
<span class="pl-k">val</span> <span class="pl-en">serializer</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">DocumentSerializer</span>
serializer.save(someAnnotation, pw)

<span class="pl-c"><span class="pl-c">//</span> loading from an BufferedReader, br</span>
<span class="pl-k">val</span> <span class="pl-en">someAnnotation</span> <span class="pl-k">=</span> serializer.load(br)</pre>
  </div> 
  <h3><a href="https://github.com/clulab/processors#serialization-tofrom-strings" aria-hidden="true" class="anchor" id="user-content-serialization-tofrom-strings" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Serialization to/from Strings</h3> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> saving to a String object, savedString</span>
<span class="pl-k">val</span> <span class="pl-en">someAnnotation</span> <span class="pl-k">=</span> proc.annotate(someText)
<span class="pl-k">val</span> <span class="pl-en">serializer</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">DocumentSerializer</span>
<span class="pl-k">val</span> <span class="pl-en">savedString</span> <span class="pl-k">=</span> serializer.save(someAnnotation)

<span class="pl-c"><span class="pl-c">//</span> loading from a String object, fromString</span>
<span class="pl-k">val</span> <span class="pl-en">someAnnotation</span> <span class="pl-k">=</span> serializer.load(fromString)</pre>
  </div> 
  <p>Note that space required for these serialized annotations is considerably smaller (8 to 10 times) than the corresponding serialized Java objects. This is because we store only the information required to recreate these annotations (e.g., words, lemmas, etc.) without storing any of the Java/Scala objects and classes.</p> 
  <h3><a href="https://github.com/clulab/processors#serialization-tofrom-json" aria-hidden="true" class="anchor" id="user-content-serialization-tofrom-json" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Serialization to/from <code>json</code></h3> 
  <p>As of v5.9.6, <code>Document</code> and <code>Mention</code> instances can be serialized to/from <code>json</code> (<a href="https://gist.github.com/myedibleenso/87a3191c73938840b8ed768ec305db38" target="_blank">see the complete working example</a>).</p> 
  <h2><a href="https://github.com/clulab/processors#cleaning-up-the-interned-strings" aria-hidden="true" class="anchor" id="user-content-cleaning-up-the-interned-strings" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Cleaning up the interned strings</h2> 
  <p>Classes that implement the <code>Processor</code> trait intern String objects to avoid allocating memory repeatedly for the same string. This is implemented by maintaining an internal dictionary of strings previously seen. This dictionary is unlikely to use a lot of memory due to the Zipfian distribution of language. But, if memory usage is a big concern, it can be cleaned by calling:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-en">Processor</span>.in.clear()</pre>
  </div> 
  <p>I recommend you do this only <em>after</em> you annotated all the documents you plan to keep in memory.</p> 
  <p>Although I see no good reason for doing this, you can disable the interning of strings completely by setting the <code>internStrings = false</code> in the CoreNLProcessor constructor, as such:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">val</span> <span class="pl-en">processor</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">CoreNLPProcessor</span>(internStrings <span class="pl-k">=</span> <span class="pl-c1">false</span>)</pre>
  </div> 
  <h2><a href="https://github.com/clulab/processors#using-processors-from-java" aria-hidden="true" class="anchor" id="user-content-using-processors-from-java" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Using processors from Java</h2> 
  <p>Scala is (largely) compatible with Java, so this library can be directly used from Java. Below is Java code that translates most of the functionality from the first Scala example in this document to Java:</p> 
  <div class="highlight highlight-source-java">
   <pre><span class="pl-k">package</span> <span class="pl-smi">org.clulab.processors</span>;


<span class="pl-k">import</span> <span class="pl-smi">org.clulab.discourse.rstparser.DiscourseTree</span>;
<span class="pl-k">import</span> <span class="pl-smi">org.clulab.processors.fastnlp.FastNLPProcessor</span>;
<span class="pl-k">import</span> <span class="pl-smi">org.clulab.processors.corenlp.CoreNLPProcessor</span>;
<span class="pl-k">import</span> <span class="pl-smi">org.clulab.struct.CorefMention</span>;
<span class="pl-k">import</span> <span class="pl-smi">org.clulab.struct.DirectedGraphEdgeIterator</span>;

<span class="pl-k">public</span> <span class="pl-k">class</span> <span class="pl-en">ProcessorsJavaExample</span> {
    <span class="pl-k">public</span> <span class="pl-k">static</span> <span class="pl-k">void</span> <span class="pl-en">main</span>(<span class="pl-smi">String</span> [] <span class="pl-v">args</span>) <span class="pl-k">throws</span> <span class="pl-smi">Exception</span> {
        <span class="pl-c"><span class="pl-c">//</span> create the processor</span>
        <span class="pl-smi">Processor</span> proc <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">CoreNLPProcessor</span>(<span class="pl-c1">true</span>, <span class="pl-c1">false</span>, <span class="pl-c1">0</span>, <span class="pl-c1">100</span>);
        <span class="pl-c"><span class="pl-c">//</span> for much faster processing, use FastNLPProcessor</span>
        <span class="pl-c"><span class="pl-c">//</span> Processor proc = new FastNLPProcessor(true, false);</span>

        <span class="pl-c"><span class="pl-c">//</span> the actual work is done here</span>
        <span class="pl-smi">Document</span> doc <span class="pl-k">=</span> proc<span class="pl-k">.</span>annotate(<span class="pl-s"><span class="pl-pds">"</span>John Smith went to China. He visited Beijing, on January 10th, 2013.<span class="pl-pds">"</span></span>, <span class="pl-c1">false</span>);

        <span class="pl-c"><span class="pl-c">//</span> you are basically done. the rest of this code simply prints out the annotations</span>

        <span class="pl-c"><span class="pl-c">//</span> let's print the sentence-level annotations</span>
        <span class="pl-k">int</span> sentenceCount <span class="pl-k">=</span> <span class="pl-c1">0</span>;
        <span class="pl-k">for</span> (<span class="pl-smi">Sentence</span> sentence<span class="pl-k">:</span> doc<span class="pl-k">.</span>sentences()) {
            <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>Sentence #<span class="pl-pds">"</span></span> <span class="pl-k">+</span> sentenceCount <span class="pl-k">+</span> <span class="pl-s"><span class="pl-pds">"</span>:<span class="pl-pds">"</span></span>);
            <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>Tokens: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> mkString(sentence<span class="pl-k">.</span>words(), <span class="pl-s"><span class="pl-pds">"</span> <span class="pl-pds">"</span></span>));
            <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>Start character offsets: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> mkString(sentence<span class="pl-k">.</span>startOffsets(), <span class="pl-s"><span class="pl-pds">"</span> <span class="pl-pds">"</span></span>));
            <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>End character offsets: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> mkString(sentence<span class="pl-k">.</span>endOffsets(), <span class="pl-s"><span class="pl-pds">"</span> <span class="pl-pds">"</span></span>));

            <span class="pl-c"><span class="pl-c">//</span> these annotations are optional, so they are stored using Option objects, hence the isDefined checks</span>
            <span class="pl-k">if</span>(sentence<span class="pl-k">.</span>lemmas()<span class="pl-k">.</span>isDefined()){
                <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>Lemmas: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> mkString(sentence<span class="pl-k">.</span>lemmas()<span class="pl-k">.</span>get(), <span class="pl-s"><span class="pl-pds">"</span> <span class="pl-pds">"</span></span>));
            }
            <span class="pl-k">if</span>(sentence<span class="pl-k">.</span>tags()<span class="pl-k">.</span>isDefined()){
                <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>POS tags: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> mkString(sentence<span class="pl-k">.</span>tags()<span class="pl-k">.</span>get(), <span class="pl-s"><span class="pl-pds">"</span> <span class="pl-pds">"</span></span>));
            }
            <span class="pl-k">if</span>(sentence<span class="pl-k">.</span>chunks()<span class="pl-k">.</span>isDefined()){
                <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>Chunks: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> mkString(sentence<span class="pl-k">.</span>chunks()<span class="pl-k">.</span>get(), <span class="pl-s"><span class="pl-pds">"</span> <span class="pl-pds">"</span></span>));
            }
            <span class="pl-k">if</span>(sentence<span class="pl-k">.</span>entities()<span class="pl-k">.</span>isDefined()){
                <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>Named entities: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> mkString(sentence<span class="pl-k">.</span>entities()<span class="pl-k">.</span>get(), <span class="pl-s"><span class="pl-pds">"</span> <span class="pl-pds">"</span></span>));
            }
            <span class="pl-k">if</span>(sentence<span class="pl-k">.</span>norms()<span class="pl-k">.</span>isDefined()){
                <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>Normalized entities: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> mkString(sentence<span class="pl-k">.</span>norms()<span class="pl-k">.</span>get(), <span class="pl-s"><span class="pl-pds">"</span> <span class="pl-pds">"</span></span>));
            }
            <span class="pl-k">if</span>(sentence<span class="pl-k">.</span>dependencies()<span class="pl-k">.</span>isDefined()) {
                <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>Syntactic dependencies:<span class="pl-pds">"</span></span>);
                <span class="pl-k">DirectedGraphEdgeIterator&lt;<span class="pl-smi">String</span>&gt;</span> iterator <span class="pl-k">=</span> <span class="pl-k">new</span>
                    <span class="pl-k">DirectedGraphEdgeIterator&lt;<span class="pl-smi">String</span>&gt;</span>(sentence<span class="pl-k">.</span>dependencies()<span class="pl-k">.</span>get());
                <span class="pl-k">while</span>(iterator<span class="pl-k">.</span>hasNext()) {
                    <span class="pl-k">scala.Tuple3&lt;<span class="pl-smi">Object</span>, <span class="pl-smi">Object</span>, <span class="pl-smi">String</span>&gt;</span> dep <span class="pl-k">=</span> iterator<span class="pl-k">.</span>next();
                    <span class="pl-c"><span class="pl-c">//</span> note that we use offsets starting at 0 (unlike CoreNLP, which uses offsets starting at 1)</span>
                    <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span> head:<span class="pl-pds">"</span></span> <span class="pl-k">+</span> dep<span class="pl-k">.</span>_1() <span class="pl-k">+</span> <span class="pl-s"><span class="pl-pds">"</span> modifier:<span class="pl-pds">"</span></span> <span class="pl-k">+</span> dep<span class="pl-k">.</span>_2() <span class="pl-k">+</span> <span class="pl-s"><span class="pl-pds">"</span> label:<span class="pl-pds">"</span></span> <span class="pl-k">+</span> dep<span class="pl-k">.</span>_3());
                }
            }
            <span class="pl-k">if</span>(sentence<span class="pl-k">.</span>syntacticTree()<span class="pl-k">.</span>isDefined()) {
                <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>Constituent tree: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> sentence<span class="pl-k">.</span>syntacticTree()<span class="pl-k">.</span>get());
                <span class="pl-c"><span class="pl-c">//</span> see the org.clulab.struct.Tree class for more information</span>
                <span class="pl-c"><span class="pl-c">//</span> on syntactic trees, including access to head phrases/words</span>
            }

            sentenceCount <span class="pl-k">+=</span> <span class="pl-c1">1</span>;
            <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\n</span><span class="pl-pds">"</span></span>);
        }

        <span class="pl-c"><span class="pl-c">//</span> let's print the coreference chains</span>
        <span class="pl-k">if</span>(doc<span class="pl-k">.</span>coreferenceChains()<span class="pl-k">.</span>isDefined()) {
            <span class="pl-c"><span class="pl-c">//</span> these are scala.collection Iterator and Iterable (not Java!)</span>
            <span class="pl-k">scala.collection.Iterator&lt;<span class="pl-k">scala.collection.Iterable&lt;<span class="pl-smi">CorefMention</span>&gt;</span>&gt;</span> chains <span class="pl-k">=</span> doc<span class="pl-k">.</span>coreferenceChains()<span class="pl-k">.</span>get()<span class="pl-k">.</span>getChains()<span class="pl-k">.</span>iterator();
            <span class="pl-k">while</span>(chains<span class="pl-k">.</span>hasNext()) {
                <span class="pl-k">scala.collection.Iterator&lt;<span class="pl-smi">CorefMention</span>&gt;</span> chain <span class="pl-k">=</span> chains<span class="pl-k">.</span>next()<span class="pl-k">.</span>iterator();
                <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>Found one coreference chain containing the following mentions:<span class="pl-pds">"</span></span>);
                <span class="pl-k">while</span>(chain<span class="pl-k">.</span>hasNext()) {
                    <span class="pl-smi">CorefMention</span> mention <span class="pl-k">=</span> chain<span class="pl-k">.</span>next();
                    <span class="pl-c"><span class="pl-c">//</span> note that all these offsets start at 0 too</span>
                    <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\t</span>sentenceIndex:<span class="pl-pds">"</span></span> <span class="pl-k">+</span> mention<span class="pl-k">.</span>sentenceIndex() <span class="pl-k">+</span>
                        <span class="pl-s"><span class="pl-pds">"</span> headIndex:<span class="pl-pds">"</span></span> <span class="pl-k">+</span> mention<span class="pl-k">.</span>headIndex() <span class="pl-k">+</span>
                        <span class="pl-s"><span class="pl-pds">"</span> startTokenOffset:<span class="pl-pds">"</span></span> <span class="pl-k">+</span> mention<span class="pl-k">.</span>startOffset() <span class="pl-k">+</span>
                        <span class="pl-s"><span class="pl-pds">"</span> endTokenOffset:<span class="pl-pds">"</span></span> <span class="pl-k">+</span> mention<span class="pl-k">.</span>endOffset());
                }
            }
        }
	
        <span class="pl-c"><span class="pl-c">//</span> let's print the discourse tree</span>
        <span class="pl-k">if</span>(doc<span class="pl-k">.</span>discourseTree()<span class="pl-k">.</span>isDefined()) {
            <span class="pl-smi">DiscourseTree</span> tree <span class="pl-k">=</span> doc<span class="pl-k">.</span>discourseTree()<span class="pl-k">.</span>get();
            <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>Discourse tree:<span class="pl-cce">\n</span><span class="pl-pds">"</span></span> <span class="pl-k">+</span> tree);
        }
    }

    <span class="pl-k">public</span> <span class="pl-k">static</span> <span class="pl-smi">String</span> <span class="pl-en">mkString</span>(<span class="pl-smi">String</span> [] <span class="pl-v">sa</span>, <span class="pl-smi">String</span> <span class="pl-v">sep</span>) {
        <span class="pl-smi">StringBuilder</span> os <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">StringBuilder</span>();
        <span class="pl-k">for</span>(<span class="pl-k">int</span> i <span class="pl-k">=</span> <span class="pl-c1">0</span>; i <span class="pl-k">&lt;</span> sa<span class="pl-k">.</span>length; i <span class="pl-k">++</span>) {
            <span class="pl-k">if</span>(i <span class="pl-k">&gt;</span> <span class="pl-c1">0</span>) os<span class="pl-k">.</span>append(sep);
            os<span class="pl-k">.</span>append(sa[i]);
        }
        <span class="pl-k">return</span> os<span class="pl-k">.</span>toString();
    }
    <span class="pl-k">public</span> <span class="pl-k">static</span> <span class="pl-smi">String</span> <span class="pl-en">mkString</span>(<span class="pl-k">int</span> [] <span class="pl-v">sa</span>, <span class="pl-smi">String</span> <span class="pl-v">sep</span>) {
        <span class="pl-smi">StringBuilder</span> os <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">StringBuilder</span>();
        <span class="pl-k">for</span>(<span class="pl-k">int</span> i <span class="pl-k">=</span> <span class="pl-c1">0</span>; i <span class="pl-k">&lt;</span> sa<span class="pl-k">.</span>length; i <span class="pl-k">++</span>) {
            <span class="pl-k">if</span>(i <span class="pl-k">&gt;</span> <span class="pl-c1">0</span>) os<span class="pl-k">.</span>append(sep);
            os<span class="pl-k">.</span>append(<span class="pl-smi">Integer</span><span class="pl-k">.</span>toString(sa[i]));
        }
        <span class="pl-k">return</span> os<span class="pl-k">.</span>toString();
    }
}</pre>
  </div> 
  <p>The output of this code is:</p> 
  <pre><code>Sentence #0:
Tokens: John Smith went to China .
Start character offsets: 0 5 11 16 19 24
End character offsets: 4 10 15 18 24 25
Lemmas: John Smith go to China .
POS tags: NNP NNP VBD TO NNP .
Chunks: B-NP I-NP B-VP B-PP B-NP O
Named entities: PERSON PERSON O O LOCATION O
Normalized entities: O O O O O O
Syntactic dependencies:
 head:1 modifier:0 label:nn
 head:2 modifier:1 label:nsubj
 head:2 modifier:4 label:prep_to
Constituent tree:
(ROOT
    (S
        (NP
            (NNP John)
            (NNP Smith)
        )
        (VP
            (VBD went)
            (PP
                (TO to)
                (NP
                    (NNP China)
                )
            )
        )
        (. .)
    )
)


Sentence #1:
Tokens: He visited Beijing , on January 10th , 2013 .
Start character offsets: 26 29 37 44 46 49 57 61 63 67
End character offsets: 28 36 44 45 48 56 61 62 67 68
Lemmas: he visit Beijing , on January 10th , 2013 .
POS tags: PRP VBD NNP , IN NNP JJ , CD .
Chunks: B-NP B-VP B-NP O B-PP B-NP I-NP I-NP I-NP O
Named entities: O O LOCATION O O DATE DATE DATE DATE O
Normalized entities: O O O O O 2013-01-10 2013-01-10 2013-01-10 2013-01-10 O
Syntactic dependencies:
 head:1 modifier:0 label:nsubj
 head:1 modifier:2 label:dobj
 head:1 modifier:8 label:tmod
 head:2 modifier:5 label:prep_on
 head:5 modifier:6 label:amod
Constituent tree:
(ROOT
    (S
        (NP
            (PRP He)
        )
        (VP
            (VBD visited)
            (NP
                (NP
                    (NNP Beijing)
                )
                (, ,)
                (PP
                    (IN on)
                    (NP
                        (NNP January)
                        (JJ 10th)
                    )
                )
                (, ,)
            )
            (NP-TMP
                (CD 2013)
            )
        )
        (. .)
    )
)


Found one coreference chain containing the following mentions:
	sentenceIndex:1 headIndex:2 startTokenOffset:2 endTokenOffset:7
Found one coreference chain containing the following mentions:
	sentenceIndex:0 headIndex:1 startTokenOffset:0 endTokenOffset:2
	sentenceIndex:1 headIndex:0 startTokenOffset:0 endTokenOffset:1
Found one coreference chain containing the following mentions:
	sentenceIndex:1 headIndex:5 startTokenOffset:5 endTokenOffset:7
Found one coreference chain containing the following mentions:
	sentenceIndex:0 headIndex:4 startTokenOffset:4 endTokenOffset:5
Found one coreference chain containing the following mentions:
	sentenceIndex:1 headIndex:8 startTokenOffset:8 endTokenOffset:9
Discourse tree:
elaboration (LeftToRight)
	TEXT:John Smith went to China .
    TEXT:He visited Beijing , on January 10th , 2013 .
</code></pre> 
  <h2><a href="https://github.com/clulab/processors#the-discourse-parser" aria-hidden="true" class="anchor" id="user-content-the-discourse-parser" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>The discourse parser</h2> 
  <p>The discourse parser in <code>processors</code> is inspired by the parser of <a href="http://www.cs.toronto.edu/%7Eweifeng/software.html" target="_blank">Feng and Hirst</a> and the HILDA parser of <a href="http://elanguage.net/journals/dad/article/view/591" target="_blank">Hernault et al.</a>, but with a different feature set. It is transparently integrated in both <code>CoreNLPProcessor</code> and <code>FastNLPProcessor</code>: just instantiate it as <code>CoreNLPProcessor(withDiscourse = true)</code> or <code>FastNLPProcessor(withDiscourse = true)</code>. If discourse is enabled, <code>Document.discourseTree</code> stores the discourse tree for the entire document as an instance of the <code>DiscourseTree</code> class.</p> 
  <p>Following the conventions from other modern discourse parsing work, the discourse tree:</p> 
  <ul> 
   <li>Is represented as a binary tree, containing hypotactic relations (containing one nucleus and one satellite node) or paratactic relations (both nodes have equal importance).</li> 
   <li>Stores the relation labels in the parent node (in <code>DiscourseTree.relationLabel</code>) rather than the satellite nodes (like the RST corpus). We use the same 18 labels as Feng and Hirst.</li> 
   <li>Stores the relation direction in <code>DiscourseTree.relationDirection</code>. The direction can be <code>LeftToRight</code> (meaning the nucleus is the left child), <code>RightToLeft</code> (the right node is the nucleus), or <code>None</code> (for paratactic relations).</li> 
  </ul> 
  <p>Developers only: For more details on the discourse parsers, please see <a href="https://github.com/clulab/processors/wiki/Discourse-Parsers-Details" target="_blank">this Wiki page</a>.</p> 
  <h2><a href="https://github.com/clulab/processors#the-orgclulablearning-package" aria-hidden="true" class="anchor" id="user-content-the-orgclulablearning-package" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>The <code>org.clulab.learning</code> package</h2> 
  <p><code>processors</code> now contains a machine learning (ML) package (<code>org.clulab.learning</code>), which includes implementations for common ML algorithms (e.g., Perceptron, Logistic Regression, Support Vector Machines, Random Forests) for both classification and ranking.</p> 
  <p>The structure of this package is heavily inspired by Stanford's CoreNLP. Similar to CoreNLP, we use a <code>Datum</code> trait to store a single data point, which is implemented by <code>BVFDatum</code> to store binary-valued-feature datums, or by <code>RVFDatum</code> to store real-valued-feature datums. A collection of data points is stored as a <code>Dataset</code>, which is similarly implemented by <code>BVFDataset</code> or <code>RVFDataset</code>. All classifiers implement the <code>Classifier</code> trait, which has three main methods: <code>train</code>, which trains a model a given dataset, <code>classOf</code>, which returns the most likely prediction for a given datum, and <code>scoresOf</code>, which returns the scores for all known labels for a given datum. We currently support the following classifiers: large-margin Perceptron (<code>PerceptronClassifier</code>), linear SVMs and logistic regression from <a href="http://www.csie.ntu.edu.tw/%7Ecjlin/liblinear/" target="_blank">liblinear</a> (<code>LibLinearClassifier</code>), dual SVMs from <a href="http://www.csie.ntu.edu.tw/%7Ecjlin/libsvm/" target="_blank">libsvm</a> (<code>LibSVMClassifier</code>), and random forests, implemented in-house (<code>RFClassifier</code>).</p> 
  <p>A similar structure exists for ranking problems, with <code>RankingDataset</code> used to store a corpus of ranking examples, and <code>RankingClassifier</code> as the API to be implemented by all ranking classifiers. We currently support the following classifiers: ranking Perceptron (<code>PerceptronRankingClassifier</code>), and ranking SVMs from <a href="http://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html" target="_blank">svm-rank</a> (<code>SVMRankingClassifier</code>).</p> 
  <p>For usage examples, including how to create datums and datasets from scratch or import them from the svm-light format, please take a look at the examples under <code>src/test/scala/org/clulab/learning</code>.</p> 
  <h2><a href="https://github.com/clulab/processors#the-odin-event-extraction-framework" aria-hidden="true" class="anchor" id="user-content-the-odin-event-extraction-framework" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>The Odin event extraction framework</h2> 
  <p>Please see <a href="https://github.com/clulab/processors/wiki/ODIN-(Open-Domain-INformer)" target="_blank">Odin's Wiki</a> page for details.</p> 
  <h2><a href="https://github.com/clulab/processors#other-resources" aria-hidden="true" class="anchor" id="user-content-other-resources" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Other resources</h2> 
  <ul> 
   <li><a href="http://agathon.sista.arizona.edu:8080/odinweb/open" target="_blank">Odin online demo</a></li> 
   <li>See our <a href="https://github.com/clulab/reach" target="_blank">Reach project</a> for more applications of Odin and demos</li> 
  </ul> 
 </article>
</div>