<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a id="user-content-reactive-streams-for-kafka" class="anchor" href="https://github.com/kciesielski/reactive-kafka#reactive-streams-for-kafka" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Reactive Streams for Kafka</h1> 
  <p><a href="https://maven-badges.herokuapp.com/maven-central/com.typesafe.akka/akka-stream-kafka_2.11" target="_blank"><img src="https://camo.githubusercontent.com/651cde74e4f71dd033adfcc68bd73a4d1532cb9f/68747470733a2f2f6d6176656e2d6261646765732e6865726f6b756170702e636f6d2f6d6176656e2d63656e7472616c2f636f6d2e74797065736166652e616b6b612f616b6b612d73747265616d2d6b61666b615f322e31312f62616467652e737667" alt="Maven Central" data-canonical-src="https://maven-badges.herokuapp.com/maven-central/com.typesafe.akka/akka-stream-kafka_2.11/badge.svg" style="max-width:100%;"></a> If you have questions or are working on a pull request or just curious, please feel welcome to join the chat room: <a href="https://gitter.im/akka/reactive-kafka?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge" target="_blank"><img src="https://camo.githubusercontent.com/da2edb525cde1455a622c58c0effc3a90b9a181c/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667" alt="Join the chat at https://gitter.im/akka/reactive-kafka" data-canonical-src="https://badges.gitter.im/Join%20Chat.svg" style="max-width:100%;"></a></p> 
  <p><a href="http://doc.akka.io/docs/akka/2.4.6/scala/stream/index.html" target="_blank">Akka Streams</a> connector for <a href="https://kafka.apache.org/" target="_blank">Apache Kafka</a>.</p> 
  <p>Created and maintained by <a href="https://softwaremill.com" target="_blank"><img src="https://camo.githubusercontent.com/658f085689718a7dbe7c1c0b9bbd3022dd37391c/68747470733a2f2f736f6674776172656d696c6c2e636f6d2f696d672f6c6f676f32782e706e67" alt="SoftwareMill logo" height="25" data-canonical-src="https://softwaremill.com/img/logo2x.png" style="max-width:100%;"></a></p> 
  <h2><a id="user-content-new-api-011-m3" class="anchor" href="https://github.com/kciesielski/reactive-kafka#new-api-011-m3" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>New API: 0.11-M3</h2> 
  <p>Supports Kafka 0.9.0.x</p> 
  <p>This version of <code>akka-stream-kafka</code> depends on Akka 2.4.6 and Scala 2.11.8. </p> 
  <p>Available at Maven Central for Scala 2.11:</p> 
  <div class="highlight highlight-source-scala">
   <pre>libraryDependencies <span class="pl-k">+</span><span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>com.typesafe.akka<span class="pl-pds">"</span></span> <span class="pl-k">%%</span> <span class="pl-s"><span class="pl-pds">"</span>akka-stream-kafka<span class="pl-pds">"</span></span> <span class="pl-k">%</span> <span class="pl-s"><span class="pl-pds">"</span>0.11-M3<span class="pl-pds">"</span></span></pre>
  </div> 
  <h2><a id="user-content-example-usage" class="anchor" href="https://github.com/kciesielski/reactive-kafka#example-usage" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Example usage</h2> 
  <h4><a id="user-content-scala" class="anchor" href="https://github.com/kciesielski/reactive-kafka#scala" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Scala</h4> 
  <p>Producer Settings:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">akka.kafka.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">akka.kafka.scaladsl.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.common.serialization.</span><span class="pl-v">StringSerializer</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.common.serialization.</span><span class="pl-v">ByteArraySerializer</span>

  <span class="pl-k">val</span> <span class="pl-en">producerSettings</span> <span class="pl-k">=</span> <span class="pl-en">ProducerSettings</span>(system, <span class="pl-k">new</span> <span class="pl-en">ByteArraySerializer,</span> <span class="pl-k">new</span> <span class="pl-en">StringSerializer)</span>
    .withBootstrapServers(<span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>)</pre>
  </div> 
  <p>Produce messages:</p> 
  <div class="highlight highlight-source-scala">
   <pre>  <span class="pl-en">Source</span>(<span class="pl-c1">1</span> to <span class="pl-c1">10000</span>)
    .map(_.toString)
    .map(elem <span class="pl-k">=&gt;</span> <span class="pl-k">new</span> <span class="pl-en">ProducerRecord</span>[<span class="pl-en">Array</span>[<span class="pl-k">Byte</span>], <span class="pl-k">String</span>](<span class="pl-s"><span class="pl-pds">"</span>topic1<span class="pl-pds">"</span></span>, elem))
    .to(<span class="pl-en">Producer</span>.plainSink(producerSettings))</pre>
  </div> 
  <p>Produce messages in a flow:</p> 
  <div class="highlight highlight-source-scala">
   <pre>  <span class="pl-en">Source</span>(<span class="pl-c1">1</span> to <span class="pl-c1">10000</span>)
    .map(elem <span class="pl-k">=&gt;</span> <span class="pl-en">ProducerMessage</span>.<span class="pl-en">Message</span>(<span class="pl-k">new</span> <span class="pl-en">ProducerRecord</span>[<span class="pl-en">Array</span>[<span class="pl-k">Byte</span>], <span class="pl-k">String</span>](<span class="pl-s"><span class="pl-pds">"</span>topic1<span class="pl-pds">"</span></span>, elem.toString), elem))
    .via(<span class="pl-en">Producer</span>.flow(producerSettings))
    .map { result <span class="pl-k">=&gt;</span>
      <span class="pl-k">val</span> <span class="pl-en">record</span> <span class="pl-k">=</span> result.message.record
      println(s<span class="pl-s"><span class="pl-pds">"</span>${record.topic}/${record.partition} ${result.offset}: ${record.value} (${result.message.passThrough}<span class="pl-pds">"</span></span>)
      result
    }</pre>
  </div> 
  <p>Consumer Settings:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">akka.kafka.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">akka.kafka.scaladsl.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.common.serialization.</span><span class="pl-v">StringDeserializer</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.common.serialization.</span><span class="pl-v">ByteArrayDeserializer</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.clients.consumer.</span><span class="pl-v">ConsumerConfig</span>

<span class="pl-k">val</span> <span class="pl-en">consumerSettings</span> <span class="pl-k">=</span> <span class="pl-en">ConsumerSettings</span>(system, <span class="pl-k">new</span> <span class="pl-en">ByteArrayDeserializer,</span> <span class="pl-k">new</span> <span class="pl-en">StringDeserializer,</span> 
    <span class="pl-en">Set</span>(<span class="pl-s"><span class="pl-pds">"</span>topic1<span class="pl-pds">"</span></span>))
  .withBootstrapServers(<span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>)
  .withGroupId(<span class="pl-s"><span class="pl-pds">"</span>group1<span class="pl-pds">"</span></span>)
  .withProperty(<span class="pl-en">ConsumerConfig</span>.<span class="pl-en">AUTO_OFFSET_RESET_CONFIG</span>, <span class="pl-s"><span class="pl-pds">"</span>earliest<span class="pl-pds">"</span></span>)</pre>
  </div> 
  <p>Consume messages and store a representation, including offset, in DB:</p> 
  <div class="highlight highlight-source-scala">
   <pre>  db.loadOffset().foreach { fromOffset <span class="pl-k">=&gt;</span>
    <span class="pl-k">val</span> <span class="pl-en">settings</span> <span class="pl-k">=</span> consumerSettings
      .withFromOffset(<span class="pl-k">new</span> <span class="pl-en">TopicPartition</span>(<span class="pl-s"><span class="pl-pds">"</span>topic1<span class="pl-pds">"</span></span>, <span class="pl-c1">1</span>), fromOffset)
    <span class="pl-en">Consumer</span>.plainSource(settings)
      .mapAsync(<span class="pl-c1">1</span>)(db.save)
  }</pre>
  </div> 
  <p>Consume messages at-most-once:</p> 
  <div class="highlight highlight-source-scala">
   <pre>  <span class="pl-en">Consumer</span>.atMostOnceSource(consumerSettings.withClientId(<span class="pl-s"><span class="pl-pds">"</span>client1<span class="pl-pds">"</span></span>))
    .mapAsync(<span class="pl-c1">1</span>) { record <span class="pl-k">=&gt;</span>
      rocket.launch(record.value)
    }</pre>
  </div> 
  <p>Consume messages at-least-once:</p> 
  <div class="highlight highlight-source-scala">
   <pre>  <span class="pl-en">Consumer</span>.committableSource(consumerSettings.withClientId(<span class="pl-s"><span class="pl-pds">"</span>client1<span class="pl-pds">"</span></span>))
    .mapAsync(<span class="pl-c1">1</span>) { msg <span class="pl-k">=&gt;</span>
      db.update(msg.value).flatMap(_ <span class="pl-k">=&gt;</span> msg.committableOffset.commit())
    }</pre>
  </div> 
  <p>Connect a Consumer to Producer:</p> 
  <div class="highlight highlight-source-scala">
   <pre>  <span class="pl-en">Consumer</span>.committableSource(consumerSettings.withClientId(<span class="pl-s"><span class="pl-pds">"</span>client1<span class="pl-pds">"</span></span>))
    .map(msg <span class="pl-k">=&gt;</span>
      <span class="pl-en">ProducerMessage</span>.<span class="pl-en">Message</span>(<span class="pl-k">new</span> <span class="pl-en">ProducerRecord</span>[<span class="pl-en">Array</span>[<span class="pl-k">Byte</span>], <span class="pl-k">String</span>](<span class="pl-s"><span class="pl-pds">"</span>topic2<span class="pl-pds">"</span></span>, msg.value), msg.committableOffset))
    .to(<span class="pl-en">Producer</span>.commitableSink(producerSettings))</pre>
  </div> 
  <p>Consume messages at-least-once, and commit in batches:</p> 
  <div class="highlight highlight-source-scala">
   <pre>  <span class="pl-en">Consumer</span>.committableSource(consumerSettings.withClientId(<span class="pl-s"><span class="pl-pds">"</span>client1<span class="pl-pds">"</span></span>))
    .mapAsync(<span class="pl-c1">1</span>) { msg <span class="pl-k">=&gt;</span>
      db.update(msg.value).map(_ <span class="pl-k">=&gt;</span> msg.committableOffset)
    }
    .batch(max <span class="pl-k">=</span> <span class="pl-c1">10</span>, first <span class="pl-k">=&gt;</span> <span class="pl-en">CommittableOffsetBatch</span>.empty.updated(first)) { (batch, elem) <span class="pl-k">=&gt;</span>
      batch.updated(elem)
    }
    .mapAsync(<span class="pl-c1">1</span>)(_.commit())</pre>
  </div> 
  <p>Additional examples are available in <a href="https://github.com/akka/reactive-kafka/blob/v0.11-M3/core/src/test/scala/examples/scaladsl/ConsumerExample.scala" target="_blank">ConsumerExamples.scala</a></p> 
  <h4><a id="user-content-java" class="anchor" href="https://github.com/kciesielski/reactive-kafka#java" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Java</h4> 
  <p>Producer Settings:</p> 
  <div class="highlight highlight-source-java">
   <pre><span class="pl-k">import</span> <span class="pl-smi">akka.kafka.*</span>;
<span class="pl-k">import</span> <span class="pl-smi">akka.kafka.javadsl.*</span>;
<span class="pl-k">import</span> <span class="pl-smi">org.apache.kafka.common.serialization.StringSerializer</span>;
<span class="pl-k">import</span> <span class="pl-smi">org.apache.kafka.common.serialization.ByteArraySerializer</span>;

  <span class="pl-k">final</span> <span class="pl-k">ProducerSettings&lt;byte[], <span class="pl-smi">String</span>&gt;</span> producerSettings <span class="pl-k">=</span> <span class="pl-smi">ProducerSettings</span>
      .create(system, <span class="pl-k">new</span> <span class="pl-smi">ByteArraySerializer</span>(), <span class="pl-k">new</span> <span class="pl-smi">StringSerializer</span>())
      .withBootstrapServers(<span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>);</pre>
  </div> 
  <p>Produce messages:</p> 
  <div class="highlight highlight-source-java">
   <pre>    <span class="pl-smi">Source</span><span class="pl-k">.</span>range(<span class="pl-c1">1</span>, <span class="pl-c1">10000</span>)
      .map(n <span class="pl-k">-</span><span class="pl-k">&gt;</span> n<span class="pl-k">.</span>toString())<span class="pl-k">.</span>map(elem <span class="pl-k">-</span><span class="pl-k">&gt;</span> <span class="pl-k">new</span> <span class="pl-k">ProducerRecord&lt;byte[], <span class="pl-smi">String</span>&gt;</span>(<span class="pl-s"><span class="pl-pds">"</span>topic1<span class="pl-pds">"</span></span>, elem))
      .to(<span class="pl-smi">Producer</span><span class="pl-k">.</span>plainSink(producerSettings));</pre>
  </div> 
  <p>Produce messages in a flow:</p> 
  <div class="highlight highlight-source-java">
   <pre>    <span class="pl-smi">Source</span><span class="pl-k">.</span>range(<span class="pl-c1">1</span>, <span class="pl-c1">10000</span>)
      .map(n <span class="pl-k">-</span><span class="pl-k">&gt;</span> <span class="pl-k">new</span> <span class="pl-smi">ProducerMessage</span>.<span class="pl-k">Message&lt;byte[], <span class="pl-smi">String</span>, <span class="pl-smi">Integer</span>&gt;</span>(
        <span class="pl-k">new</span> <span class="pl-k">ProducerRecord&lt;&gt;</span>(<span class="pl-s"><span class="pl-pds">"</span>topic1<span class="pl-pds">"</span></span>, n<span class="pl-k">.</span>toString()), n))
      .via(<span class="pl-smi">Producer</span><span class="pl-k">.</span>flow(producerSettings))
      .map(result <span class="pl-k">-</span><span class="pl-k">&gt;</span> {
        <span class="pl-smi">ProducerRecord</span> record <span class="pl-k">=</span> result<span class="pl-k">.</span>message()<span class="pl-k">.</span>record();
        <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(record);
        <span class="pl-k">return</span> result;
      });</pre>
  </div> 
  <p>Consumer Settings:</p> 
  <div class="highlight highlight-source-java">
   <pre><span class="pl-k">import</span> <span class="pl-smi">akka.kafka.*</span>;
<span class="pl-k">import</span> <span class="pl-smi">akka.kafka.javadsl.*</span>;
<span class="pl-k">import</span> <span class="pl-smi">org.apache.kafka.common.serialization.StringSerializer</span>;
<span class="pl-k">import</span> <span class="pl-smi">org.apache.kafka.common.serialization.ByteArraySerializer</span>;
<span class="pl-k">import</span> <span class="pl-smi">org.apache.kafka.clients.consumer.ConsumerConfig</span>;

<span class="pl-k">final</span> <span class="pl-k">ConsumerSettings&lt;byte[], <span class="pl-smi">String</span>&gt;</span> consumerSettings <span class="pl-k">=</span>
      <span class="pl-smi">ConsumerSettings</span><span class="pl-k">.</span>create(system, <span class="pl-k">new</span> <span class="pl-smi">ByteArrayDeserializer</span>(), <span class="pl-k">new</span> <span class="pl-smi">StringDeserializer</span>(),
          <span class="pl-smi">ConsumerSettings</span><span class="pl-k">.</span>asSet(<span class="pl-s"><span class="pl-pds">"</span>topic1<span class="pl-pds">"</span></span>))
    .withBootstrapServers(<span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>)
    .withGroupId(<span class="pl-s"><span class="pl-pds">"</span>group1<span class="pl-pds">"</span></span>)
    .withProperty(<span class="pl-smi">ConsumerConfig</span><span class="pl-c1"><span class="pl-k">.</span>AUTO_OFFSET_RESET_CONFIG</span>, <span class="pl-s"><span class="pl-pds">"</span>earliest<span class="pl-pds">"</span></span>);</pre>
  </div> 
  <p>Consume messages and store a representation, including offset, in DB:</p> 
  <div class="highlight highlight-source-java">
   <pre>    db<span class="pl-k">.</span>loadOffset()<span class="pl-k">.</span>thenAccept(fromOffset <span class="pl-k">-</span><span class="pl-k">&gt;</span> {
      <span class="pl-k">ConsumerSettings&lt;byte[], <span class="pl-smi">String</span>&gt;</span> settings <span class="pl-k">=</span> consumerSettings
        .withFromOffset(<span class="pl-k">new</span> <span class="pl-smi">TopicPartition</span>(<span class="pl-s"><span class="pl-pds">"</span>topic1<span class="pl-pds">"</span></span>, <span class="pl-c1">1</span>), fromOffset);
      <span class="pl-smi">Consumer</span><span class="pl-k">.</span>plainSource(settings)<span class="pl-k">.</span>mapAsync(<span class="pl-c1">1</span>, record <span class="pl-k">-</span><span class="pl-k">&gt;</span> db<span class="pl-k">.</span>save(record));
    });</pre>
  </div> 
  <p>Consume messages at-most-once:</p> 
  <div class="highlight highlight-source-java">
   <pre>    <span class="pl-smi">Consumer</span><span class="pl-k">.</span>atMostOnceSource(consumerSettings<span class="pl-k">.</span>withClientId(<span class="pl-s"><span class="pl-pds">"</span>client1<span class="pl-pds">"</span></span>))
      .mapAsync(<span class="pl-c1">1</span>, record <span class="pl-k">-</span><span class="pl-k">&gt;</span> rocket<span class="pl-k">.</span>launch(record<span class="pl-k">.</span>value()));</pre>
  </div> 
  <p>Consume messages at-least-once:</p> 
  <div class="highlight highlight-source-java">
   <pre>    <span class="pl-smi">Consumer</span><span class="pl-k">.</span>committableSource(consumerSettings<span class="pl-k">.</span>withClientId(<span class="pl-s"><span class="pl-pds">"</span>client1<span class="pl-pds">"</span></span>))
      .mapAsync(<span class="pl-c1">1</span>, msg <span class="pl-k">-</span><span class="pl-k">&gt;</span> db<span class="pl-k">.</span>update(msg<span class="pl-k">.</span>value())
        .thenCompose(done <span class="pl-k">-</span><span class="pl-k">&gt;</span> msg<span class="pl-k">.</span>committableOffset()<span class="pl-k">.</span>commitJavadsl()));</pre>
  </div> 
  <p>Connect a Consumer to Producer:</p> 
  <div class="highlight highlight-source-java">
   <pre>    <span class="pl-smi">Consumer</span><span class="pl-k">.</span>committableSource(consumerSettings<span class="pl-k">.</span>withClientId(<span class="pl-s"><span class="pl-pds">"</span>client1<span class="pl-pds">"</span></span>))
      .map(msg <span class="pl-k">-</span><span class="pl-k">&gt;</span>
        <span class="pl-k">new</span> <span class="pl-smi">ProducerMessage</span>.<span class="pl-k">Message&lt;byte[], <span class="pl-smi">String</span>, <span class="pl-smi">ConsumerMessage</span>.</span><span class="pl-smi">Committable</span>&gt;(
            <span class="pl-k">new</span> <span class="pl-k">ProducerRecord&lt;&gt;</span>(<span class="pl-s"><span class="pl-pds">"</span>topic2<span class="pl-pds">"</span></span>, msg<span class="pl-k">.</span>value()), msg<span class="pl-k">.</span>committableOffset()))
      .to(<span class="pl-smi">Producer</span><span class="pl-k">.</span>commitableSink(producerSettings));</pre>
  </div> 
  <p>Consume messages at-least-once, and commit in batches:</p> 
  <div class="highlight highlight-source-java">
   <pre>    <span class="pl-smi">Consumer</span><span class="pl-k">.</span>committableSource(consumerSettings<span class="pl-k">.</span>withClientId(<span class="pl-s"><span class="pl-pds">"</span>client1<span class="pl-pds">"</span></span>))
      .mapAsync(<span class="pl-c1">1</span>, msg <span class="pl-k">-</span><span class="pl-k">&gt;</span>
        db<span class="pl-k">.</span>update(msg<span class="pl-k">.</span>value())<span class="pl-k">.</span>thenApply(done <span class="pl-k">-</span><span class="pl-k">&gt;</span> msg<span class="pl-k">.</span>committableOffset()))
      .batch(<span class="pl-c1">10</span>,
        first <span class="pl-k">-</span><span class="pl-k">&gt;</span> <span class="pl-smi">ConsumerMessage</span><span class="pl-k">.</span>emptyCommittableOffsetBatch()<span class="pl-k">.</span>updated(first),
        (batch, elem) <span class="pl-k">-</span><span class="pl-k">&gt;</span> batch<span class="pl-k">.</span>updated(elem))
      .mapAsync(<span class="pl-c1">1</span>, c <span class="pl-k">-</span><span class="pl-k">&gt;</span> c<span class="pl-k">.</span>commitJavadsl());</pre>
  </div> 
  <p>Additional examples are available in <a href="https://github.com/akka/reactive-kafka/blob/v0.11-M3/core/src/test/java/examples/javadsl/ConsumerExample.java" target="_blank">ConsumerExamples.java</a></p> 
  <h2><a id="user-content-configuration" class="anchor" href="https://github.com/kciesielski/reactive-kafka#configuration" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Configuration</h2> 
  <p>The configuration properties are defined in <a href="https://github.com/akka/reactive-kafka/blob/v0.11-M3/core/src/main/resources/reference.conf" target="_blank">reference.conf</a></p> 
  <h2><a id="user-content-testing" class="anchor" href="https://github.com/kciesielski/reactive-kafka#testing" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Testing</h2> 
  <p>Tests require Apache Kafka and Zookeeper to be available on <code>localhost:9092</code> and <code>localhost:2181</code>. Note that <code>auto.create.topics.enable</code> should be <code>true</code>.</p> 
  <h2><a id="user-content-old-api-0100" class="anchor" href="https://github.com/kciesielski/reactive-kafka#old-api-0100" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Old API: 0.10.0</h2> 
  <p>Supports Kafka 0.9.0.x <strong>For Kafka 0.8</strong> see <a href="https://github.com/softwaremill/reactive-kafka/tree/0.8" target="_blank">this branch</a>.</p> 
  <p>Available at Maven Central for Scala 2.11:</p> 
  <div class="highlight highlight-source-scala">
   <pre>libraryDependencies <span class="pl-k">+</span><span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>com.softwaremill.reactivekafka<span class="pl-pds">"</span></span> <span class="pl-k">%%</span> <span class="pl-s"><span class="pl-pds">"</span>reactive-kafka-core<span class="pl-pds">"</span></span> <span class="pl-k">%</span> <span class="pl-s"><span class="pl-pds">"</span>0.10.0<span class="pl-pds">"</span></span></pre>
  </div> 
  <h2><a id="user-content-example-usage-1" class="anchor" href="https://github.com/kciesielski/reactive-kafka#example-usage-1" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Example usage</h2> 
  <h4><a id="user-content-scala-1" class="anchor" href="https://github.com/kciesielski/reactive-kafka#scala-1" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Scala</h4> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">akka.actor.</span><span class="pl-v">ActorSystem</span>
<span class="pl-k">import</span> <span class="pl-v">akka.stream.</span><span class="pl-v">ActorMaterializer</span>
<span class="pl-k">import</span> <span class="pl-v">akka.stream.scaladsl.</span>{<span class="pl-v">Sink</span>, <span class="pl-v">Source</span>}
<span class="pl-k">import</span> <span class="pl-v">com.softwaremill.react.kafka.KafkaMessages.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.common.serialization.</span>{<span class="pl-v">StringSerializer</span>, <span class="pl-v">StringDeserializer</span>}
<span class="pl-k">import</span> <span class="pl-v">com.softwaremill.react.kafka.</span>{<span class="pl-v">ProducerMessage</span>, <span class="pl-v">ConsumerProperties</span>, <span class="pl-v">ProducerProperties</span>, <span class="pl-v">ReactiveKafka</span>}
<span class="pl-k">import</span> <span class="pl-v">org.reactivestreams.</span>{ <span class="pl-v">Publisher</span>, <span class="pl-v">Subscriber</span> }

<span class="pl-k">implicit</span> <span class="pl-k">val</span> <span class="pl-en">actorSystem</span> <span class="pl-k">=</span> <span class="pl-en">ActorSystem</span>(<span class="pl-s"><span class="pl-pds">"</span>ReactiveKafka<span class="pl-pds">"</span></span>)
<span class="pl-k">implicit</span> <span class="pl-k">val</span> <span class="pl-en">materializer</span> <span class="pl-k">=</span> <span class="pl-en">ActorMaterializer</span>()

<span class="pl-k">val</span> <span class="pl-en">kafka</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">ReactiveKafka</span>()
<span class="pl-k">val</span> <span class="pl-en">publisher</span><span class="pl-k">:</span> <span class="pl-en">Publisher</span>[<span class="pl-en">StringConsumerRecord</span>] <span class="pl-k">=</span> kafka.consume(<span class="pl-en">ConsumerProperties</span>(
 bootstrapServers <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>,
 topic <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>lowercaseStrings<span class="pl-pds">"</span></span>,
 groupId <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>groupName<span class="pl-pds">"</span></span>,
 valueDeserializer <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">StringDeserializer</span>()
))
<span class="pl-k">val</span> <span class="pl-en">subscriber</span><span class="pl-k">:</span> <span class="pl-en">Subscriber</span>[<span class="pl-en">StringProducerMessage</span>] <span class="pl-k">=</span> kafka.publish(<span class="pl-en">ProducerProperties</span>(
  bootstrapServers <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>,
  topic <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>uppercaseStrings<span class="pl-pds">"</span></span>,
  valueSerializer <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">StringSerializer</span>()
))

<span class="pl-en">Source</span>.fromPublisher(publisher).map(m <span class="pl-k">=&gt;</span> <span class="pl-en">ProducerMessage</span>(m.value().toUpperCase))
  .to(<span class="pl-en">Sink</span>.fromSubscriber(subscriber)).run()</pre>
  </div> 
  <h4><a id="user-content-java-1" class="anchor" href="https://github.com/kciesielski/reactive-kafka#java-1" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Java</h4> 
  <div class="highlight highlight-source-java">
   <pre><span class="pl-k">import</span> <span class="pl-smi">akka.actor.ActorSystem</span>;
<span class="pl-k">import</span> <span class="pl-smi">akka.stream.ActorMaterializer</span>;
<span class="pl-k">import</span> <span class="pl-smi">akka.stream.javadsl.Sink</span>;
<span class="pl-k">import</span> <span class="pl-smi">akka.stream.javadsl.Source</span>;
<span class="pl-k">import</span> <span class="pl-smi">org.apache.kafka.clients.consumer.ConsumerRecord</span>;
<span class="pl-k">import</span> <span class="pl-smi">org.apache.kafka.common.serialization.StringDeserializer</span>;
<span class="pl-k">import</span> <span class="pl-smi">org.apache.kafka.common.serialization.StringSerializer</span>;
<span class="pl-k">import</span> <span class="pl-smi">org.reactivestreams.Publisher</span>;
<span class="pl-k">import</span> <span class="pl-smi">org.reactivestreams.Subscriber</span>;

<span class="pl-k">public</span> <span class="pl-k">void</span> run() {
<span class="pl-smi">String</span> brokerList <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>;

<span class="pl-smi">ReactiveKafka</span> kafka <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">ReactiveKafka</span>();
<span class="pl-smi">ActorSystem</span> system <span class="pl-k">=</span> <span class="pl-smi">ActorSystem</span><span class="pl-k">.</span>create(<span class="pl-s"><span class="pl-pds">"</span>ReactiveKafka<span class="pl-pds">"</span></span>);
<span class="pl-smi">ActorMaterializer</span> materializer <span class="pl-k">=</span> <span class="pl-smi">ActorMaterializer</span><span class="pl-k">.</span>create(system);

<span class="pl-smi">StringDeserializer</span> deserializer <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">StringDeserializer</span>();
<span class="pl-k">ConsumerProperties&lt;<span class="pl-smi">String</span>&gt;</span> cp <span class="pl-k">=</span>
   <span class="pl-k">new</span> <span class="pl-smi">PropertiesBuilder</span>.<span class="pl-smi">Consumer</span>(brokerList, <span class="pl-s"><span class="pl-pds">"</span>topic<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>groupId<span class="pl-pds">"</span></span>, deserializer)
      .build();

<span class="pl-k">Publisher&lt;<span class="pl-k">ConsumerRecord&lt;<span class="pl-smi">String</span>, <span class="pl-smi">String</span>&gt;</span>&gt;</span> publisher <span class="pl-k">=</span> kafka<span class="pl-k">.</span>consume(cp, system);

<span class="pl-smi">StringSerializer</span> serializer <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">StringSerializer</span>();
<span class="pl-k">ProducerProperties&lt;<span class="pl-smi">String</span>, <span class="pl-smi">String</span>&gt;</span> pp <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">PropertiesBuilder</span>.<span class="pl-smi">Producer</span>(
   brokerList,
   <span class="pl-s"><span class="pl-pds">"</span>topic<span class="pl-pds">"</span></span>,
   serializer,
   serializer)<span class="pl-k">.</span>build();

<span class="pl-k">Subscriber&lt;<span class="pl-k">ProducerMessage&lt;<span class="pl-smi">String</span>, <span class="pl-smi">String</span>&gt;</span>&gt;</span> subscriber <span class="pl-k">=</span> kafka<span class="pl-k">.</span>publish(pp, system);
<span class="pl-smi">Source</span><span class="pl-k">.</span>fromPublisher(publisher)<span class="pl-k">.</span>map(<span class="pl-v">this</span><span class="pl-k">::</span>toProdMessage)
  .to(<span class="pl-smi">Sink</span><span class="pl-k">.</span>fromSubscriber(subscriber))<span class="pl-k">.</span>run(materializer);
}

<span class="pl-k">private</span> <span class="pl-k">ProducerMessage&lt;<span class="pl-smi">String</span>, <span class="pl-smi">String</span>&gt;</span> toProdMessage(<span class="pl-k">ConsumerRecord&lt;<span class="pl-smi">String</span>, <span class="pl-smi">String</span>&gt;</span> record) {
  <span class="pl-k">return</span> <span class="pl-smi">KeyValueProducerMessage</span><span class="pl-k">.</span>apply(record<span class="pl-k">.</span>key(), record<span class="pl-k">.</span>value());
}</pre>
  </div> 
  <h2><a id="user-content-passing-configuration-properties-to-kafka" class="anchor" href="https://github.com/kciesielski/reactive-kafka#passing-configuration-properties-to-kafka" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Passing configuration properties to Kafka</h2> 
  <p>In order to set your own custom Kafka parameters, you can construct <code>ConsumerProperties</code> and <code>ProducerProperties</code> using some of their provided methods in a builder-pattern-style DSL, for example: </p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.common.serialization.</span><span class="pl-v">StringDeserializer</span>
<span class="pl-k">import</span> <span class="pl-v">com.softwaremill.react.kafka.</span><span class="pl-v">ConsumerProperties</span>

<span class="pl-k">val</span> <span class="pl-en">consumerProperties</span> <span class="pl-k">=</span> <span class="pl-en">ConsumerProperties</span>(
  <span class="pl-s"><span class="pl-pds">"</span>localhost:2181<span class="pl-pds">"</span></span>,
  <span class="pl-s"><span class="pl-pds">"</span>topic<span class="pl-pds">"</span></span>,
  <span class="pl-s"><span class="pl-pds">"</span>groupId<span class="pl-pds">"</span></span>,
  <span class="pl-k">new</span> <span class="pl-en">StringDeserializer</span>()
)
  .readFromEndOfStream()
  .consumerTimeoutMs(<span class="pl-c1">300</span>)
  .commitInterval(<span class="pl-c1">2</span> seconds)
  .setProperty(<span class="pl-s"><span class="pl-pds">"</span>some.kafka.property<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>value<span class="pl-pds">"</span></span>) </pre>
  </div> 
  <p>The <code>ProducerProperties</code> class offers a similar API.</p> 
  <h2><a id="user-content-controlling-consumer-start-offset" class="anchor" href="https://github.com/kciesielski/reactive-kafka#controlling-consumer-start-offset" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Controlling consumer start offset</h2> 
  <p>By default a new consumer will start reading from the beginning of a topic, fetching all uncommitted messages. If you want to start reading from the end, you can specify this on your <code>ConsumerProperties</code>:</p> 
  <div class="highlight highlight-source-scala">
   <pre>  <span class="pl-k">val</span> <span class="pl-en">consumerProperties</span> <span class="pl-k">=</span> <span class="pl-en">ConsumerProperties</span>(...).readFromEndOfStream()</pre>
  </div> 
  <h2><a id="user-content-working-with-actors" class="anchor" href="https://github.com/kciesielski/reactive-kafka#working-with-actors" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Working with actors</h2> 
  <p>Since we are based upon akka-stream, the best way to handle errors is to leverage Akka's error handling and lifecycle management capabilities. Producers and consumers are in fact actors. </p> 
  <h4><a id="user-content-obtaining-actor-references" class="anchor" href="https://github.com/kciesielski/reactive-kafka#obtaining-actor-references" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Obtaining actor references</h4> 
  <p><code>ReactiveKafka</code> comes with a few methods allowing working on the actor level. You can let it create <code>Props</code> to let your own supervisor create these actors as children, or you can directly create actors at the top level of supervision. Here are some examples: </p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">akka.actor.</span>{<span class="pl-v">Props</span>, <span class="pl-v">ActorRef</span>, <span class="pl-v">Actor</span>, <span class="pl-v">ActorSystem</span>}
<span class="pl-k">import</span> <span class="pl-v">akka.stream.</span><span class="pl-v">ActorMaterializer</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.common.serialization.</span>{<span class="pl-v">StringSerializer</span>, <span class="pl-v">StringDeserializer</span>}
<span class="pl-k">import</span> <span class="pl-v">com.softwaremill.react.kafka.</span>{<span class="pl-v">ReactiveKafka</span>, <span class="pl-v">ProducerProperties</span>, <span class="pl-v">ConsumerProperties</span>}

<span class="pl-c">// inside an Actor:</span>
<span class="pl-k">implicit</span> <span class="pl-k">val</span> <span class="pl-en">materializer</span> <span class="pl-k">=</span> <span class="pl-en">ActorMaterializer</span>()

<span class="pl-k">val</span> <span class="pl-en">kafka</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">ReactiveKafka</span>()
<span class="pl-c">// consumer</span>
<span class="pl-k">val</span> <span class="pl-en">consumerProperties</span> <span class="pl-k">=</span> <span class="pl-en">ConsumerProperties</span>(
  bootstrapServers <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>,
  topic <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>lowercaseStrings<span class="pl-pds">"</span></span>,
  groupId <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>groupName<span class="pl-pds">"</span></span>,
  valueDeserializer <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">StringDeserializer</span>()
)
<span class="pl-k">val</span> <span class="pl-en">consumerActorProps</span><span class="pl-k">:</span> <span class="pl-en">Props</span> <span class="pl-k">=</span> kafka.consumerActorProps(consumerProperties)
<span class="pl-k">val</span> <span class="pl-en">publisherActor</span><span class="pl-k">:</span> <span class="pl-en">ActorRef</span> <span class="pl-k">=</span> context.actorOf(consumerActorProps)
<span class="pl-c">// or:</span>
<span class="pl-k">val</span> <span class="pl-en">topLevelPublisherActor</span><span class="pl-k">:</span> <span class="pl-en">ActorRef</span> <span class="pl-k">=</span> kafka.consumerActor(consumerActorProps)

<span class="pl-c">// subscriber</span>
<span class="pl-k">val</span> <span class="pl-en">producerProperties</span> <span class="pl-k">=</span> <span class="pl-en">ProducerProperties</span>(
  bootstrapServers <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>,
  topic <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>uppercaseStrings<span class="pl-pds">"</span></span>,
  <span class="pl-k">new</span> <span class="pl-en">StringSerializer</span>()
)
<span class="pl-k">val</span> <span class="pl-en">producerActorProps</span><span class="pl-k">:</span> <span class="pl-en">Props</span> <span class="pl-k">=</span> kafka.producerActorProps(producerProperties)
<span class="pl-k">val</span> <span class="pl-en">subscriberActor</span><span class="pl-k">:</span> <span class="pl-en">ActorRef</span> <span class="pl-k">=</span> context.actorOf(producerActorProps)
<span class="pl-c">// or:</span>
<span class="pl-k">val</span> <span class="pl-en">topLevelSubscriberActor</span><span class="pl-k">:</span> <span class="pl-en">ActorRef</span> <span class="pl-k">=</span> kafka.producerActor(producerProperties)</pre>
  </div> 
  <h4><a id="user-content-handling-errors" class="anchor" href="https://github.com/kciesielski/reactive-kafka#handling-errors" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Handling errors</h4> 
  <p>When a consumer or a producer fails to read/write from Kafka, the error is unrecoverable and requires that the connection be terminated. This will be performed automatically and the <code>KafkaActorSubscriber</code> / <code>KafkaActorPublisher</code> which failed will be stopped. You can use <code>DeathWatch</code> to detect such failures in order to restart your stream. Additionally, when a producer fails, it will signal <code>onError()</code> to stop the rest of stream.</p> 
  <p>Example of monitoring routine:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">akka.actor.</span>{<span class="pl-v">Actor</span>, <span class="pl-v">ActorRef</span>, <span class="pl-v">ActorSystem</span>, <span class="pl-v">Props</span>}
<span class="pl-k">import</span> <span class="pl-v">akka.stream.</span><span class="pl-v">ActorMaterializer</span>
<span class="pl-k">import</span> <span class="pl-v">com.softwaremill.react.kafka.KafkaMessages.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">com.softwaremill.react.kafka.</span>{<span class="pl-v">ConsumerProperties</span>, <span class="pl-v">ProducerProperties</span>, <span class="pl-v">ReactiveKafka</span>}

<span class="pl-k">class</span> <span class="pl-en">Handler</span> <span class="pl-k">extends</span> <span class="pl-e">Actor</span> {
  <span class="pl-k">implicit</span> <span class="pl-k">val</span> <span class="pl-en">materializer</span> <span class="pl-k">=</span> <span class="pl-en">ActorMaterializer</span>()

  <span class="pl-k">def</span> <span class="pl-en">createSupervisedSubscriberActor</span>() <span class="pl-k">=</span> {
    <span class="pl-k">val</span> <span class="pl-en">kafka</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">ReactiveKafka</span>()

    <span class="pl-c">// subscriber</span>
    <span class="pl-k">val</span> <span class="pl-en">subscriberProperties</span> <span class="pl-k">=</span> <span class="pl-en">ProducerProperties</span>(
      bootstrapServers <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>,
      topic <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>uppercaseStrings<span class="pl-pds">"</span></span>,
      valueSerializer <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">StringSerializer</span>()
    )
    <span class="pl-k">val</span> <span class="pl-en">subscriberActorProps</span><span class="pl-k">:</span> <span class="pl-en">Props</span> <span class="pl-k">=</span> kafka.producerActorProps(subscriberProperties)
    <span class="pl-k">val</span> <span class="pl-en">subscriberActor</span> <span class="pl-k">=</span> context.actorOf(subscriberActorProps)
    context.watch(subscriberActor)
  }

  <span class="pl-k">override</span> <span class="pl-k">def</span> <span class="pl-en">receive</span><span class="pl-k">:</span> <span class="pl-en">Receive</span> <span class="pl-k">=</span> {
    <span class="pl-k">case</span> <span class="pl-en">Terminated</span>(actorRef) <span class="pl-k">=&gt;</span> <span class="pl-c">// your custom handling</span>
  }

  <span class="pl-c">// Rest of the Actor's body</span>
}</pre>
  </div> 
  <h4><a id="user-content-cleaning-up" class="anchor" href="https://github.com/kciesielski/reactive-kafka#cleaning-up" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Cleaning up</h4> 
  <p>If you want to manually stop a publisher or a subscriber, you have to send an appropriate message to the underlying actor. <code>KafkaActorPublisher</code> must receive a <code>KafkaActorPublisher.Stop</code>, whereas <code>KafkaActorSubscriber</code> must receive a <code>ActorSubscriberMessage.OnComplete</code>. If you're using a <code>PublisherWithCommitSink</code> returned from <code>ReactiveKafka.consumeWithOffsetSink()</code>, you must call its <code>cancel()</code> method in order to gracefully close all underlying resources.</p> 
  <h4><a id="user-content-manual-commit-version-08-and-above" class="anchor" href="https://github.com/kciesielski/reactive-kafka#manual-commit-version-08-and-above" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Manual Commit (version 0.8 and above)</h4> 
  <p>In order to be able to achieve "at-least-once" delivery, you can use following API to obtain an additional Sink, where you can stream back messages that you processed. An underlying actor will periodically flush offsets of these messages as committed. Example: </p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">scala.concurrent.duration.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">akka.actor.</span><span class="pl-v">ActorSystem</span>
<span class="pl-k">import</span> <span class="pl-v">akka.stream.</span><span class="pl-v">ActorMaterializer</span>
<span class="pl-k">import</span> <span class="pl-v">com.softwaremill.react.kafka.KafkaMessages.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">akka.stream.scaladsl.</span><span class="pl-v">Source</span>
<span class="pl-k">import</span> <span class="pl-v">com.softwaremill.react.kafka.</span>{<span class="pl-v">ConsumerProperties</span>, <span class="pl-v">ReactiveKafka</span>}

<span class="pl-k">implicit</span> <span class="pl-k">val</span> <span class="pl-en">actorSystem</span> <span class="pl-k">=</span> <span class="pl-en">ActorSystem</span>(<span class="pl-s"><span class="pl-pds">"</span>ReactiveKafka<span class="pl-pds">"</span></span>)
<span class="pl-k">implicit</span> <span class="pl-k">val</span> <span class="pl-en">materializer</span> <span class="pl-k">=</span> <span class="pl-en">ActorMaterializer</span>()

<span class="pl-k">val</span> <span class="pl-en">kafka</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">ReactiveKafka</span>()
<span class="pl-k">val</span> <span class="pl-en">consumerProperties</span> <span class="pl-k">=</span> <span class="pl-en">ConsumerProperties</span>(
  bootstrapServers <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>,
  topic <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>lowercaseStrings<span class="pl-pds">"</span></span>,
  groupId <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>groupName<span class="pl-pds">"</span></span>,
  valueDeserializer <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">StringDeserializer</span>())
.commitInterval(<span class="pl-c1">5</span> seconds) <span class="pl-c">// flush interval</span>

<span class="pl-k">val</span> <span class="pl-en">consumerWithOffsetSink</span> <span class="pl-k">=</span> kafka.consumeWithOffsetSink(consumerProperties)
<span class="pl-en">Source</span>.fromPublisher(consumerWithOffsetSink.publisher)
  .map(processMessage(_)) <span class="pl-c">// your message processing</span>
  .to(consumerWithOffsetSink.offsetCommitSink) <span class="pl-c">// stream back for commit</span>
  .run()</pre>
  </div> 
  <h2><a id="user-content-tuning" class="anchor" href="https://github.com/kciesielski/reactive-kafka#tuning" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Tuning</h2> 
  <p><code>KafkaActorSubscriber</code> and <code>KafkaActorPublisher</code> have their own thread pools, configured in <code>reference.conf</code>. You can tune them by overriding <code>kafka-publisher-dispatcher.thread-pool-executor</code> and <code>kafka-subscriber-dispatcher.thread-pool-executor</code> in your <code>application.conf</code> file.<br> Alternatively, you can provide your own dispatcher name. It can be passed to appropriate variants of factory methods in <code>ReactiveKafka</code>: <code>publish()</code>, <code>producerActor()</code>, <code>producerActorProps()</code> or <code>consume()</code>, <code>consumerActor()</code>, <code>consumerActorProps()</code>.</p> 
  <h2><a id="user-content-testing-1" class="anchor" href="https://github.com/kciesielski/reactive-kafka#testing-1" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Testing</h2> 
  <p>Tests require Apache Kafka and Zookeeper to be available on <code>localhost:9092</code> and <code>localhost:2181</code>. Note that <code>auto.create.topics.enable</code> should be <code>true</code>.</p> 
 </article>
</div>