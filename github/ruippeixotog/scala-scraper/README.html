<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a href="https://github.com/ruippeixotog/scala-scraper#scala-scraper----" aria-hidden="true" class="anchor" id="user-content-scala-scraper----" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Scala Scraper <a href="https://travis-ci.org/ruippeixotog/scala-scraper" target="_blank"><img src="https://camo.githubusercontent.com/0b55699ce0abf8c4acb785c2557947416af8966d/68747470733a2f2f7472617669732d63692e6f72672f72756970706569786f746f672f7363616c612d736372617065722e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/ruippeixotog/scala-scraper.svg?branch=master" style="max-width:100%;"></a> <a href="https://coveralls.io/github/ruippeixotog/scala-scraper?branch=master" target="_blank"><img src="https://camo.githubusercontent.com/0f78b795d700c2d2aa172179d805637a4a383653/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f72756970706569786f746f672f7363616c612d736372617065722f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/ruippeixotog/scala-scraper/badge.svg?branch=master" style="max-width:100%;"></a> <a href="https://maven-badges.herokuapp.com/maven-central/net.ruippeixotog/scala-scraper_2.12" target="_blank"><img src="https://camo.githubusercontent.com/c9d08974baf6f29ad6f0e7a499ca4cfdffb98010/68747470733a2f2f696d672e736869656c64732e696f2f6d6176656e2d63656e7472616c2f762f6e65742e72756970706569786f746f672f7363616c612d736372617065725f322e31322e737667" alt="Maven Central" data-canonical-src="https://img.shields.io/maven-central/v/net.ruippeixotog/scala-scraper_2.12.svg" style="max-width:100%;"></a> <a href="https://gitter.im/ruippeixotog/scala-scraper" target="_blank"><img src="https://camo.githubusercontent.com/4ef9317892eea287893f7d3ef30ea2b9733ecd9f/68747470733a2f2f6261646765732e6769747465722e696d2f72756970706569786f746f672f7363616c612d736372617065722e737667" alt="Join the chat at https://gitter.im/ruippeixotog/scala-scraper" data-canonical-src="https://badges.gitter.im/ruippeixotog/scala-scraper.svg" style="max-width:100%;"></a></h1> 
  <p>A library providing a DSL for loading and extracting content from HTML pages.</p> 
  <p>Take a look at <a href="https://github.com/ruippeixotog/scala-scraper/blob/master/core/src/test/scala/net/ruippeixotog/scalascraper/Examples.scala" target="_blank">Examples.scala</a> and at the <a href="https://github.com/ruippeixotog/scala-scraper/blob/master/core/src/test/scala/net/ruippeixotog/scalascraper" target="_blank">unit specs</a> for usage examples or keep reading for more thorough documentation. Feel free to use <a href="https://github.com/ruippeixotog/scala-scraper/issues" target="_blank">GitHub Issues</a> for submitting any bug or feature request and <a href="https://gitter.im/ruippeixotog/scala-scraper" target="_blank">Gitter</a> to ask questions.</p> 
  <p>This README contains the following sections:</p> 
  <ul> 
   <li><a href="https://github.com/ruippeixotog/scala-scraper#quick-start" target="_blank">Quick Start</a></li> 
   <li><a href="https://github.com/ruippeixotog/scala-scraper#core-model" target="_blank">Core Model</a></li> 
   <li><a href="https://github.com/ruippeixotog/scala-scraper#browsers" target="_blank">Browsers</a></li> 
   <li><a href="https://github.com/ruippeixotog/scala-scraper#content-extraction" target="_blank">Content Extraction</a></li> 
   <li><a href="https://github.com/ruippeixotog/scala-scraper#content-validation" target="_blank">Content Validation</a></li> 
   <li><a href="https://github.com/ruippeixotog/scala-scraper#other-dsl-features" target="_blank">Other DSL Features</a></li> 
   <li><a href="https://github.com/ruippeixotog/scala-scraper#using-browser-specific-features" target="_blank">Using Browser-Specific Features</a></li> 
   <li><a href="https://github.com/ruippeixotog/scala-scraper#working-behind-an-httphttps-proxy" target="_blank">Working Behind an HTTP/HTTPS Proxy</a></li> 
   <li><a href="https://github.com/ruippeixotog/scala-scraper#integration-with-typesafe-config" target="_blank">Integration with Typesafe Config</a></li> 
   <li><a href="https://github.com/ruippeixotog/scala-scraper#new-features-and-migration-guide" target="_blank">New Features and Migration Guide</a></li> 
   <li><a href="https://github.com/ruippeixotog/scala-scraper#copyright" target="_blank">Copyright</a></li> 
  </ul> 
  <h2><a href="https://github.com/ruippeixotog/scala-scraper#quick-start" aria-hidden="true" class="anchor" id="user-content-quick-start" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Quick Start</h2> 
  <p>To use Scala Scraper in an existing SBT project with Scala 2.11 or 2.12, add the following dependency to your <code>build.sbt</code>:</p> 
  <div class="highlight highlight-source-scala">
   <pre>libraryDependencies <span class="pl-k">+</span><span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>net.ruippeixotog<span class="pl-pds">"</span></span> <span class="pl-k">%%</span> <span class="pl-s"><span class="pl-pds">"</span>scala-scraper<span class="pl-pds">"</span></span> <span class="pl-k">%</span> <span class="pl-s"><span class="pl-pds">"</span>2.0.0<span class="pl-pds">"</span></span></pre>
  </div> 
  <p>If you are using an older version of this library, see this document for the version you're using: <a href="https://github.com/ruippeixotog/scala-scraper/blob/v1.2.1/README.md" target="_blank">1.x</a>, <a href="https://github.com/ruippeixotog/scala-scraper/blob/v0.1.2/README.md" target="_blank">0.1.2</a>, <a href="https://github.com/ruippeixotog/scala-scraper/blob/v0.1.1/README.md" target="_blank">0.1.1</a>, <a href="https://github.com/ruippeixotog/scala-scraper/blob/v0.1/README.md" target="_blank">0.1</a>.</p> 
  <p>An implementation of the <code>Browser</code> trait, such as <code>JsoupBrowser</code>, can be used to fetch HTML from the web or to parse a local HTML file or string:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">net.ruippeixotog.scalascraper.browser.</span><span class="pl-v">JsoupBrowser</span>

<span class="pl-k">val</span> <span class="pl-en">browser</span> <span class="pl-k">=</span> <span class="pl-en">JsoupBrowser</span>()
<span class="pl-k">val</span> <span class="pl-en">doc</span> <span class="pl-k">=</span> browser.parseFile(<span class="pl-s"><span class="pl-pds">"</span>core/src/test/resources/example.html<span class="pl-pds">"</span></span>)
<span class="pl-k">val</span> <span class="pl-en">doc2</span> <span class="pl-k">=</span> browser.get(<span class="pl-s"><span class="pl-pds">"</span>http://example.com<span class="pl-pds">"</span></span>)</pre>
  </div> 
  <p>The returned object is a <code>Document</code>, which already provides several methods for manipulating and querying HTML elements. For simple use cases, it can be enough. For others, this library improves the content extracting process by providing a powerful DSL.</p> 
  <p>You can open the <a href="https://github.com/ruippeixotog/scala-scraper/blob/master/core/src/test/resources/example.html" target="_blank">example.html</a> file loaded above to follow the examples throughout the README.</p> 
  <p>First of all, the DSL methods and conversions must be imported:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">net.ruippeixotog.scalascraper.dsl.DSL.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">net.ruippeixotog.scalascraper.dsl.DSL.Extract.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">net.ruippeixotog.scalascraper.dsl.DSL.Parse.</span><span class="pl-v">_</span></pre>
  </div> 
  <p>Content can then be extracted using the <code>&gt;&gt;</code> extraction operator and CSS queries:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">net.ruippeixotog.scalascraper.model.</span><span class="pl-v">_</span>
<span class="pl-c"><span class="pl-c">//</span> import net.ruippeixotog.scalascraper.model._</span>

<span class="pl-c"><span class="pl-c">//</span> Extract the text inside the element with id "header"</span>
doc <span class="pl-k">&gt;&gt;</span> text(<span class="pl-s"><span class="pl-pds">"</span>#header<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res2: String = Test page h1</span>

<span class="pl-c"><span class="pl-c">//</span> Extract the &lt;span&gt; elements inside #menu</span>
<span class="pl-k">val</span> <span class="pl-en">items</span> <span class="pl-k">=</span> doc <span class="pl-k">&gt;&gt;</span> elementList(<span class="pl-s"><span class="pl-pds">"</span>#menu span<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> items: List[net.ruippeixotog.scalascraper.model.Element] = List(JsoupElement(&lt;span&gt;&lt;a href="#home"&gt;Home&lt;/a&gt;&lt;/span&gt;), JsoupElement(&lt;span&gt;&lt;a href="#section1"&gt;Section 1&lt;/a&gt;&lt;/span&gt;), JsoupElement(&lt;span class="active"&gt;Section 2&lt;/span&gt;), JsoupElement(&lt;span&gt;&lt;a href="#section3"&gt;Section 3&lt;/a&gt;&lt;/span&gt;))</span>

<span class="pl-c"><span class="pl-c">//</span> From each item, extract all the text inside their &lt;a&gt; elements</span>
items.map(_ <span class="pl-k">&gt;&gt;</span> allText(<span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>))
<span class="pl-c"><span class="pl-c">//</span> res5: List[String] = List(Home, Section 1, "", Section 3)</span>

<span class="pl-c"><span class="pl-c">//</span> From the meta element with "viewport" as its attribute name, extract the</span>
<span class="pl-c"><span class="pl-c">//</span> text in the content attribute</span>
doc <span class="pl-k">&gt;&gt;</span> attr(<span class="pl-s"><span class="pl-pds">"</span>content<span class="pl-pds">"</span></span>)(<span class="pl-s"><span class="pl-pds">"</span>meta[name=viewport]<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res8: String = width=device-width, initial-scale=1</span></pre>
  </div> 
  <p>If the element may or may not be in the page, the <code>&gt;?&gt;</code> tries to extract the content and returns it wrapped in an <code>Option</code>:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> Extract the element with id "footer" if it exists, return `None` if it</span>
<span class="pl-c"><span class="pl-c">//</span> doesn't:</span>
doc <span class="pl-k">&gt;</span><span class="pl-k">?</span><span class="pl-k">&gt;</span> element(<span class="pl-s"><span class="pl-pds">"</span>#footer<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res11: Option[net.ruippeixotog.scalascraper.model.Element] =</span>
<span class="pl-c"><span class="pl-c">//</span> Some(JsoupElement(&lt;div id="footer"&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>  &lt;span&gt;No copyright 2014&lt;/span&gt;</span>
<span class="pl-c"><span class="pl-c">//</span> &lt;/div&gt;))</span></pre>
  </div> 
  <p>With only these two operators, some useful things can already be achieved:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> Go to a news website and extract the hyperlink inside the h1 element if it</span>
<span class="pl-c"><span class="pl-c">//</span> exists. Follow that link and print both the article title and its short</span>
<span class="pl-c"><span class="pl-c">//</span> description (inside ".lead")</span>
<span class="pl-k">for</span> {
  headline <span class="pl-k">&lt;</span><span class="pl-k">-</span> browser.get(<span class="pl-s"><span class="pl-pds">"</span>http://observador.pt<span class="pl-pds">"</span></span>) <span class="pl-k">&gt;</span><span class="pl-k">?</span><span class="pl-k">&gt;</span> element(<span class="pl-s"><span class="pl-pds">"</span>h1 a<span class="pl-pds">"</span></span>)
  headlineDesc <span class="pl-k">=</span> browser.get(headline.attr(<span class="pl-s"><span class="pl-pds">"</span>href<span class="pl-pds">"</span></span>)) <span class="pl-k">&gt;&gt;</span> text(<span class="pl-s"><span class="pl-pds">"</span>.lead<span class="pl-pds">"</span></span>)
} println(<span class="pl-s"><span class="pl-pds">"</span>== <span class="pl-pds">"</span></span> <span class="pl-k">+</span> headline.text <span class="pl-k">+</span> <span class="pl-s"><span class="pl-pds">"</span> ==<span class="pl-cce">\n</span><span class="pl-pds">"</span></span> <span class="pl-k">+</span> headlineDesc)</pre>
  </div> 
  <p>In the next two sections the core classes used by this library are presented. They are followed by a description of the full capabilities of the DSL, including the ability to parse content after extracting, validating the contents of a page and defining custom extractors or validators.</p> 
  <h2><a href="https://github.com/ruippeixotog/scala-scraper#core-model" aria-hidden="true" class="anchor" id="user-content-core-model" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Core Model</h2> 
  <p>The library represents HTML documents and their elements by <a href="https://github.com/ruippeixotog/scala-scraper/blob/master/core/src/main/scala/net/ruippeixotog/scalascraper/model/Document.scala" target="_blank">Document</a> and <a href="https://github.com/ruippeixotog/scala-scraper/blob/master/core/src/main/scala/net/ruippeixotog/scalascraper/model/Element.scala" target="_blank">Element</a> objects, simple interfaces containing methods for retrieving information and navigating through the DOM.</p> 
  <p><a href="https://github.com/ruippeixotog/scala-scraper/blob/master/core/src/main/scala/net/ruippeixotog/scalascraper/browser/Browser.scala" target="_blank">Browser</a> implementations are the entrypoints for obtaining <code>Document</code> instances. Most notably, they implement <code>get</code>, <code>post</code>, <code>parseFile</code> and <code>parseString</code> methods for retrieving documents from different sources. Depending on the browser used, <code>Document</code> and <code>Element</code> instances may have different semantics, mainly on their immutability guarantees.</p> 
  <h2><a href="https://github.com/ruippeixotog/scala-scraper#browsers" aria-hidden="true" class="anchor" id="user-content-browsers" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Browsers</h2> 
  <p>The library currently provides two built-in implementations of <code>Browser</code>:</p> 
  <ul> 
   <li><a href="https://github.com/ruippeixotog/scala-scraper/blob/master/core/src/main/scala/net/ruippeixotog/scalascraper/browser/JsoupBrowser.scala" target="_blank">JsoupBrowser</a> is backed by <a href="http://jsoup.org/" target="_blank">jsoup</a>, a Java HTML parser library. <code>JsoupBrowser</code> provides powerful and efficient document querying, but it doesn't run JavaScript in the pages. As such, it is limited to working strictly with the HTML sent in the page source;</li> 
   <li><a href="https://github.com/ruippeixotog/scala-scraper/blob/master/core/src/main/scala/net/ruippeixotog/scalascraper/browser/HtmlUnitBrowser.scala" target="_blank">HtmlUnitBrowser</a> is based on <a href="http://htmlunit.sourceforge.net" target="_blank">HtmlUnit</a>, a GUI-less browser for Java programs. <code>HtmlUnitBrowser</code> simulates thoroughly a web browser, executing JavaScript code in the pages in addition to parsing HTML. It supports several compatibility modes, allowing it to emulate browsers such as Internet Explorer.</li> 
  </ul> 
  <p>Due to its speed and maturity, <code>JsoupBrowser</code> is the recommended browser to use when JavaScript execution is not needed. More information about each browser and its semantics can be obtained in the Scaladoc of each implementation.</p> 
  <h2><a href="https://github.com/ruippeixotog/scala-scraper#content-extraction" aria-hidden="true" class="anchor" id="user-content-content-extraction" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Content Extraction</h2> 
  <p>The <code>&gt;&gt;</code> and <code>&gt;?&gt;</code> operators shown above accept an <code>HtmlExtractor</code> as their right argument, a trait with a very simple interface:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">trait</span> <span class="pl-en">HtmlExtractor</span>[<span class="pl-k">-</span><span class="pl-en">E</span> <span class="pl-k">&lt;</span><span class="pl-k">:</span> <span class="pl-en">Element</span>, <span class="pl-k">+</span><span class="pl-en">A</span>] {
  <span class="pl-k">def</span> <span class="pl-en">extract</span>(<span class="pl-v">doc</span>: <span class="pl-en">ElementQuery</span>[<span class="pl-en">E</span>])<span class="pl-k">:</span> <span class="pl-en">A</span>
}</pre>
  </div> 
  <p>One can always create a custom extractor by implementing <code>HtmlExtractor</code>. However, the DSL provides several ways to create <code>HtmlExtractor</code> instances, which should be enough in most situations. In general, you can use the <code>extractor</code> factory method:</p> 
  <pre><code>doc &gt;&gt; extractor(&lt;cssQuery&gt;, &lt;contentExtractor&gt;, &lt;contentParser&gt;)
</code></pre> 
  <p>Where the arguments are:</p> 
  <ul> 
   <li><strong>cssQuery</strong>: the CSS query used to select the elements to be processed;</li> 
   <li><strong>contentExtractor</strong>: the content to be extracted from the selected elements, e.g. the element objects themselves, their text, a specific attribute, form data;</li> 
   <li><strong>contentParser</strong>: an optional parser for the data extracted in the step above, such as parsing numbers and dates or using regexes.</li> 
  </ul> 
  <p>The DSL provides several <code>contentExtractor</code> and <code>contentParser</code> instances, which were imported before with <code>DSL.Extract._</code> and <code>DSL.Parse._</code>. The full list can be seen in <a href="https://github.com/ruippeixotog/scala-scraper/blob/master/core/src/main/scala/net/ruippeixotog/scalascraper/scraper/ContentExtractors.scala" target="_blank">ContentExtractors.scala</a> and <a href="https://github.com/ruippeixotog/scala-scraper/blob/master/core/src/main/scala/net/ruippeixotog/scalascraper/scraper/ContentParsers.scala" target="_blank">ContentParsers.scala</a>.</p> 
  <p>Some usage examples:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> Extract the date from the "#date" element</span>
doc <span class="pl-k">&gt;&gt;</span> extractor(<span class="pl-s"><span class="pl-pds">"</span>#date<span class="pl-pds">"</span></span>, text, asLocalDate(<span class="pl-s"><span class="pl-pds">"</span>yyyy-MM-dd<span class="pl-pds">"</span></span>))
<span class="pl-c"><span class="pl-c">//</span> res17: org.joda.time.LocalDate = 2014-10-26</span>

<span class="pl-c"><span class="pl-c">//</span> Extract the text of all "#mytable td" elements and parse each of them as a number</span>
doc <span class="pl-k">&gt;&gt;</span> extractor(<span class="pl-s"><span class="pl-pds">"</span>#mytable td<span class="pl-pds">"</span></span>, texts, seq(asDouble))
<span class="pl-c"><span class="pl-c">//</span> res19: TraversableOnce[Double] = non-empty iterator</span>

<span class="pl-c"><span class="pl-c">//</span> Extract an element "h1" and do no parsing (the default parsing behavior)</span>
doc <span class="pl-k">&gt;&gt;</span> extractor(<span class="pl-s"><span class="pl-pds">"</span>h1<span class="pl-pds">"</span></span>, element, asIs[<span class="pl-en">Element</span>])
<span class="pl-c"><span class="pl-c">//</span> res21: net.ruippeixotog.scalascraper.model.Element = JsoupElement(&lt;h1&gt;Test page h1&lt;/h1&gt;)</span></pre>
  </div> 
  <p>With the help of the implicit conversions provided by the DSL, we can write more succinctly the most common extraction cases:</p> 
  <ul> 
   <li><code>&lt;cssQuery&gt;</code> is taken as <code>extractor(&lt;cssQuery&gt;, elements, asIs)</code> (by an implicit conversion);</li> 
   <li><code>&lt;contentExtractor&gt;</code> is taken as <code>extractor(":root", &lt;contentExtractor&gt;, asIs)</code> (content extractors are also <code>HtmlExtractor</code> instances by themselves);</li> 
   <li><code>&lt;contentExtractor&gt;(&lt;cssQuery&gt;)</code> is taken as <code>extractor(&lt;cssQuery&gt;, &lt;contentExtractor&gt;, asIs)</code> (by an implicit conversion).</li> 
  </ul> 
  <p>Because of that, one can write the expressions in the Quick Start section, as well as:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> Extract all the "h3" elements (as a lazy iterable)</span>
doc <span class="pl-k">&gt;&gt;</span> <span class="pl-s"><span class="pl-pds">"</span>h3<span class="pl-pds">"</span></span>
<span class="pl-c"><span class="pl-c">//</span> res23: net.ruippeixotog.scalascraper.model.ElementQuery[net.ruippeixotog.scalascraper.model.Element] =</span>
<span class="pl-c"><span class="pl-c">//</span> LazyElementQuery(WrappedArray(h3), JsoupElement(&lt;html lang="en"&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>  &lt;head&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>   &lt;meta charset="utf-8"&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>   &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>   &lt;title&gt;Test page&lt;/title&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>  &lt;/head&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>  &lt;body&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>   &lt;div id="wrapper"&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>    &lt;div id="header"&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;h1&gt;Test page h1&lt;/h1&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>    &lt;/div&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>    &lt;div id="menu"&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;span&gt;&lt;a href="#home"&gt;Home&lt;/a&gt;&lt;/span&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;span&gt;&lt;a href="#section1"&gt;Section 1&lt;/a&gt;&lt;/span&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;span class="active"&gt;Section 2&lt;/span&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;span&gt;&lt;a href="#section3"&gt;Section 3&lt;/a&gt;&lt;/span&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>    &lt;/div&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>    &lt;div id="content"&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;h2&gt;Test page h2&lt;/h2&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;span id="date"&gt;2014-10-26&lt;/span&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;span id="datefull"&gt;2014-10-26T12:30:05Z&lt;/span&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;span id="rating"&gt;4....</span>

<span class="pl-c"><span class="pl-c">//</span> Extract all text inside this document</span>
doc <span class="pl-k">&gt;&gt;</span> allText
<span class="pl-c"><span class="pl-c">//</span> res25: String = Test page Test page h1 Home Section 1 Section 2 Section 3 Test page h2 2014-10-26 2014-10-26T12:30:05Z 4.5 2 Section 1 h3 Some text for testing More text for testing Section 2 h3 My Form Add field Section 3 h3 3 15 15 1 No copyright 2014</span>

<span class="pl-c"><span class="pl-c">//</span> Extract the elements with class ".active"</span>
doc <span class="pl-k">&gt;&gt;</span> elementList(<span class="pl-s"><span class="pl-pds">"</span>.active<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res27: List[net.ruippeixotog.scalascraper.model.Element] = List(JsoupElement(&lt;span class="active"&gt;Section 2&lt;/span&gt;))</span>

<span class="pl-c"><span class="pl-c">//</span> Extract the text inside each "p" element</span>
doc <span class="pl-k">&gt;&gt;</span> texts(<span class="pl-s"><span class="pl-pds">"</span>p<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res29: Iterable[String] = List(Some text for testing, More text for testing)</span></pre>
  </div> 
  <h2><a href="https://github.com/ruippeixotog/scala-scraper#content-validation" aria-hidden="true" class="anchor" id="user-content-content-validation" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Content Validation</h2> 
  <p>While scraping web pages, it is a common use case to validate if a page effectively has the expected structure. This library provides special support for creating and applying validations.</p> 
  <p>A <code>HtmlValidator</code> has the following signature:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">trait</span> <span class="pl-en">HtmlValidator</span>[<span class="pl-k">-</span><span class="pl-en">E</span> <span class="pl-k">&lt;</span><span class="pl-k">:</span> <span class="pl-en">Element</span>, <span class="pl-k">+</span><span class="pl-en">R</span>] {
  <span class="pl-k">def</span> <span class="pl-en">matches</span>(<span class="pl-v">doc</span>: <span class="pl-en">ElementQuery</span>[<span class="pl-en">E</span>])<span class="pl-k">:</span> <span class="pl-k">Boolean</span>
  <span class="pl-k">def</span> <span class="pl-en">result</span><span class="pl-k">:</span> <span class="pl-en">Option</span>[<span class="pl-en">R</span>]
}</pre>
  </div> 
  <p>As with extractors, the DSL provides the <code>validator</code> constructor and the <code>&gt;/~</code> operator for applying a validation to a document:</p> 
  <pre><code>doc &gt;/~ validator(&lt;extractor&gt;)(&lt;matcher&gt;)
</code></pre> 
  <p>Where the arguments are:</p> 
  <ul> 
   <li><strong>extractor</strong>: an extractor as defined in the previous section;</li> 
   <li><strong>matcher</strong>: a function mapping the extracted content to a boolean indicating if the document is valid.</li> 
  </ul> 
  <p>The result of a validation is an <code>Either[R, A]</code> instance, where <code>A</code> is the type of the document and <code>R</code> is the result type of the validation (which will be explained later).</p> 
  <p>Some validation examples:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> Check if the title of the page is "Test page"</span>
doc <span class="pl-k">&gt;</span><span class="pl-k">/~</span> validator(text(<span class="pl-s"><span class="pl-pds">"</span>title<span class="pl-pds">"</span></span>))(_ <span class="pl-k">==</span> <span class="pl-s"><span class="pl-pds">"</span>Test page<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res31: Either[Unit,browser.DocumentType] =</span>
<span class="pl-c"><span class="pl-c">//</span> Right(JsoupDocument(&lt;!doctype html&gt;</span>
<span class="pl-c"><span class="pl-c">//</span> &lt;html lang="en"&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>  &lt;head&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>   &lt;meta charset="utf-8"&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>   &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>   &lt;title&gt;Test page&lt;/title&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>  &lt;/head&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>  &lt;body&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>   &lt;div id="wrapper"&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>    &lt;div id="header"&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;h1&gt;Test page h1&lt;/h1&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>    &lt;/div&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>    &lt;div id="menu"&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;span&gt;&lt;a href="#home"&gt;Home&lt;/a&gt;&lt;/span&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;span&gt;&lt;a href="#section1"&gt;Section 1&lt;/a&gt;&lt;/span&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;span class="active"&gt;Section 2&lt;/span&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;span&gt;&lt;a href="#section3"&gt;Section 3&lt;/a&gt;&lt;/span&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>    &lt;/div&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>    &lt;div id="content"&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;h2&gt;Test page h2&lt;/h2&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;span id="date"&gt;2014-10-26&lt;/span&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;span id="datefull"&gt;2014-10-26T12:30:05Z&lt;/span&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;span id="rating"&gt;4.5&lt;/span&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;span id="pages"&gt;2&lt;/span&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>     &lt;section&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>      &lt;h3&gt;Section 1 h3&lt;/h3&gt;</span>
<span class="pl-c"><span class="pl-c">//</span>      &lt;p&gt;Some text ...</span>

<span class="pl-c"><span class="pl-c">//</span> Check if there are at least 3 ".active" elements</span>
doc <span class="pl-k">&gt;</span><span class="pl-k">/~</span> validator(<span class="pl-s"><span class="pl-pds">"</span>.active<span class="pl-pds">"</span></span>)(_.size <span class="pl-k">&gt;=</span> <span class="pl-c1">3</span>)
<span class="pl-c"><span class="pl-c">//</span> res33: Either[Unit,browser.DocumentType] = Left(())</span>

<span class="pl-c"><span class="pl-c">//</span> Check if the text in ".desc" contains the word "blue"</span>
doc <span class="pl-k">&gt;</span><span class="pl-k">/~</span> validator(allText(<span class="pl-s"><span class="pl-pds">"</span>#mytable<span class="pl-pds">"</span></span>))(_.contains(<span class="pl-s"><span class="pl-pds">"</span>blue<span class="pl-pds">"</span></span>))
<span class="pl-c"><span class="pl-c">//</span> res35: Either[Unit,browser.DocumentType] = Left(())</span></pre>
  </div> 
  <p>When a document fails a validation, it may be useful to identify the problem by pattern-matching it against common scraping pitfalls, such as a login page that appears unexpectedly because of an expired cookie, dynamic content that disappeared or server-side errors. If we define validators for both the success case and error cases:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">val</span> <span class="pl-en">succ</span> <span class="pl-k">=</span> validator(text(<span class="pl-s"><span class="pl-pds">"</span>title<span class="pl-pds">"</span></span>))(_ <span class="pl-k">==</span> <span class="pl-s"><span class="pl-pds">"</span>My Page<span class="pl-pds">"</span></span>)

<span class="pl-k">val</span> <span class="pl-en">errors</span> <span class="pl-k">=</span> <span class="pl-en">Seq</span>(
  validator(allText(<span class="pl-s"><span class="pl-pds">"</span>.msg<span class="pl-pds">"</span></span>), <span class="pl-s"><span class="pl-pds">"</span>Not logged in<span class="pl-pds">"</span></span>)(_.contains(<span class="pl-s"><span class="pl-pds">"</span>sign in<span class="pl-pds">"</span></span>)),
  validator(<span class="pl-s"><span class="pl-pds">"</span>.item<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>Too few items<span class="pl-pds">"</span></span>)(_.size <span class="pl-k">&lt;</span> <span class="pl-c1">3</span>),
  validator(text(<span class="pl-s"><span class="pl-pds">"</span>h1<span class="pl-pds">"</span></span>), <span class="pl-s"><span class="pl-pds">"</span>Internal Server Error<span class="pl-pds">"</span></span>)(_.contains(<span class="pl-s"><span class="pl-pds">"</span>500<span class="pl-pds">"</span></span>)))</pre>
  </div> 
  <p>They can be used in combination to create more informative validations:</p> 
  <div class="highlight highlight-source-scala">
   <pre>doc <span class="pl-k">&gt;</span><span class="pl-k">/~</span> (succ, errors)
<span class="pl-c"><span class="pl-c">//</span> res37: Either[String,browser.DocumentType] = Left(Too few items)</span></pre>
  </div> 
  <p>Validators matching errors were constructed above using an additional <code>result</code> parameter after the extractor. That value is returned wrapped in a <code>Left</code> if that particular error occurs during a validation.</p> 
  <h2><a href="https://github.com/ruippeixotog/scala-scraper#other-dsl-features" aria-hidden="true" class="anchor" id="user-content-other-dsl-features" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Other DSL Features</h2> 
  <p>As shown before in the Quick Start section, one can try if an extractor works in a page and obtain the extracted content wrapped in an <code>Option</code>:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> Try to extract an element with id "optional", return `None` if none exist</span>
doc <span class="pl-k">&gt;</span><span class="pl-k">?</span><span class="pl-k">&gt;</span> element(<span class="pl-s"><span class="pl-pds">"</span>#optional<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res39: Option[net.ruippeixotog.scalascraper.model.Element] = None</span></pre>
  </div> 
  <p>Note that when using <code>&gt;?&gt;</code> with content extractors that return sequences, such as <code>texts</code> and <code>elements</code>, <code>None</code> will never be returned (<code>Some(Seq())</code> will be returned instead).</p> 
  <p>If you want to use multiple extractors in a single document or element, you can pass tuples or triples to <code>&gt;&gt;</code>:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> Extract the text of the title element and all inputs of #myform</span>
doc <span class="pl-k">&gt;&gt;</span> (text(<span class="pl-s"><span class="pl-pds">"</span>title<span class="pl-pds">"</span></span>), elementList(<span class="pl-s"><span class="pl-pds">"</span>#myform input<span class="pl-pds">"</span></span>))
<span class="pl-c"><span class="pl-c">//</span> res41: (String, List[net.ruippeixotog.scalascraper.model.Element]) = (Test page,List(JsoupElement(&lt;input type="text" name="name" value="John"&gt;), JsoupElement(&lt;input type="text" name="address"&gt;), JsoupElement(&lt;input type="submit" value="Submit"&gt;)))</span></pre>
  </div> 
  <p>The extraction operators work on <code>List</code>, <code>Option</code>, <code>Either</code> and other instances for which a <a href="https://github.com/scalaz/scalaz" target="_blank">Scalaz</a> <code>Functor</code> instance exists. The extraction occurs by mapping over the functors:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> Extract the titles of all documents in the list</span>
<span class="pl-en">List</span>(doc, doc) <span class="pl-k">&gt;&gt;</span> text(<span class="pl-s"><span class="pl-pds">"</span>title<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res43: List[String] = List(Test page, Test page)</span>

<span class="pl-c"><span class="pl-c">//</span> Extract the title if the document is a `Some`</span>
<span class="pl-en">Option</span>(doc) <span class="pl-k">&gt;&gt;</span> text(<span class="pl-s"><span class="pl-pds">"</span>title<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res45: Option[String] = Some(Test page)</span></pre>
  </div> 
  <p>You can apply other extractors and validators to the result of an extraction, which is particularly powerful combined with the feature shown above:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> From the "#menu" element, extract the text in the ".active" element inside</span>
doc <span class="pl-k">&gt;&gt;</span> element(<span class="pl-s"><span class="pl-pds">"</span>#menu<span class="pl-pds">"</span></span>) <span class="pl-k">&gt;&gt;</span> text(<span class="pl-s"><span class="pl-pds">"</span>.active<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res47: String = Section 2</span>

<span class="pl-c"><span class="pl-c">//</span> Same as above, but in a scenario where "#menu" can be absent</span>
doc <span class="pl-k">&gt;</span><span class="pl-k">?</span><span class="pl-k">&gt;</span> element(<span class="pl-s"><span class="pl-pds">"</span>#menu<span class="pl-pds">"</span></span>) <span class="pl-k">&gt;&gt;</span> text(<span class="pl-s"><span class="pl-pds">"</span>.active<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res49: Option[String] = Some(Section 2)</span>

<span class="pl-c"><span class="pl-c">//</span> Same as above, but check if the "#menu" has any "span" element before</span>
<span class="pl-c"><span class="pl-c">//</span> extracting the text</span>
doc <span class="pl-k">&gt;</span><span class="pl-k">?</span><span class="pl-k">&gt;</span> element(<span class="pl-s"><span class="pl-pds">"</span>#menu<span class="pl-pds">"</span></span>) <span class="pl-k">&gt;</span><span class="pl-k">/~</span> validator(<span class="pl-s"><span class="pl-pds">"</span>span<span class="pl-pds">"</span></span>)(_.nonEmpty) <span class="pl-k">&gt;&gt;</span> text(<span class="pl-s"><span class="pl-pds">"</span>.active<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res52: Option[scala.util.Either[Unit,String]] = Some(Right(Section 2))</span>

<span class="pl-c"><span class="pl-c">//</span> Extract the links inside all the "#menu &gt; span" elements</span>
doc <span class="pl-k">&gt;&gt;</span> elementList(<span class="pl-s"><span class="pl-pds">"</span>#menu &gt; span<span class="pl-pds">"</span></span>) <span class="pl-k">&gt;</span><span class="pl-k">?</span><span class="pl-k">&gt;</span> attr(<span class="pl-s"><span class="pl-pds">"</span>href<span class="pl-pds">"</span></span>)(<span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res54: List[Option[String]] = List(Some(#home), Some(#section1), None, Some(#section3))</span></pre>
  </div> 
  <p>This library also provides a <code>Functor</code> for <code>HtmlExtractor</code>, making it possible to map over extractors and create chained extractors that can be passed around and stored like objects. For example, new extractors can be defined like this:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">net.ruippeixotog.scalascraper.scraper.</span><span class="pl-v">HtmlExtractor</span>

<span class="pl-c"><span class="pl-c">//</span> An extractor for a list with the first link found in each "span" element</span>
<span class="pl-k">val</span> <span class="pl-en">spanLinks</span><span class="pl-k">:</span> <span class="pl-en">HtmlExtractor</span>[<span class="pl-en">Element</span>, <span class="pl-en">List</span>[<span class="pl-en">Option</span>[<span class="pl-k">String</span>]]] <span class="pl-k">=</span>
  elementList(<span class="pl-s"><span class="pl-pds">"</span>span<span class="pl-pds">"</span></span>) <span class="pl-k">&gt;</span><span class="pl-k">?</span><span class="pl-k">&gt;</span> attr(<span class="pl-s"><span class="pl-pds">"</span>href<span class="pl-pds">"</span></span>)(<span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">//</span> An extractor for the number of "span" elements that actually have links</span>
<span class="pl-k">val</span> <span class="pl-en">spanLinksCount</span><span class="pl-k">:</span> <span class="pl-en">HtmlExtractor</span>[<span class="pl-en">Element</span>, <span class="pl-k">Int</span>] <span class="pl-k">=</span>
  spanLinks.map(_.flatten.length)</pre>
  </div> 
  <p>You can also "prepend" a query to any existing extractor by using its <code>mapQuery</code> method:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> An extractor for `spanLinks` that are inside "#menu"</span>
<span class="pl-k">val</span> <span class="pl-en">menuLinks</span><span class="pl-k">:</span> <span class="pl-en">HtmlExtractor</span>[<span class="pl-en">Element</span>, <span class="pl-en">List</span>[<span class="pl-en">Option</span>[<span class="pl-k">String</span>]]] <span class="pl-k">=</span>
  spanLinks.mapQuery(<span class="pl-s"><span class="pl-pds">"</span>#menu<span class="pl-pds">"</span></span>)</pre>
  </div> 
  <p>And they can be used just as extractors created using other means provided by the DSL:</p> 
  <div class="highlight highlight-source-scala">
   <pre>doc <span class="pl-k">&gt;&gt;</span> spanLinks
<span class="pl-c"><span class="pl-c">//</span> res60: List[Option[String]] = List(Some(#home), Some(#section1), None, Some(#section3), None, None, None, None, None, Some(#), None)</span>

doc <span class="pl-k">&gt;&gt;</span> spanLinksCount
<span class="pl-c"><span class="pl-c">//</span> res61: Int = 4</span>

doc <span class="pl-k">&gt;&gt;</span> menuLinks
<span class="pl-c"><span class="pl-c">//</span> res62: List[Option[String]] = List(Some(#home), Some(#section1), None, Some(#section3))</span></pre>
  </div> 
  <p>Just remember that you can only apply extraction operators <code>&gt;&gt;</code> and <code>&gt;?&gt;</code> to documents, elements or functors "containing" them, which means that the following is a compile-time error:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> The `texts` extractor extracts a list of strings and extractors cannot be</span>
<span class="pl-c"><span class="pl-c">//</span> applied to strings</span>
doc <span class="pl-k">&gt;&gt;</span> texts(<span class="pl-s"><span class="pl-pds">"</span>#menu &gt; span<span class="pl-pds">"</span></span>) <span class="pl-k">&gt;&gt;</span> <span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>
<span class="pl-c"><span class="pl-c">//</span> &lt;console&gt;:30: error: value &gt;&gt; is not a member of Iterable[String]</span>
<span class="pl-c"><span class="pl-c">//</span>        doc &gt;&gt; texts("#menu &gt; span") &gt;&gt; "a"</span>
<span class="pl-c"><span class="pl-c">//</span>                                     ^</span></pre>
  </div> 
  <p>Finally, if you prefer not using operators for the sake of code legibility, you can use alternative methods:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> `extract` is the same as `&gt;&gt;`</span>
doc extract text(<span class="pl-s"><span class="pl-pds">"</span>title<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res67: String = Test page</span>

<span class="pl-c"><span class="pl-c">//</span> `tryExtract` is the same as `&gt;?&gt;`</span>
doc tryExtract element(<span class="pl-s"><span class="pl-pds">"</span>#optional<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res69: Option[net.ruippeixotog.scalascraper.model.Element] = None</span>

<span class="pl-c"><span class="pl-c">//</span> `validateWith` is the same as `&gt;/~`</span>
doc validateWith (succ, errors)
<span class="pl-c"><span class="pl-c">//</span> res71: Either[String,browser.DocumentType] = Left(Too few items)</span></pre>
  </div> 
  <h2><a href="https://github.com/ruippeixotog/scala-scraper#using-browser-specific-features" aria-hidden="true" class="anchor" id="user-content-using-browser-specific-features" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Using Browser-Specific Features</h2> 
  <p><em>NOTE: this feature is in a beta stage. Please expect API changes in future releases.</em></p> 
  <p>At this moment, Scala Scraper is focused on providing a DSL for querying documents efficiently and elegantly. Therefore, it doesn't support directly modifying the DOM or executing actions such as clicking an element. However, since version 2.0.0 a new typed element API allows users to interact directly with the data structures of the underlying <code>Browser</code> implementation.</p> 
  <p>First of all, make sure your <code>Browser</code> instance has a concrete type, like <code>HtmlUnitBrowser</code>:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">net.ruippeixotog.scalascraper.browser.</span><span class="pl-v">HtmlUnitBrowser</span>
<span class="pl-k">import</span> <span class="pl-v">net.ruippeixotog.scalascraper.browser.HtmlUnitBrowser.</span><span class="pl-v">_</span>

<span class="pl-c"><span class="pl-c">//</span> the `typed` method on the companion object of a `Browser` returns instances</span>
<span class="pl-c"><span class="pl-c">//</span> with their concrete type</span>
<span class="pl-k">val</span> <span class="pl-en">typedBrowser</span><span class="pl-k">:</span> <span class="pl-en">HtmlUnitBrowser</span> <span class="pl-k">=</span> <span class="pl-en">HtmlUnitBrowser</span>.typed()

<span class="pl-k">val</span> <span class="pl-en">typedDoc</span><span class="pl-k">:</span> <span class="pl-en">HtmlUnitDocument</span> <span class="pl-k">=</span> typedBrowser.parseFile(<span class="pl-s"><span class="pl-pds">"</span>core/src/test/resources/example.html<span class="pl-pds">"</span></span>)</pre>
  </div> 
  <p>Note that the <code>val</code> declarations are explicitly typed for explanation purposes only; the methods work just as well when types are inferred.</p> 
  <p>The content extractors <code>pElement</code>, <code>pElements</code> and <code>pElementList</code> are special types of extractors - they are polymorphic extractors. They work just like their non-polymorphic <code>element</code>, <code>elements</code> and <code>elementList</code> extractors, but they propagate the concrete types of the elements if the document or element being extracted also has a concrete type. For example:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> extract the "a" inside the second child of "#menu"</span>
<span class="pl-k">val</span> <span class="pl-en">aElem</span> <span class="pl-k">=</span> typedDoc <span class="pl-k">&gt;&gt;</span> pElement(<span class="pl-s"><span class="pl-pds">"</span>#menu span:nth-child(2) a<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> aElem: net.ruippeixotog.scalascraper.browser.HtmlUnitBrowser.HtmlUnitElement = HtmlUnitElement(HtmlAnchor[&lt;a href="#section1"&gt;])</span></pre>
  </div> 
  <p>Note that extracting using CSS queries also keeps the concrete types of the elements:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> same thing as above</span>
typedDoc <span class="pl-k">&gt;&gt;</span> <span class="pl-s"><span class="pl-pds">"</span>#menu<span class="pl-pds">"</span></span> <span class="pl-k">&gt;&gt;</span> <span class="pl-s"><span class="pl-pds">"</span>span:nth-child(2)<span class="pl-pds">"</span></span> <span class="pl-k">&gt;&gt;</span> <span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span> <span class="pl-k">&gt;&gt;</span> pElement
<span class="pl-c"><span class="pl-c">//</span> res78: net.ruippeixotog.scalascraper.dsl.DSL.Extract.pElement.Out[net.ruippeixotog.scalascraper.browser.HtmlUnitBrowser.HtmlUnitElement] = HtmlUnitElement(HtmlAnchor[&lt;a href="#section1"&gt;])</span></pre>
  </div> 
  <p>Concrete element types, like <code>HtmlUnitElement</code>, expose a public <code>underlying</code> field with the underlying element object used by the browser backend. In the case of HtmlUnit, that would be a <a href="http://htmlunit.sourceforge.net/apidocs/com/gargoylesoftware/htmlunit/html/DomElement.html" target="_blank"><code>DomElement</code></a>, which exposes a whole new range of operations:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> extract the current "href" this "a" element points to</span>
aElem <span class="pl-k">&gt;&gt;</span> attr(<span class="pl-s"><span class="pl-pds">"</span>href<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res80: String = #section1</span>

<span class="pl-c"><span class="pl-c">//</span> use `underlying` to update the "href" attribute</span>
aElem.underlying.setAttribute(<span class="pl-s"><span class="pl-pds">"</span>href<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>#section1_2<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">//</span> verify that "href" was updated</span>
aElem <span class="pl-k">&gt;&gt;</span> attr(<span class="pl-s"><span class="pl-pds">"</span>href<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">//</span> res84: String = #section1_2</span>

<span class="pl-c"><span class="pl-c">//</span> get the location of the document (without the host and the full path parts)</span>
typedDoc.location.split(<span class="pl-s"><span class="pl-pds">"</span>/<span class="pl-pds">"</span></span>).last
<span class="pl-c"><span class="pl-c">//</span> res86: String = example.html</span>

<span class="pl-k">def</span> <span class="pl-en">click</span>(<span class="pl-v">elem</span>: <span class="pl-en">HtmlUnitElement</span>) {
  <span class="pl-c"><span class="pl-c">//</span> the type param may be needed, as the original API uses Java wildcards</span>
  aElem.underlying.click[com.gargoylesoftware.htmlunit.<span class="pl-en">Page</span>]()
}
<span class="pl-c"><span class="pl-c">//</span> click: (elem: net.ruippeixotog.scalascraper.browser.HtmlUnitBrowser.HtmlUnitElement)Unit</span>

<span class="pl-c"><span class="pl-c">//</span> simulate a click on our recently modified element</span>
click(aElem)

<span class="pl-c"><span class="pl-c">//</span> check the new location</span>
typedDoc.location.split(<span class="pl-s"><span class="pl-pds">"</span>/<span class="pl-pds">"</span></span>).last
<span class="pl-c"><span class="pl-c">//</span> res90: String = example.html#section1_2</span></pre>
  </div> 
  <p>Using the typed element API provides much more flexibility when more than querying elements is required. However, one should avoid using it unless strictly necessary, as:</p> 
  <ul> 
   <li>It binds code to specific <code>Browser</code> implementations, making it more difficult to change implementations later;</li> 
   <li>The code becomes subject to changes in the API of the underlying library;</li> 
   <li>It's heavier on the Scala type system and it is not as mature, leading to possible unexpected compilation errors. If that happens, please file an issue!</li> 
  </ul> 
  <h2><a href="https://github.com/ruippeixotog/scala-scraper#working-behind-an-httphttps-proxy" aria-hidden="true" class="anchor" id="user-content-working-behind-an-httphttps-proxy" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Working Behind an HTTP/HTTPS Proxy</h2> 
  <p><em>NOTE: this feature is in a beta stage. Please expect API changes in future releases.</em></p> 
  <p>If you are behind an HTTP proxy, you can configure <code>Browser</code> implementations to make connections through it by setting the Java system properties <code>http.proxyHost</code>, <code>https.proxyHost</code>, <code>http.proxyPort</code> and <code>https.proxyPort</code>. Scala Scraper provides a <code>ProxyUtils</code> object that facilitates that configuration:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">net.ruippeixotog.scalascraper.util.</span><span class="pl-v">ProxyUtils</span>

<span class="pl-en">ProxyUtils</span>.setProxy(<span class="pl-s"><span class="pl-pds">"</span>localhost<span class="pl-pds">"</span></span>, <span class="pl-c1">3128</span>)
<span class="pl-k">val</span> <span class="pl-en">browser</span> <span class="pl-k">=</span> <span class="pl-en">JsoupBrowser</span>()
<span class="pl-c"><span class="pl-c">//</span> HTTP requests and scraping operations...</span>
<span class="pl-en">ProxyUtils</span>.removeProxy()</pre>
  </div> 
  <p><code>JsoupBrowser</code> uses internally <code>java.net.HttpURLConnection</code>. Configuring those JVM-wide system properties will affect not only <code>Browser</code> instances, but <em>all</em> requests done using <code>HttpURLConnection</code> directly or indirectly. <code>HtmlUnitBrowser</code> was implementated so that it reads the same system properties for configuration, but once the browser is created they will be used on every request done by the instance, regardless of the properties' values at the time of the request.</p> 
  <h2><a href="https://github.com/ruippeixotog/scala-scraper#integration-with-typesafe-config" aria-hidden="true" class="anchor" id="user-content-integration-with-typesafe-config" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Integration with Typesafe Config</h2> 
  <p>The <a href="https://github.com/ruippeixotog/scala-scraper/blob/master/modules/config/README.md" target="_blank">Scala Scraper Config module</a> can be used to load extractors and validators from config files.</p> 
  <h2><a href="https://github.com/ruippeixotog/scala-scraper#new-features-and-migration-guide" aria-hidden="true" class="anchor" id="user-content-new-features-and-migration-guide" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>New Features and Migration Guide</h2> 
  <p>The <a href="https://github.com/ruippeixotog/scala-scraper/blob/master/CHANGELOG.md" target="_blank">CHANGELOG</a> is kept updated with the bug fixes and new features of each version. When there are breaking changes, they are listed there together with suggestions for migrating old code.</p> 
  <h2><a href="https://github.com/ruippeixotog/scala-scraper#copyright" aria-hidden="true" class="anchor" id="user-content-copyright" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Copyright</h2> 
  <p>Copyright (c) 2014-2017 Rui Gonçalves. See LICENSE for details.</p> 
 </article>
</div>