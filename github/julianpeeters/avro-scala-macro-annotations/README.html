<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <p>##Herein lie assorted macro annotations for working with Avro in Scala:</p> 
  <ol> 
   <li> <p><code>@AvroTypeProvider("path/to/schema")</code> - Convert Avro Schemas to Scala case class definitions for use in your favorite Scala Avro runtime.</p> </li> 
   <li> <p><code>@AvroRecord</code> - Use Scala case classes to represent your Avro SpecificRecords, serializable by the Apache Avro runtime (a port of <a href="https://code.google.com/p/avro-scala-compiler-plugin/" target="_blank">Avro-Scala-Compiler-Plugin</a>).</p> </li> 
  </ol> 
  <p>Macros are an experimental feature of Scala. <a href="https://github.com/julianpeeters/avrohugger" target="_blank">Avrohugger</a> is a more traditional alternative.</p> 
  <p>####Get the dependency: For Scala 2.11.x and 2.12.x (<a href="https://github.com/julianpeeters/avro-scala-macro-annotations/issues/6#issuecomment-77973333" target="_blank">for Scala 2.10.x</a> please use version 0.4.9 with sbt 0.13.8+):</p> 
  <pre><code>    libraryDependencies += "com.julianpeeters" % "avro-scala-macro-annotations_2.11" % "0.11.1"
</code></pre> 
  <p>Macro annotations are only available in Scala 2.10.x, 2.11.x, and 2.12.x with the macro paradise plugin. Their inclusion in official Scala might happen in Scala 2.13 - <a href="http://docs.scala-lang.org/overviews/macros/annotations.html" target="_blank">official docs</a>. To use the plugin, add the following <code>build.sbt</code>:</p> 
  <pre><code>    addCompilerPlugin("org.scalamacros" % "paradise" % "2.1.0" cross CrossVersion.full)
</code></pre> 
  <p>In your IDE of choice you may have to explicitly load this compiler plugin. In Eclipse for example, you can do so by providing the full path under the <code>Xplugin</code>, found in the advanced Scala compiler preferences; you should have the jar in a path like <code>~/.ivy2/cache/org.scalamacros/paradise_2.10.4/jars/paradise_2.10.4-2.0.1.jar</code>.</p> 
  <p>####Usage: Use the annotations separately, or together like this:</p> 
  <div class="highlight highlight-source-scala">
   <pre>        <span class="pl-k">package</span> <span class="pl-en">sample</span>

        <span class="pl-k">import</span> <span class="pl-v">com.julianpeeters.avro.annotations.</span><span class="pl-v">_</span>

        <span class="pl-k">@</span><span class="pl-en">AvroTypeProvider</span>(<span class="pl-s"><span class="pl-pds">"</span>data/input.avro<span class="pl-pds">"</span></span>)
        <span class="pl-k">@</span><span class="pl-en">AvroRecord</span>
        <span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">MyRecord</span>()</pre>
  </div> 
  <p>First the fields are added automatically from an Avro Schema in a file, then the methods necessary for de/serialization are generated for you, all at compile time. Please see warnings below.</p> 
  <p>####Supported data types:</p> 
  <p><code>int</code></p> 
  <p><code>float</code></p> 
  <p><code>long</code></p> 
  <p><code>double</code></p> 
  <p><code>boolean</code></p> 
  <p><code>string</code></p> 
  <p><code>null</code></p> 
  <p><code>array</code>*</p> 
  <p><code>map</code></p> 
  <p><code>record</code></p> 
  <p><code>union</code>**</p> 
  <p>*Arrays are represented by <code>List[T]</code>, where T is any other supported type.</p> 
  <p>**Optional fields of type <code>[null, t]</code> are represented by <code>Option[T]</code></p> 
  <p>The remaining avro types, <code>fixed</code>, <code>enum</code>, and <code>union</code> (beyond nullable fields), are not yet supported.</p> 
  <p>##1) Avro-Type-Provider If your use-case is "data-first" and you're using an Avro runtime library that allows you to use Scala case classes to represent your Avro records, then you are probably a little weary of transcribing Avro Schemas into their Scala case class equivalents.</p> 
  <p>Annotate an "empty" case class, and its members will be generated automatically at compile time using the data found in the Schema of a given file:</p> 
  <p>given the schema automatically found in <code>input.avro</code> or <code>input.avsc</code>:</p> 
  <pre><code>        {"type":"record","name":"MyRecord","namespace":"tutorial","doc":"Auto-generated schema","fields":[{"name":"x","type":{"type":"record","name":"Rec","doc":"Auto-generated schema","fields":[{"name":"i","type":"int","doc":"Auto-Generated Field"}]},"doc":"Auto-Generated Field","default":{"i":4}}]}}
</code></pre> 
  <p>annotated empty case classes:</p> 
  <div class="highlight highlight-source-scala">
   <pre>        <span class="pl-k">import</span> <span class="pl-v">com.julianpeeters.avro.annotations.</span><span class="pl-v">_</span>

        <span class="pl-k">@</span><span class="pl-en">AvroTypeProvider</span>(<span class="pl-s"><span class="pl-pds">"</span>data/input.avro<span class="pl-pds">"</span></span>)
        <span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">Rec</span>()

        <span class="pl-k">@</span><span class="pl-en">AvroTypeProvider</span>(<span class="pl-s"><span class="pl-pds">"</span>data/input.avro<span class="pl-pds">"</span></span>)
        <span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">MyRecord</span>()</pre>
  </div> 
  <p>expand to:</p> 
  <div class="highlight highlight-source-scala">
   <pre>       <span class="pl-k">package</span> <span class="pl-en">tutorial</span>

       <span class="pl-k">import</span> <span class="pl-v">com.julianpeeters.avro.annotations.</span><span class="pl-v">_</span>

       <span class="pl-k">@</span><span class="pl-en">AvroTypeProvider</span>(<span class="pl-s"><span class="pl-pds">"</span>data/input.avro<span class="pl-pds">"</span></span>)
       <span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">Rec</span>(<span class="pl-v">i</span>: <span class="pl-k">Int</span>)

       <span class="pl-k">@</span><span class="pl-en">AvroTypeProvider</span>(<span class="pl-s"><span class="pl-pds">"</span>data/input.avro<span class="pl-pds">"</span></span>)
       <span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">MyRecord</span>(<span class="pl-v">x</span>: <span class="pl-en">Rec</span> <span class="pl-k">=</span> <span class="pl-en">Rec</span>(<span class="pl-c1">4</span>))</pre>
  </div> 
  <p>####Please note:</p> 
  <ol> 
   <li> <p>The datafile must be available at compile time.</p> </li> 
   <li> <p>The filepath must be a String literal.</p> </li> 
   <li> <p>The name of the empty case class must match the record name exactly (peek at the schema in the file, if needed).</p> </li> 
   <li> <p>The order of class definition must be such that the classes that represent the most-nested records are expanded first.</p> </li> 
   <li> <p>A class that is doubly annotated with <code>@AvroTypeProvider</code> and <code>@AvroRecord</code> will be updated with vars instead of vals.</p> </li> 
  </ol> 
  <p>##2) Avro-Record: Implements <code>SpecificRecord</code> at compile time so you can use Scala case classes to represent Avro records (like <a href="https://github.com/GenslerAppsPod/scalavro" target="_blank">Scalavro</a> or <a href="https://github.com/julianpeeters/salat-avro/tree/master" target="_blank">Salat-Avro</a>, but for the Apache Avro runtime so that it runs on your cluster). Since Avro-Scala-Compiler-Plugin doesn't work with Scala 2.10+ and the compiler still stumps me, I ported the serialization essentials over to use <a href="http://docs.scala-lang.org/overviews/macros/annotations.html" target="_blank">Scala Macro Annotations</a> instead.</p> 
  <p>Now you can annotate a case class that you'd like to have serve as your Avro record:</p> 
  <div class="highlight highlight-source-scala">
   <pre>        <span class="pl-k">package</span> <span class="pl-en">sample</span>

        <span class="pl-k">@</span><span class="pl-en">AvroRecord</span>
        <span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">A</span>(<span class="pl-k">var</span> <span class="pl-en">i</span><span class="pl-k">:</span> <span class="pl-k">Int</span>)

        <span class="pl-k">@</span><span class="pl-en">AvroRecord</span>
        <span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">B</span>(<span class="pl-k">var</span> <span class="pl-en">a</span><span class="pl-k">:</span> <span class="pl-en">Option</span>[<span class="pl-en">A</span>] <span class="pl-k">=</span> <span class="pl-c1">None</span>)</pre>
  </div> 
  <p>expands to implement <code>SpecificRecord</code>, adding <code>put</code>, <code>get</code>, and <code>getSchema</code> methods, and a static <code>lazy val SCHEMA$</code> with the schema:</p> 
  <pre><code>        {"type":"record","name":"B","namespace":"sample","doc":"Auto-generated schema","fields":[{"name":"a","type":["null",{"type":"record","name":"A","doc":"Auto-generated schema","fields":[{"name":"i","type":"int","doc":"Auto-Generated Field"}]}],"doc":"Auto-Generated Field",default: null}]}
</code></pre> 
  <p>Use the expanded class as you would a code-gen'd class with any <code>SpecificRecord</code> API. e.g.:</p> 
  <div class="highlight highlight-source-scala">
   <pre>        <span class="pl-c"><span class="pl-c">//</span>Writing avros</span>
        <span class="pl-k">val</span> <span class="pl-en">datumWriter</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">SpecificDatumWriter</span>[<span class="pl-en">B</span>](<span class="pl-en">B</span>.<span class="pl-en">SCHEMA</span>$)
        <span class="pl-k">val</span> <span class="pl-en">dataFileWriter</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">DataFileWriter</span>[<span class="pl-en">B</span>](datumWriter)


        <span class="pl-c"><span class="pl-c">//</span>Reading avros</span>
        <span class="pl-k">val</span> <span class="pl-en">userDatumReader</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">SpecificDatumReader</span>[<span class="pl-en">B</span>](<span class="pl-en">B</span>.<span class="pl-en">SCHEMA</span>$)
        <span class="pl-k">val</span> <span class="pl-en">dataFileReader</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">DataFileReader</span>[<span class="pl-en">B</span>](file, userDatumReader)</pre>
  </div> 
  <p>####Please note:</p> 
  <ol> 
   <li> <p>If your framework is one that relies on reflection to get the Schema, it will fail since Scala fields are private. Therefore preempt it by passing in a Schema to DatumReaders and DatumWriters (as in the Avro example above).</p> </li> 
   <li> <p>Fields must be <code>var</code>s in order to be compatible with the SpecificRecord API.</p> </li> 
   <li> <p>A class that is doubly annotated with <code>@AvroTypeProvider</code> and <code>@AvroRecord</code> will automatically be updated with vars instead of vals.</p> </li> 
   <li> <p>An annotatee may extend a trait (to become a mixin after expansion) but not a class, since SpecificRecordBase will need to occupy that position.</p> </li> 
  </ol> 
 </article>
</div>