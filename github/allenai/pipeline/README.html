<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a id="user-content-allen-ai-pipeline-framework" class="anchor" href="https://github.com/allenai/pipeline#allen-ai-pipeline-framework" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Allen-AI Pipeline Framework</h1> 
  <p>The Allen-AI Pipeline (AIP) framework is a library that facilitates collaborative on data-driven projects. It allows users to define workflows that share data resources transparently while maintaining complete freedom over the environment in which those workflows execute. AIP falls somewhere between unix make and KNIME. Unlike make, it can operate on cloud storage resources and execute in a distributed environment. Unlike KNIME, it does not lock you into any particular repository for storing your data or execution environment in which the workflows must run.</p> 
  <p>AIP can be used in two ways:</p> 
  <ol> 
   <li>As <a href="https://github.com/allenai/pipeline/blob/master/docs/PipeScript.md" target="_blank">PipeScript</a>, a binary that interprets a simple scripting language to execute native commands locally and store the results remotely</li> 
   <li>Via the <a href="https://github.com/allenai/pipeline/blob/master/docs/README.md" target="_blank">Scala API</a> to define workflows that produce strongly-typed objects and execute within any JVM-based environment.</li> 
  </ol> 
  <p>In summary, AIP provides the following benefits:</p> 
  <ul> 
   <li>Intermediate data is cached and is sharable by different users on different systems.</li> 
   <li>A record of past runs is maintained, with navigable links to all inputs/output of the pipeline.</li> 
   <li>A pipeline can be visualized before running.</li> 
   <li>Output resource naming is managed to eliminate naming collisions.</li> 
   <li>Input/output data is always compatible with the code reading the data.</li> 
  </ul> 
  <p>Send questions to <em><a href="mailto:rodneyk@allenai.org" target="_blank">rodneyk@allenai.org</a></em></p> 
 </article>
</div>