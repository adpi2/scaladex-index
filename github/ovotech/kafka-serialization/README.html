<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a href="https://github.com/ovotech/kafka-serialization#kafka-serializationdeserialization-building-blocks" aria-hidden="true" class="anchor" id="user-content-kafka-serializationdeserialization-building-blocks" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Kafka serialization/deserialization building blocks</h1> 
  <p><a href="https://circleci.com/gh/ovotech/kafka-serialization" target="_blank"><img src="https://camo.githubusercontent.com/ec3d8dac3762ccaa3bfc0031d6ab63fc06ae0ea1/68747470733a2f2f636972636c6563692e636f6d2f67682f6f766f746563682f6b61666b612d73657269616c697a6174696f6e2e7376673f7374796c653d736869656c64" alt="CircleCI Badge" data-canonical-src="https://circleci.com/gh/ovotech/kafka-serialization.svg?style=shield" style="max-width:100%;"></a> <a href="https://www.codacy.com/app/filippo-deluca/kafka-serialization?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=ovotech/kafka-serialization&amp;utm_campaign=Badge_Grade" target="_blank"><img src="https://camo.githubusercontent.com/85a58cb869a3d09caa1dc41d3ecb2cd1fb9104fc/68747470733a2f2f6170692e636f646163792e636f6d2f70726f6a6563742f62616467652f47726164652f6132643831346632326434653466616361653066386133656231633834316664" alt="Codacy Badge" data-canonical-src="https://api.codacy.com/project/badge/Grade/a2d814f22d4e4facae0f8a3eb1c841fd" style="max-width:100%;"></a> <a href="https://bintray.com/ovotech/maven/kafka-serialization/_latestVersion" target="_blank"><img src="https://camo.githubusercontent.com/0e08e7b9122e72c7d52b4665edcc1a82b3ea9565/68747470733a2f2f6170692e62696e747261792e636f6d2f7061636b616765732f6f766f746563682f6d6176656e2f6b61666b612d73657269616c697a6174696f6e2f696d616765732f646f776e6c6f61642e737667" alt="Download" data-canonical-src="https://api.bintray.com/packages/ovotech/maven/kafka-serialization/images/download.svg" style="max-width:100%;"></a></p> 
  <p>The aim of this library is to provide the Legoâ„¢ bricks to build a serializer/deserializer for kafka messages.</p> 
  <p>The serializers/deserializers built by this library cannot be used in the Kafka configuration through properties, but need to be passed through the Kafka Producer/Consumer constructors (It is feature IMHO).</p> 
  <p>For the Avro serialization this library uses Avro4s while for JSON it supports Json4s, Circe and Spray out of the box. It is quite easy to add support for other libraries as well.</p> 
  <h2><a href="https://github.com/ovotech/kafka-serialization#modules" aria-hidden="true" class="anchor" id="user-content-modules" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Modules</h2> 
  <p>The library is composed by these modules:</p> 
  <ul> 
   <li>kafka-serialization-core: provides the serialization primitives to build serializers and deserializers.</li> 
   <li>kafka-serialization-json4s: provides serializer and deserializer based on Json4s</li> 
   <li>kafka-serialization-spray: provides serializer and deserializer based on Spray Json</li> 
   <li>kafka-serialization-circe: provides serializer and deserializer based on Circe</li> 
   <li>kafka-serialization-avro: provides an improved schema-registry client based on Jersey 2.x that allow basic auth</li> 
   <li>kafka-serialization-avro4s: provides serializer and deserializer based on Avro4s</li> 
  </ul> 
  <p>The Avro4s serialization support the schema evolution through the schema registry. The consumer can provide its own schema and Avro will take care of the conversion.</p> 
  <h2><a href="https://github.com/ovotech/kafka-serialization#getting-started" aria-hidden="true" class="anchor" id="user-content-getting-started" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Getting Started</h2> 
  <p>The library is available in the Bintray OVO repository. Add this snippet to your build.sbt to use it.</p> 
  <pre lang="sbtshell"><code>import sbt._
import sbt.Keys.

resolvers += Resolver.bintrayRepo("ovotech", "maven")

libraryDependencies ++= {
  val kafkaSerializationV = "0.1.19"
  Seq(
    "com.ovoenergy" %% "kafka-serialization-core" % kafkaSerializationV,
    "com.ovoenergy" %% "kafka-serialization-circe" % kafkaSerializationV, // To provide Circe JSON support
    "com.ovoenergy" %% "kafka-serialization-json4s" % kafkaSerializationV, // To provide Json4s JSON support
    "com.ovoenergy" %% "kafka-serialization-spray" % kafkaSerializationV, // To provide Spray-json JSON support
    "com.ovoenergy" %% "kafka-serialization-avro4s" % kafkaSerializationV // To provide Avro4s Avro support
  )
}

</code></pre> 
  <h2><a href="https://github.com/ovotech/kafka-serialization#circe-example" aria-hidden="true" class="anchor" id="user-content-circe-example" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Circe example</h2> 
  <p>Circe is a JSON library for Scala that provides support for generic programming trough Shapeless. You can find more information on the <a href="https://circe.github.io/circe" target="_blank">Circe website</a>.</p> 
  <p>Simple serialization/deserialization example with Circe:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.ovoenergy.kafka.serialization.core.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">com.ovoenergy.kafka.serialization.circe.</span><span class="pl-v">_</span>

<span class="pl-c"><span class="pl-c">//</span> Import the Circe generic support</span>
<span class="pl-k">import</span> <span class="pl-v">io.circe.generic.auto.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">io.circe.syntax.</span><span class="pl-v">_</span>

<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.clients.producer.</span><span class="pl-v">KafkaProducer</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.clients.consumer.</span><span class="pl-v">KafkaConsumer</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.clients.CommonClientConfigs.</span><span class="pl-v">_</span>

<span class="pl-k">import</span> <span class="pl-v">scala.collection.JavaConverters.</span><span class="pl-v">_</span>

<span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">UserCreated</span>(<span class="pl-v">id</span>: <span class="pl-k">String</span>, <span class="pl-v">name</span>: <span class="pl-k">String</span>, <span class="pl-v">age</span>: <span class="pl-k">Int</span>)

<span class="pl-k">val</span> <span class="pl-en">producer</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">KafkaProducer</span>(
  <span class="pl-en">Map</span>[<span class="pl-k">String</span>, <span class="pl-en">AnyRef</span>](<span class="pl-en">BOOTSTRAP_SERVERS_CONFIG</span><span class="pl-k">-</span><span class="pl-k">&gt;</span><span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>).asJava, 
  nullSerializer[<span class="pl-k">Unit</span>], 
  circeJsonSerializer[<span class="pl-en">UserCreated</span>]
)

<span class="pl-k">val</span> <span class="pl-en">consumer</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">KafkaConsumer</span>(
  <span class="pl-en">Map</span>[<span class="pl-k">String</span>, <span class="pl-en">AnyRef</span>](<span class="pl-en">BOOTSTRAP_SERVERS_CONFIG</span><span class="pl-k">-</span><span class="pl-k">&gt;</span><span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>).asJava,
  nullDeserializer[<span class="pl-k">Unit</span>],
  circeJsonDeserializer[<span class="pl-en">UserCreated</span>]
)
</pre>
  </div> 
  <h2><a href="https://github.com/ovotech/kafka-serialization#avro-example" aria-hidden="true" class="anchor" id="user-content-avro-example" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Avro example</h2> 
  <p>Apache Avro is a remote procedure call and data serialization framework developed within Apache's Hadoop project. It uses JSON for defining data types and protocols, and serializes data in a compact binary format.</p> 
  <p>Apache Avro provide some support to evolve your messages across multiple version without breaking compatibility with older or newer consumers. It supports several encoding formats but two are the most used in Kafka: Binary and Json.</p> 
  <p>The encoded data is always validated and parsed using a Schema (defined in JSON) and eventually evolved to the reader Schema version.</p> 
  <p>This library provided the support to Avro by using the <a href="https://github.com/sksamuel/avro4s" target="_blank">Avro4s</a> libray. It uses macro and shapeless to allowing effortless serialization and deserialization. In addition to Avro4s it need a Confluent schema registry in place, It will provide a way to control the format of the messages produced in kafka. You can find more information in the <a href="http://docs.confluent.io/current/schema-registry/docs/" target="_blank">Confluent Schema Registry Documentation </a>.</p> 
  <p>An example with Avro4s binary and Schema Registry:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.ovoenergy.kafka.serialization.core.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">com.ovoenergy.kafka.serialization.avro4s.</span><span class="pl-v">_</span>

<span class="pl-k">import</span> <span class="pl-v">com.sksamuel.avro4s.</span><span class="pl-v">_</span>

<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.clients.producer.</span><span class="pl-v">KafkaProducer</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.clients.consumer.</span><span class="pl-v">KafkaConsumer</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.clients.CommonClientConfigs.</span><span class="pl-v">_</span>

<span class="pl-k">import</span> <span class="pl-v">scala.collection.JavaConverters.</span><span class="pl-v">_</span>

<span class="pl-k">val</span> <span class="pl-en">schemaRegistryEndpoint</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>http://localhost:8081<span class="pl-pds">"</span></span>

<span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">UserCreated</span>(<span class="pl-v">id</span>: <span class="pl-k">String</span>, <span class="pl-v">name</span>: <span class="pl-k">String</span>, <span class="pl-v">age</span>: <span class="pl-k">Int</span>)

<span class="pl-c"><span class="pl-c">//</span> This type class is need by the avroBinarySchemaIdSerializer</span>
<span class="pl-k">implicit</span> <span class="pl-k">val</span> <span class="pl-en">UserCreatedToRecord</span> <span class="pl-k">=</span> <span class="pl-en">ToRecord</span>[<span class="pl-en">UserCreated</span>]

<span class="pl-k">val</span> <span class="pl-en">producer</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">KafkaProducer</span>(
  <span class="pl-en">Map</span>[<span class="pl-k">String</span>, <span class="pl-en">AnyRef</span>](<span class="pl-en">BOOTSTRAP_SERVERS_CONFIG</span><span class="pl-k">-</span><span class="pl-k">&gt;</span><span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>).asJava, 
  nullSerializer[<span class="pl-k">Unit</span>], 
  avroBinarySchemaIdSerializer[<span class="pl-en">UserCreated</span>](schemaRegistryEndpoint, isKey <span class="pl-k">=</span> <span class="pl-c1">false</span>)
)

<span class="pl-c"><span class="pl-c">//</span> This type class is need by the avroBinarySchemaIdDeserializer</span>
<span class="pl-k">implicit</span> <span class="pl-k">val</span> <span class="pl-en">UserCreatedFromRecord</span> <span class="pl-k">=</span> <span class="pl-en">FromRecord</span>[<span class="pl-en">UserCreated</span>]

<span class="pl-k">val</span> <span class="pl-en">consumer</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">KafkaConsumer</span>(
  <span class="pl-en">Map</span>[<span class="pl-k">String</span>, <span class="pl-en">AnyRef</span>](<span class="pl-en">BOOTSTRAP_SERVERS_CONFIG</span><span class="pl-k">-</span><span class="pl-k">&gt;</span><span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>).asJava,
  nullDeserializer[<span class="pl-k">Unit</span>],
  avroBinarySchemaIdDeserializer[<span class="pl-en">UserCreated</span>](schemaRegistryEndpoint, isKey <span class="pl-k">=</span> <span class="pl-c1">false</span>)
)</pre>
  </div> 
  <p>This Avro serializer will try to register the schema every new message type it will serialize and will save the obtained schema id in cache. The deserializer will contact the schema registry each time it will encounter a message with a never seen before schema id.</p> 
  <p>The schema id will encoded in the first 4 bytes of the payload. The deserializer will extract the schema id from the payload and fetch the schema from the schema registry. The deserializer is able to evolve the original message to the consumer schema. The use case is when the consumer is only interested in a part of the original message (schema projection) or when the original message is in a older or newer format of the cosumer schema (schema evolution).</p> 
  <p>An example of the consumer schema:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.ovoenergy.kafka.serialization.core.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">com.ovoenergy.kafka.serialization.avro4s.</span><span class="pl-v">_</span>

<span class="pl-k">import</span> <span class="pl-v">com.sksamuel.avro4s.</span><span class="pl-v">_</span>

<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.clients.producer.</span><span class="pl-v">KafkaProducer</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.clients.consumer.</span><span class="pl-v">KafkaConsumer</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.clients.CommonClientConfigs.</span><span class="pl-v">_</span>

<span class="pl-k">import</span> <span class="pl-v">scala.collection.JavaConverters.</span><span class="pl-v">_</span>

<span class="pl-k">val</span> <span class="pl-en">schemaRegistryEndpoint</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>http://localhost:8081<span class="pl-pds">"</span></span>

<span class="pl-c"><span class="pl-c">/*</span> Assuming the original message has been serialized using the </span>
<span class="pl-c"> * previously defined UserCreated class. We are going to project</span>
<span class="pl-c"> * it ignoring the value of the age</span>
<span class="pl-c"> <span class="pl-c">*/</span></span>
<span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">UserCreated</span>(<span class="pl-v">id</span>: <span class="pl-k">String</span>, <span class="pl-v">name</span>: <span class="pl-k">String</span>)

<span class="pl-c"><span class="pl-c">//</span> This type class is need by the avroBinarySchemaIdDeserializer</span>
<span class="pl-k">implicit</span> <span class="pl-k">val</span> <span class="pl-en">UserCreatedFromRecord</span> <span class="pl-k">=</span> <span class="pl-en">FromRecord</span>[<span class="pl-en">UserCreated</span>]


<span class="pl-c"><span class="pl-c">/*</span> This type class is need by the avroBinarySchemaIdDeserializer </span>
<span class="pl-c"> * to obtain the consumer schema</span>
<span class="pl-c"> <span class="pl-c">*/</span></span>
<span class="pl-k">implicit</span> <span class="pl-k">val</span> <span class="pl-en">UserCreatedSchemaFor</span> <span class="pl-k">=</span> <span class="pl-en">SchemaFor</span>[<span class="pl-en">UserCreated</span>]

<span class="pl-k">val</span> <span class="pl-en">consumer</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">KafkaConsumer</span>(
  <span class="pl-en">Map</span>[<span class="pl-k">String</span>, <span class="pl-en">AnyRef</span>](<span class="pl-en">BOOTSTRAP_SERVERS_CONFIG</span><span class="pl-k">-</span><span class="pl-k">&gt;</span><span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>).asJava,
  nullDeserializer[<span class="pl-k">Unit</span>],
  avroBinarySchemaIdWithReaderSchemaDeserializer[<span class="pl-en">UserCreated</span>](schemaRegistryEndpoint, isKey <span class="pl-k">=</span> <span class="pl-c1">false</span>)
)</pre>
  </div> 
  <h2><a href="https://github.com/ovotech/kafka-serialization#format-byte" aria-hidden="true" class="anchor" id="user-content-format-byte" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Format byte</h2> 
  <p>The Original Confluent Avro serializer/deserializer prefix the payload with a "magic" byte to identify that the message has been written with the Avro serializer.</p> 
  <p>Similarly this library support the same mechanism by mean of a couple of function. It is even able to multiplex and demultiplex different serializers/deserializers based on that format byte. At the moment the supported formats are</p> 
  <ul> 
   <li>JSON</li> 
   <li>Avro Binary with schema ID</li> 
   <li>Avro JSON with schema ID</li> 
  </ul> 
  <p>let's see this mechanism in action:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.ovoenergy.kafka.serialization.core.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">com.ovoenergy.kafka.serialization.avro4s.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">com.ovoenergy.kafka.serialization.circe.</span><span class="pl-v">_</span>

<span class="pl-c"><span class="pl-c">//</span> Import the Circe generic support</span>
<span class="pl-k">import</span> <span class="pl-v">io.circe.generic.auto.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">io.circe.syntax.</span><span class="pl-v">_</span>

<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.clients.producer.</span><span class="pl-v">KafkaProducer</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.clients.consumer.</span><span class="pl-v">KafkaConsumer</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.clients.CommonClientConfigs.</span><span class="pl-v">_</span>


<span class="pl-k">sealed</span> <span class="pl-k">trait</span> <span class="pl-en">Event</span>
<span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">UserCreated</span>(<span class="pl-v">id</span>: <span class="pl-k">String</span>, <span class="pl-v">name</span>: <span class="pl-k">String</span>, <span class="pl-v">email</span>: <span class="pl-k">String</span>) <span class="pl-k">extends</span> <span class="pl-e">Event</span>

<span class="pl-c"><span class="pl-c">/*</span> This producer will produce messages in Avro binary format <span class="pl-c">*/</span></span>
<span class="pl-k">val</span> <span class="pl-en">avroBinaryProducer</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">KafkaProducer</span>(
  <span class="pl-en">Map</span>[<span class="pl-k">String</span>, <span class="pl-en">AnyRef</span>](<span class="pl-en">BOOTSTRAP_SERVERS_CONFIG</span><span class="pl-k">-</span><span class="pl-k">&gt;</span><span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>).asJava, 
  nullSerializer[<span class="pl-k">Unit</span>],   
  formatSerializer(<span class="pl-en">Format</span>.<span class="pl-en">AvroBinarySchemaId</span>, avroBinarySchemaIdSerializer[<span class="pl-en">UserCreated</span>](schemaRegistryEndpoint, isKey <span class="pl-k">=</span> <span class="pl-c1">false</span>))
)

<span class="pl-c"><span class="pl-c">/*</span> This producer will produce messages in Json format <span class="pl-c">*/</span></span>
<span class="pl-k">val</span> <span class="pl-en">circeProducer</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">KafkaProducer</span>(
  <span class="pl-en">Map</span>[<span class="pl-k">String</span>, <span class="pl-en">AnyRef</span>](<span class="pl-en">BOOTSTRAP_SERVERS_CONFIG</span><span class="pl-k">-</span><span class="pl-k">&gt;</span><span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>).asJava, 
  nullSerializer[<span class="pl-k">Unit</span>],   
  formatSerializer(<span class="pl-en">Format</span>.<span class="pl-en">Json</span>, circeJsonSerializer[<span class="pl-en">UserCreated</span>])
)

<span class="pl-c"><span class="pl-c">/*</span> This consumer will be able to consume messages from both producer <span class="pl-c">*/</span></span>
<span class="pl-k">val</span> <span class="pl-en">consumer</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">KafkaConsumer</span>(
  <span class="pl-en">Map</span>[<span class="pl-k">String</span>, <span class="pl-en">AnyRef</span>](<span class="pl-en">BOOTSTRAP_SERVERS_CONFIG</span><span class="pl-k">-</span><span class="pl-k">&gt;</span><span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>).asJava,
  nullDeserializer[<span class="pl-k">Unit</span>],
  formatDemultiplexerDeserializer[<span class="pl-en">UserCreated</span>](unknownFormat <span class="pl-k">=&gt;</span> failingDeserializer(<span class="pl-k">new</span> <span class="pl-en">RuntimeException</span>(<span class="pl-s"><span class="pl-pds">"</span>Unsupported format<span class="pl-pds">"</span></span>))){
    <span class="pl-k">case</span> <span class="pl-en">Format</span>.<span class="pl-en">Json</span> <span class="pl-k">=&gt;</span> circeJsonDeserializer[<span class="pl-en">UserCreated</span>]
    <span class="pl-k">case</span> <span class="pl-en">Format</span>.<span class="pl-en">AvroBinarySchemaId</span> <span class="pl-k">=&gt;</span> avroBinarySchemaIdDeserializer[<span class="pl-en">UserCreated</span>](schemaRegistryEndpoint, isKey <span class="pl-k">=</span> <span class="pl-c1">false</span>)
  }
)
</pre>
  </div> 
  <p>You can notice that the <code>formatDemultiplexerDeserializer</code> is little bit nasty because it is invariant in the type <code>T</code> so all the demultiplexed <code>serialiazer</code> must be declared as <code>Deserializer[T]</code>.</p> 
  <p>There are other support serializer and deserializer, you can discover them looking trough the code and the tests.</p> 
  <h2><a href="https://github.com/ovotech/kafka-serialization#complaints-and-other-feedback" aria-hidden="true" class="anchor" id="user-content-complaints-and-other-feedback" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Complaints and other Feedback</h2> 
  <p>Feedback of any kind is always appreciated.</p> 
  <p>Issues and PR's are welcome as well.</p> 
  <h2><a href="https://github.com/ovotech/kafka-serialization#about-this-readme" aria-hidden="true" class="anchor" id="user-content-about-this-readme" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>About this README</h2> 
  <p>The code samples in this README file are checked using <a href="https://github.com/tpolecat/tut" target="_blank">tut</a>.</p> 
  <p>This means that the <code>README.md</code> file is generated from <code>doc/src/main/tut/README.md</code>. If you want to make any changes to the README, you should:</p> 
  <ol> 
   <li>Edit <code>doc/src/main/tut/README.md</code></li> 
   <li>Run <code>sbt tut</code> to regenerate <code>./README.md</code></li> 
   <li>Commit both files to git</li> 
  </ol> 
 </article>
</div>