<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a id="user-content-spark-kafka-writer" class="anchor" href="https://github.com/benfradet/spark-kafka-writer#spark-kafka-writer" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>spark-kafka-writer</h1> 
  <p><a href="https://travis-ci.org/BenFradet/spark-kafka-writer" target="_blank"><img src="https://camo.githubusercontent.com/b6d157b13012dd8253196588189a4a05831d02ad/68747470733a2f2f7472617669732d63692e6f72672f42656e4672616465742f737061726b2d6b61666b612d7772697465722e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/BenFradet/spark-kafka-writer.svg?branch=master" style="max-width:100%;"></a> <a href="https://codecov.io/gh/BenFradet/spark-kafka-writer" target="_blank"><img src="https://camo.githubusercontent.com/238eae277c864c30acfe8da6b3b82a0f89868b5d/68747470733a2f2f636f6465636f762e696f2f67682f42656e4672616465742f737061726b2d6b61666b612d7772697465722f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/BenFradet/spark-kafka-writer/branch/master/graph/badge.svg" style="max-width:100%;"></a> <a href="https://gitter.im/BenFradet/spark-kafka-writer?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge" target="_blank"><img src="https://camo.githubusercontent.com/73b20149ccf54e27176ce754fdee2837fef6077e/68747470733a2f2f6261646765732e6769747465722e696d2f42656e4672616465742f737061726b2d6b61666b612d7772697465722e737667" alt="Join the chat at https://gitter.im/BenFradet/spark-kafka-writer" data-canonical-src="https://badges.gitter.im/BenFradet/spark-kafka-writer.svg" style="max-width:100%;"></a> <a href="https://maven-badges.herokuapp.com/maven-central/com.github.benfradet/spark-kafka-writer_2.11" target="_blank"><img src="https://camo.githubusercontent.com/a527358741e563d31baad596faa1a25e77c169e1/68747470733a2f2f696d672e736869656c64732e696f2f6d6176656e2d63656e7472616c2f762f636f6d2e6769746875622e62656e6672616465742f737061726b2d6b61666b612d7772697465725f322e31312e737667" alt="Maven Central" data-canonical-src="https://img.shields.io/maven-central/v/com.github.benfradet/spark-kafka-writer_2.11.svg" style="max-width:100%;"></a> <a href="https://waffle.io/BenFradet/spark-kafka-writer" target="_blank"><img src="https://camo.githubusercontent.com/069e1acae75133f8ac2969274f4daaecd62f0987/68747470733a2f2f62616467652e776166666c652e696f2f42656e4672616465742f737061726b2d6b61666b612d7772697465722e706e673f6c6162656c3d7265616479267469746c653d5265616479" alt="Stories in Ready" data-canonical-src="https://badge.waffle.io/BenFradet/spark-kafka-writer.png?label=ready&amp;title=Ready" style="max-width:100%;"></a></p> 
  <p>Write your Spark data to Kafka seamlessly</p> 
  <h2><a id="user-content-installation" class="anchor" href="https://github.com/benfradet/spark-kafka-writer#installation" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Installation</h2> 
  <p>spark-kafka-writer is available on maven central with the following coordinates depending on whether you're using Kafka 0.8 or 0.10 and your version of Spark:</p> 
  <table> 
   <thead> 
    <tr> 
     <th align="center"></th> 
     <th align="center">Kafka 0.8</th> 
     <th align="center">Kafka 0.10</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td align="center"><strong>Spark 2.2.X</strong></td> 
     <td align="center">
      <g-emoji alias="x" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/274c.png" ios-version="6.0">
       ❌
      </g-emoji></td> 
     <td align="center"><code>"com.github.benfradet" %% "spark-kafka-writer" % "0.4.0"</code></td> 
    </tr> 
    <tr> 
     <td align="center"><strong>Spark 2.1.X</strong></td> 
     <td align="center"><code>"com.github.benfradet" %% "spark-kafka-0-8-writer" % "0.3.0"</code></td> 
     <td align="center"><code>"com.github.benfradet" %% "spark-kafka-0-10-writer" % "0.3.0"</code></td> 
    </tr> 
    <tr> 
     <td align="center"><strong>Spark 2.0.X</strong></td> 
     <td align="center"><code>"com.github.benfradet" %% "spark-kafka-0-8-writer" % "0.2.0"</code></td> 
     <td align="center"><code>"com.github.benfradet" %% "spark-kafka-0-10-writer" % "0.2.0"</code></td> 
    </tr> 
    <tr> 
     <td align="center"><strong>Spark 1.6.X</strong></td> 
     <td align="center"><code>"com.github.benfradet" %% "spark-kafka-writer" % "0.1.0"</code></td> 
     <td align="center">
      <g-emoji alias="x" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/274c.png" ios-version="6.0">
       ❌
      </g-emoji></td> 
    </tr>
   </tbody>
  </table> 
  <h2><a id="user-content-usage" class="anchor" href="https://github.com/benfradet/spark-kafka-writer#usage" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Usage</h2> 
  <h3><a id="user-content-without-callbacks" class="anchor" href="https://github.com/benfradet/spark-kafka-writer#without-callbacks" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Without callbacks</h3> 
  <ul> 
   <li>if you want to save an <code>RDD</code> to Kafka:</li> 
  </ul> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.github.benfradet.spark.kafka.writer.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.common.serialization.</span><span class="pl-v">StringSerializer</span>

<span class="pl-k">val</span> <span class="pl-en">topic</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>my-topic<span class="pl-pds">"</span></span>
<span class="pl-k">val</span> <span class="pl-en">producerConfig</span> <span class="pl-k">=</span> <span class="pl-en">Map</span>(
  <span class="pl-s"><span class="pl-pds">"</span>bootstrap.servers<span class="pl-pds">"</span></span> <span class="pl-k">-</span><span class="pl-k">&gt;</span> <span class="pl-s"><span class="pl-pds">"</span>127.0.0.1:9092<span class="pl-pds">"</span></span>,
  <span class="pl-s"><span class="pl-pds">"</span>key.serializer<span class="pl-pds">"</span></span> <span class="pl-k">-</span><span class="pl-k">&gt;</span> <span class="pl-c1">classOf</span>[<span class="pl-en">StringSerializer</span>].getName,
  <span class="pl-s"><span class="pl-pds">"</span>value.serializer<span class="pl-pds">"</span></span> <span class="pl-k">-</span><span class="pl-k">&gt;</span> <span class="pl-c1">classOf</span>[<span class="pl-en">StringSerializer</span>].getName
)

<span class="pl-k">val</span> <span class="pl-en">rdd</span><span class="pl-k">:</span> <span class="pl-en">RDD</span>[<span class="pl-k">String</span>] <span class="pl-k">=</span> ...
rdd.writeToKafka(
  producerConfig,
  s <span class="pl-k">=&gt;</span> <span class="pl-k">new</span> <span class="pl-en">ProducerRecord</span>[<span class="pl-k">String</span>, <span class="pl-k">String</span>](topic, s)
)</pre>
  </div> 
  <ul> 
   <li>if you want to save a <code>DStream</code> to Kafka:</li> 
  </ul> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.github.benfradet.spark.kafka.writer.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.common.serialization.</span><span class="pl-v">StringSerializer</span>

<span class="pl-k">val</span> <span class="pl-en">dStream</span><span class="pl-k">:</span> <span class="pl-en">DStream</span>[<span class="pl-k">String</span>] <span class="pl-k">=</span> ...
dStream.writeToKafka(
  producerConfig,
  s <span class="pl-k">=&gt;</span> <span class="pl-k">new</span> <span class="pl-en">ProducerRecord</span>[<span class="pl-k">String</span>, <span class="pl-k">String</span>](topic, s)
)</pre>
  </div> 
  <ul> 
   <li>if you want to save a <code>Dataset</code> to Kafka:</li> 
  </ul> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.github.benfradet.spark.kafka.writer.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.common.serialization.</span><span class="pl-v">StringSerializer</span>

<span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">Foo</span>(<span class="pl-v">a</span>: <span class="pl-k">Int</span>, <span class="pl-v">b</span>: <span class="pl-k">String</span>)
<span class="pl-k">val</span> <span class="pl-en">dataset</span><span class="pl-k">:</span> <span class="pl-en">Dataset</span>[<span class="pl-en">Foo</span>] <span class="pl-k">=</span> ...
dStream.writeToKafka(
  producerConfig,
  foo <span class="pl-k">=&gt;</span> <span class="pl-k">new</span> <span class="pl-en">ProducerRecord</span>[<span class="pl-k">String</span>, <span class="pl-k">String</span>](topic, foo.toString)
)</pre>
  </div> 
  <ul> 
   <li>if you want to write a <code>DataFrame</code> to Kafka:</li> 
  </ul> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.github.benfradet.spark.kafka.writer.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.common.serialization.</span><span class="pl-v">StringSerializer</span>

<span class="pl-k">val</span> <span class="pl-en">dataFrame</span><span class="pl-k">:</span> <span class="pl-en">DataFrame</span> <span class="pl-k">=</span> ...
dStream.writeToKafka(
  producerConfig,
  row <span class="pl-k">=&gt;</span> <span class="pl-k">new</span> <span class="pl-en">ProducerRecord</span>[<span class="pl-k">String</span>, <span class="pl-k">String</span>](topic, row.toString)
)</pre>
  </div> 
  <h3><a id="user-content-with-callbacks" class="anchor" href="https://github.com/benfradet/spark-kafka-writer#with-callbacks" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>With callbacks</h3> 
  <p>It is also possible to assign a <code>Callback</code> from the Kafka Producer API that will be triggered after each write, this has a default value of None.</p> 
  <p>The <code>Callback</code> must implement the <code>onCompletion</code> method and the <code>Exception</code> parameter will be <code>null</code> if the write was successful.</p> 
  <p>Any <code>Callback</code> implementations will need to be serializable to be used in Spark.</p> 
  <p>For example, if you want to use a <code>Callback</code> when saving an <code>RDD</code> to Kafka:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> replace by kafka08 if you're using Kafka 0.8</span>
<span class="pl-k">import</span> <span class="pl-v">com.github.benfradet.spark.kafka010.writer.</span><span class="pl-v">_</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.kafka.clients.producer.</span>{<span class="pl-v">Callback</span>, <span class="pl-v">ProducerRecord</span>, <span class="pl-v">RecordMetadata</span>}

<span class="pl-k">@</span>transient <span class="pl-k">lazy</span> <span class="pl-k">val</span> <span class="pl-en">log</span> <span class="pl-k">=</span> org.apache.log4j.<span class="pl-en">Logger</span>.getLogger(<span class="pl-s"><span class="pl-pds">"</span>spark-kafka-writer<span class="pl-pds">"</span></span>)

<span class="pl-k">val</span> <span class="pl-en">rdd</span><span class="pl-k">:</span> <span class="pl-en">RDD</span>[<span class="pl-k">String</span>] <span class="pl-k">=</span> ...
rdd.writeToKafka(
  producerConfig,
  s <span class="pl-k">=&gt;</span> <span class="pl-k">new</span> <span class="pl-en">ProducerRecord</span>[<span class="pl-k">String</span>, <span class="pl-k">String</span>](topic, s),
  <span class="pl-en">Some</span>(<span class="pl-k">new</span> <span class="pl-en">Callback</span> <span class="pl-k">with</span> <span class="pl-e">Serializable</span> {
    <span class="pl-k">override</span> <span class="pl-k">def</span> <span class="pl-en">onCompletion</span>(<span class="pl-v">metadata</span>: <span class="pl-en">RecordMetadata</span>, <span class="pl-v">e</span>: <span class="pl-en">Exception</span>)<span class="pl-k">:</span> <span class="pl-k">Unit</span> <span class="pl-k">=</span> {
      <span class="pl-k">if</span> (<span class="pl-en">Option</span>(e).isDefined) {
        log.warn(<span class="pl-s"><span class="pl-pds">"</span>error sending message<span class="pl-pds">"</span></span>, e)
      } <span class="pl-k">else</span> {
        log.info(s<span class="pl-s"><span class="pl-pds">"</span>write succeeded! offset: ${metadata.offset()}<span class="pl-pds">"</span></span>)
      }
    }
  })
)</pre>
  </div> 
  <p>Check out <a href="http://kafka.apache.org/0102/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html#send(org.apache.kafka.clients.producer.ProducerRecord,%20org.apache.kafka.clients.producer.Callback)" target="_blank">the Kafka documentation</a> to know more about callbacks.</p> 
  <h3><a id="user-content-java-usage" class="anchor" href="https://github.com/benfradet/spark-kafka-writer#java-usage" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Java usage</h3> 
  <p>It's also possible to use the library from Java, for example if we were to write a <code>DStream</code> to Kafka:</p> 
  <div class="highlight highlight-source-java">
   <pre><span class="pl-c"><span class="pl-c">//</span> Define a serializable Function1 separately</span>
<span class="pl-k">abstract</span> <span class="pl-k">class</span> <span class="pl-en">SerializableFunc1</span>&lt;T, R&gt; <span class="pl-k">extends</span> <span class="pl-e">AbstractFunction1&lt;<span class="pl-smi">T</span>, <span class="pl-smi">R</span>&gt;</span> <span class="pl-k">implements</span> <span class="pl-e">Serializable</span> {}

<span class="pl-k">Map&lt;<span class="pl-smi">String</span>, <span class="pl-smi">Object</span>&gt;</span> producerConfig <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-k">HashMap&lt;<span class="pl-smi">String</span>, <span class="pl-smi">Object</span>&gt;</span>();
producerConfig<span class="pl-k">.</span>put(<span class="pl-s"><span class="pl-pds">"</span>bootstrap.servers<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>localhost:9092<span class="pl-pds">"</span></span>);
producerConfig<span class="pl-k">.</span>put(<span class="pl-s"><span class="pl-pds">"</span>key.serializer<span class="pl-pds">"</span></span>, <span class="pl-smi">StringSerializer</span><span class="pl-k">.</span>class);
producerConfig<span class="pl-k">.</span>put(<span class="pl-s"><span class="pl-pds">"</span>value.serializer<span class="pl-pds">"</span></span>, <span class="pl-smi">StringSerializer</span><span class="pl-k">.</span>class);

<span class="pl-k">KafkaWriter&lt;<span class="pl-smi">String</span>&gt;</span> kafkaWriter <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-k">DStreamKafkaWriter&lt;&gt;</span>(javaDStream<span class="pl-k">.</span>dstream(),
    <span class="pl-smi">scala.reflect<span class="pl-k">.</span>ClassTag</span>$<span class="pl-c1"><span class="pl-k">.</span>MODULE</span>$<span class="pl-k">.</span>apply(<span class="pl-smi">String</span><span class="pl-k">.</span>class));
kafkaWriter<span class="pl-k">.</span>writeToKafka(producerConfig<span class="pl-k">.</span>asScala,
    <span class="pl-k">new</span> <span class="pl-k">SerializableFunc1&lt;<span class="pl-smi">String</span>, <span class="pl-k">ProducerRecord&lt;<span class="pl-smi">String</span>, <span class="pl-smi">String</span>&gt;</span>&gt;</span>() {
        <span class="pl-k">@Override</span>
        <span class="pl-k">public</span> <span class="pl-k">ProducerRecord&lt;<span class="pl-smi">String</span>, <span class="pl-smi">String</span>&gt;</span> <span class="pl-en">apply</span>(<span class="pl-k">final</span> <span class="pl-smi">String</span> <span class="pl-v">s</span>) {
            <span class="pl-k">return</span> <span class="pl-k">new</span> <span class="pl-k">ProducerRecord&lt;&gt;</span>(topic, s);
        }
    },
    <span class="pl-c"><span class="pl-c">//</span>new Some&lt;&gt;((metadata, exception) -&gt; {}), // with callback, define your lambda here.</span>
    <span class="pl-smi">Option</span><span class="pl-k">.</span>empty()                             <span class="pl-c"><span class="pl-c">//</span> or without callback.</span>
);</pre>
  </div> 
  <p>However, <a href="https://github.com/benfradet/spark-kafka-writer/issues/59" target="_blank">#59</a> will provide a better Java API.</p> 
  <h2><a id="user-content-scaladoc" class="anchor" href="https://github.com/benfradet/spark-kafka-writer#scaladoc" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Scaladoc</h2> 
  <p>You can find the full scaladoc at <a href="https://benfradet.github.io/spark-kafka-writer" target="_blank">https://benfradet.github.io/spark-kafka-writer</a>.</p> 
  <h2><a id="user-content-credit" class="anchor" href="https://github.com/benfradet/spark-kafka-writer#credit" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Credit</h2> 
  <p>The original code was written by <a href="https://github.com/harishreedharan" target="_blank">Hari Shreedharan</a>.</p> 
 </article>
</div>