<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a id="user-content-riff" class="anchor" href="https://github.com/sadikovi/riff#riff" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>riff</h1> 
  <p>Spark SQL row-oriented indexed file format</p> 
  <p><a href="https://travis-ci.org/sadikovi/riff" target="_blank"><img src="https://camo.githubusercontent.com/a446bc6d5ba9d6dc976e4a49ec01736370a6dd75/68747470733a2f2f7472617669732d63692e6f72672f736164696b6f76692f726966662e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/sadikovi/riff.svg?branch=master" style="max-width:100%;"></a></p> 
  <p>Riff is a Spark SQL row-oriented file format designed for faster writes and point queries, and reasonable range queries compare to Parquet. It is built to work <em>natively</em> with Spark SQL eliminating row values conversion, performing predicate pushdown and indexing. You can see benchmark results in <a href="https://gist.github.com/sadikovi/41c07e9f76177820b7f9894c79a2efa1" target="_blank">this gist</a>.</p> 
  <h2><a id="user-content-requirements" class="anchor" href="https://github.com/sadikovi/riff#requirements" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Requirements</h2> 
  <table> 
   <thead> 
    <tr> 
     <th>Spark version</th> 
     <th>riff latest version</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td>2.0.x</td> 
     <td><a href="http://spark-packages.org/package/sadikovi/riff" target="_blank">0.1.0</a></td> 
    </tr> 
    <tr> 
     <td>2.1.x</td> 
     <td><a href="http://spark-packages.org/package/sadikovi/riff" target="_blank">0.1.0</a></td> 
    </tr>
   </tbody>
  </table> 
  <h2><a id="user-content-linking" class="anchor" href="https://github.com/sadikovi/riff#linking" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Linking</h2> 
  <p>The <code>riff</code> package can be added to Spark by using the <code>--packages</code> command line option. For example, run this to include it when starting <code>spark-shell</code> (Scala 2.11.x):</p> 
  <div class="highlight highlight-source-shell">
   <pre> <span class="pl-smi">$SPARK_HOME</span>/bin/spark-shell --packages sadikovi:riff:0.1.0-s_2.11</pre>
  </div> 
  <p>See build instructions to create jar for Scala 2.10.x</p> 
  <h2><a id="user-content-spark-options" class="anchor" href="https://github.com/sadikovi/riff#spark-options" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Spark options</h2> 
  <p>Currently supported options, use <code>--conf key=value</code> on a command line to provide options similar to other Spark configuration or add them to <code>spark-defaults.conf</code> file, or add them in the code by running <code>spark.conf.set("option", "value")</code>.</p> 
  <table> 
   <thead> 
    <tr> 
     <th>Name</th> 
     <th>Description</th> 
     <th>Default</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td><code>spark.sql.riff.compression.codec</code></td> 
     <td>Compression codec to use for riff (<code>none</code>, <code>snappy</code>, <code>gzip</code>, <code>deflate</code>)</td> 
     <td><code>deflate</code></td> 
    </tr> 
    <tr> 
     <td><code>spark.sql.riff.stripe.rows</code></td> 
     <td>Number of rows to keep per stripe</td> 
     <td><code>10000</code></td> 
    </tr> 
    <tr> 
     <td><code>spark.sql.riff.column.filter.enabled</code></td> 
     <td>When enabled, write column filters in addition to min/max/null statistics (<code>true</code>, <code>false</code>)</td> 
     <td><code>true</code></td> 
    </tr> 
    <tr> 
     <td><code>spark.sql.riff.buffer.size</code></td> 
     <td>Buffer size in bytes for out/in stream</td> 
     <td><code>256 * 1024</code></td> 
    </tr> 
    <tr> 
     <td><code>spark.sql.riff.filterPushdown</code></td> 
     <td>When enabled, propagate filter to riff format, otherwise filter data in Spark only</td> 
     <td><code>true</code></td> 
    </tr> 
    <tr> 
     <td><code>spark.sql.riff.metadata.count.enabled</code></td> 
     <td>When enabled, use metadata information for count queries, otherwise read table data</td> 
     <td><code>true</code></td> 
    </tr>
   </tbody>
  </table> 
  <h2><a id="user-content-dataframe-options" class="anchor" href="https://github.com/sadikovi/riff#dataframe-options" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>DataFrame options</h2> 
  <p>These options that you can specify when writing DataFrame by calling <code>df.write.option("key", "value").save(...)</code>.</p> 
  <table> 
   <thead> 
    <tr> 
     <th>Name</th> 
     <th>Description</th> 
     <th>Default</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td><code>index</code></td> 
     <td>Optional setting to specify columns to index by Riff; if no columns provided, default row layout is used</td> 
     <td><code>&lt;empty string&gt;</code></td> 
    </tr>
   </tbody>
  </table> 
  <h2><a id="user-content-supported-spark-sql-types" class="anchor" href="https://github.com/sadikovi/riff#supported-spark-sql-types" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Supported Spark SQL types</h2> 
  <ul> 
   <li><code>IntegerType</code></li> 
   <li><code>LongType</code></li> 
   <li><code>StringType</code></li> 
   <li><code>DateType</code></li> 
   <li><code>TimestampType</code></li> 
   <li><code>BooleanType</code></li> 
   <li><code>ShortType</code></li> 
   <li><code>ByteType</code></li> 
  </ul> 
  <h2><a id="user-content-example" class="anchor" href="https://github.com/sadikovi/riff#example" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Example</h2> 
  <p>Usage is very similar to other datasources for Spark, e.g. Parquet, ORC, JSON, etc. Riff allows to set some datasource options in addition to ones listed in the table above.</p> 
  <h3><a id="user-content-scala-api" class="anchor" href="https://github.com/sadikovi/riff#scala-api" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Scala API</h3> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> Write DataFrame into Riff format by using standard specification</span>
<span class="pl-k">val</span> <span class="pl-en">df</span><span class="pl-k">:</span> <span class="pl-en">DataFrame</span> <span class="pl-k">=</span> ...
df.write.format(<span class="pl-s"><span class="pl-pds">"</span>com.github.sadikovi.spark.riff<span class="pl-pds">"</span></span>).save(<span class="pl-s"><span class="pl-pds">"</span>/path/to/table<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">//</span> Read DataFrame from Riff format by using standard specification</span>
<span class="pl-k">val</span> <span class="pl-en">df</span> <span class="pl-k">=</span> spark.read.format(<span class="pl-s"><span class="pl-pds">"</span>com.github.sadikovi.spark.riff<span class="pl-pds">"</span></span>).load(<span class="pl-s"><span class="pl-pds">"</span>/path/to/table<span class="pl-pds">"</span></span>)</pre>
  </div> 
  <p>Alternatively you can use shortcuts to write and read Riff files.</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> You can also import implicit conversions to make it similar to Parquet read/write</span>
<span class="pl-k">import</span> <span class="pl-v">com.github.sadikovi.spark.riff.</span><span class="pl-v">_</span>
<span class="pl-k">val</span> <span class="pl-en">df</span><span class="pl-k">:</span> <span class="pl-en">DataFrame</span> <span class="pl-k">=</span> ...
df.write.riff(<span class="pl-s"><span class="pl-pds">"</span>/path/to/table<span class="pl-pds">"</span></span>)

<span class="pl-k">val</span> <span class="pl-en">df</span> <span class="pl-k">=</span> spark.read.riff(<span class="pl-s"><span class="pl-pds">"</span>/path/to/table<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">//</span> You can specify fields to index, Riff will create column filters for those, and restructure</span>
<span class="pl-c"><span class="pl-c">//</span> records to optimize filtering by those fields. This is optional and can be specified on writes,</span>
<span class="pl-c"><span class="pl-c">//</span> when reading data Riff will automatically use those fields - no settings required.</span>
<span class="pl-k">val</span> <span class="pl-en">df</span><span class="pl-k">:</span> <span class="pl-en">DataFrame</span> <span class="pl-k">=</span> ...
df.write.option(<span class="pl-s"><span class="pl-pds">"</span>index<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>col1,col2,col3<span class="pl-pds">"</span></span>).riff(<span class="pl-s"><span class="pl-pds">"</span>/path/to/table<span class="pl-pds">"</span></span>)

<span class="pl-k">val</span> <span class="pl-en">df</span> <span class="pl-k">=</span> spark.read.riff(<span class="pl-s"><span class="pl-pds">"</span>/path/to/table<span class="pl-pds">"</span></span>).filter(<span class="pl-s"><span class="pl-pds">"</span>col1 = 'abc'<span class="pl-pds">"</span></span>)</pre>
  </div> 
  <h3><a id="user-content-python-api" class="anchor" href="https://github.com/sadikovi/riff#python-api" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Python API</h3> 
  <div class="highlight highlight-source-python">
   <pre><span class="pl-c"><span class="pl-c">#</span> You can also specify index columns for table</span>
df.write.format(<span class="pl-s"><span class="pl-pds">"</span>com.github.sadikovi.spark.riff<span class="pl-pds">"</span></span>).save(<span class="pl-s"><span class="pl-pds">"</span>/path/to/table<span class="pl-pds">"</span></span>)
<span class="pl-c1">...</span>
df <span class="pl-k">=</span> spark.read.format(<span class="pl-s"><span class="pl-pds">"</span>com.github.sadikovi.spark.riff<span class="pl-pds">"</span></span>).load(<span class="pl-s"><span class="pl-pds">"</span>/path/to/table<span class="pl-pds">"</span></span>)</pre>
  </div> 
  <h3><a id="user-content-sql-api" class="anchor" href="https://github.com/sadikovi/riff#sql-api" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>SQL API</h3> 
  <div class="highlight highlight-source-sql">
   <pre>CREATE TEMPORARY VIEW test
USING <span class="pl-c1">com</span>.<span class="pl-c1">github</span>.<span class="pl-c1">sadikovi</span>.<span class="pl-c1">spark</span>.riff
OPTIONS (<span class="pl-k">path</span> <span class="pl-s"><span class="pl-pds">"</span>/path/to/table<span class="pl-pds">"</span></span>);

<span class="pl-k">SELECT</span> <span class="pl-k">*</span> <span class="pl-k">FROM</span> test <span class="pl-k">LIMIT</span> <span class="pl-c1">10</span>;</pre>
  </div> 
  <h2><a id="user-content-building-from-source" class="anchor" href="https://github.com/sadikovi/riff#building-from-source" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Building From Source</h2> 
  <p>This library is built using <code>sbt</code>, to build a JAR file simply run <code>sbt package</code> from project root. To build jars for Scala 2.10.x and 2.11.x run <code>sbt +package</code>.</p> 
  <h2><a id="user-content-testing" class="anchor" href="https://github.com/sadikovi/riff#testing" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Testing</h2> 
  <p>Run <code>sbt test</code> from project root. See <code>.travis.yml</code> for CI build matrix.</p> 
  <h2><a id="user-content-running-benchmark" class="anchor" href="https://github.com/sadikovi/riff#running-benchmark" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Running benchmark</h2> 
  <p>Run <code>sbt package</code> to package project, next run <code>spark-submit</code> for following benchmarks (jar path/name might be different from example below). All data created during benchmarks is stored in <code>./temp</code> folder.</p> 
  <ul> 
   <li>Write benchmark</li> 
  </ul> 
  <pre><code>spark-submit --class com.github.sadikovi.benchmark.WriteBenchmark \
  target/scala-2.11/riff_2.11-0.1.0-SNAPSHOT.jar
</code></pre> 
  <ul> 
   <li>Scan benchmark</li> 
  </ul> 
  <pre><code>spark-submit --class com.github.sadikovi.benchmark.ScanBenchmark \
  target/scala-2.11/riff_2.11-0.1.0-SNAPSHOT.jar
</code></pre> 
  <ul> 
   <li>Query benchmark</li> 
  </ul> 
  <pre><code>spark-submit --class com.github.sadikovi.benchmark.QueryBenchmark \
  target/scala-2.11/riff_2.11-0.1.0-SNAPSHOT.jar
</code></pre> 
  <ul> 
   <li>Project benchmark</li> 
  </ul> 
  <pre><code>spark-submit --class com.github.sadikovi.benchmark.ProjectBenchmark \
  target/scala-2.11/riff_2.11-0.1.0-SNAPSHOT.jar
</code></pre> 
 </article>
</div>