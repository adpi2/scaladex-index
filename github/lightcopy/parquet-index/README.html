<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a id="user-content-parquet-index" class="anchor" href="https://github.com/lightcopy/parquet-index#parquet-index" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>parquet-index</h1> 
  <p>Spark SQL index for Parquet tables</p> 
  <p><a href="https://travis-ci.org/lightcopy/parquet-index" target="_blank"><img src="https://camo.githubusercontent.com/98475647bf920d5ea447013680ffeb2353c04d3b/68747470733a2f2f7472617669732d63692e6f72672f6c69676874636f70792f706172717565742d696e6465782e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/lightcopy/parquet-index.svg?branch=master" style="max-width:100%;"></a> <a href="https://coveralls.io/github/lightcopy/parquet-index?branch=master" target="_blank"><img src="https://camo.githubusercontent.com/783206152ac4dddb0ed7e71a6895882467777fd7/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6c69676874636f70792f706172717565742d696e6465782f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/lightcopy/parquet-index/badge.svg?branch=master" style="max-width:100%;"></a> <a href="https://gitter.im/lightcopy/parquet-index?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge" target="_blank"><img src="https://camo.githubusercontent.com/27f6ec6f554ad6684921099ad28f5023b719d714/68747470733a2f2f6261646765732e6769747465722e696d2f6c69676874636f70792f706172717565742d696e6465782e737667" alt="Join the chat at https://gitter.im/lightcopy/parquet-index" data-canonical-src="https://badges.gitter.im/lightcopy/parquet-index.svg" style="max-width:100%;"></a></p> 
  <h2><a id="user-content-overview" class="anchor" href="https://github.com/lightcopy/parquet-index#overview" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Overview</h2> 
  <p>Package allows to create index for Parquet tables to reduce query latency when used for <em>almost interactive</em> analysis or point queries in Spark SQL. It is designed for use case when table does not change frequently, but is used for queries often, e.g. using Thrift JDBC/ODBC server. When indexed, schema and list of files (including partitioning) will be automatically resolved from index metastore instead of inferring schema every time datasource is created.</p> 
  <h3><a id="user-content-metastore" class="anchor" href="https://github.com/lightcopy/parquet-index#metastore" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Metastore</h3> 
  <p>Metastore keeps information about all indexed tables and can be created on local file system or HDFS (see available options below) with support for in-memory cache of index (after first scan). Each created index includes different statistics (min/max/null) and, optionally, column filters statistics (e.g. bloom filters) on indexed columns.</p> 
  <h3><a id="user-content-supported-predicates" class="anchor" href="https://github.com/lightcopy/parquet-index#supported-predicates" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Supported predicates</h3> 
  <p>Index is automatically enabled for scan when provided predicate contains one or several filters with indexed columns; if no filters on indexed columns are provided, then normal scan is used, but with benefits of already resolved partitions and schema. Applying min/max statistics and column filter statistics (if available) happens after partition pruning. Statistics are kept per Parquet block metadata. Note that performance also depends on values distribution and predicate selectivity. Spark Parquet reader is used to read data.</p> 
  <p>Most of the Spark SQL predicates are supported to use statistics and/or column filter (<code>EqualTo</code>, <code>In</code>, <code>GreaterThan</code>, <code>LessThan</code>, and others). Note that predicates work best for equality or <code>isin</code> conditions and logical operators (<code>And</code>, <code>Or</code>, <code>Not</code>), e.g. <code>$"a" === 1 &amp;&amp; $"b" === "abc"</code> or <code>$"a".isin("a", "b", "c")</code>.</p> 
  <h3><a id="user-content-supported-spark-sql-types" class="anchor" href="https://github.com/lightcopy/parquet-index#supported-spark-sql-types" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Supported Spark SQL types</h3> 
  <p>Currently only these types are supported for indexed columns:</p> 
  <ul> 
   <li><code>IntegerType</code></li> 
   <li><code>LongType</code></li> 
   <li><code>StringType</code></li> 
  </ul> 
  <h3><a id="user-content-limitations" class="anchor" href="https://github.com/lightcopy/parquet-index#limitations" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Limitations</h3> 
  <ul> 
   <li>Indexed columns must be top level primitive columns with types above</li> 
   <li>Indexed columns cannot be the same as partitioning columns (which kind of makes sense)</li> 
   <li>Append mode is not supported for Parquet table when creating index</li> 
   <li>Certain Spark versions are supported (see table below)</li> 
  </ul> 
  <blockquote> 
   <p>Project is <strong>experimental and is in active development at the moment</strong>. We are working to remove limitations and add support for different versions. Any feedback, issues or PRs are welcome.</p> 
   <p>Documentation reflects changes in <code>master</code> branch, for specific version documentation, please select version tag or branch.</p> 
  </blockquote> 
  <h2><a id="user-content-requirements" class="anchor" href="https://github.com/lightcopy/parquet-index#requirements" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Requirements</h2> 
  <table>
   <thead> 
    <tr> 
     <th>Spark version</th> 
     <th><code>parquet-index</code> latest version</th> 
    </tr> 
   </thead>
   <tbody> 
    <tr> 
     <td>1.6.x</td> 
     <td>Not supported</td> 
    </tr> 
    <tr> 
     <td>2.0.0</td> 
     <td><a href="http://spark-packages.org/package/lightcopy/parquet-index" target="_blank">0.2.0</a></td> 
    </tr> 
    <tr> 
     <td>2.0.1</td> 
     <td><a href="http://spark-packages.org/package/lightcopy/parquet-index" target="_blank">0.2.0</a></td> 
    </tr> 
    <tr> 
     <td>2.0.2</td> 
     <td><a href="http://spark-packages.org/package/lightcopy/parquet-index" target="_blank">0.2.0</a></td> 
    </tr> 
    <tr> 
     <td>2.1.x</td> 
     <td>Not supported</td> 
    </tr> 
   </tbody>
  </table> 
  <h2><a id="user-content-linking" class="anchor" href="https://github.com/lightcopy/parquet-index#linking" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Linking</h2> 
  <p>The <code>parquet-index</code> package can be added to Spark by using the <code>--packages</code> command line option. For example, run this to include it when starting the spark shell (Scala 2.10.x):</p> 
  <div class="highlight highlight-source-shell">
   <pre> <span class="pl-smi">$SPARK_HOME</span>/bin/spark-shell --packages lightcopy:parquet-index:0.1.0-s_2.10</pre>
  </div> 
  <p>Change to <code>lightcopy:parquet-index:0.1.0-s_2.11</code> for Scala 2.11.x</p> 
  <h2><a id="user-content-options" class="anchor" href="https://github.com/lightcopy/parquet-index#options" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Options</h2> 
  <p>Currently supported options, use <code>--conf key=value</code> on a command line to provide options similar to other Spark configuration or add them to <code>spark-defaults.conf</code> file.</p> 
  <table>
   <thead> 
    <tr> 
     <th>Name</th> 
     <th align="center">Since</th> 
     <th>Description</th> 
     <th>Default</th> 
    </tr> 
   </thead>
   <tbody> 
    <tr> 
     <td><code>spark.sql.index.metastore</code></td> 
     <td align="center"><code>0.1.0</code></td> 
     <td>Index metastore location, created if does not exist (<em>file:/folder, hdfs://host:port/folder</em>)</td> 
     <td><em>working directory</em></td> 
    </tr> 
    <tr> 
     <td><code>spark.sql.index.parquet.filter.enabled</code></td> 
     <td align="center"><code>0.2.0</code></td> 
     <td>When set to <code>true</code>, write filter statistics for indexed columns when creating table index, otherwise only min/max statistics are used. Filter statistics are used during filtering stage, if can be applied and available (<em>true, false</em>)</td> 
     <td><em>false</em></td> 
    </tr> 
    <tr> 
     <td><code>spark.sql.index.parquet.filter.type</code></td> 
     <td align="center"><code>0.2.0</code></td> 
     <td>When filter statistics enabled, select type of statistics to use when creating index (<em>bloom</em>)</td> 
     <td><em>bloom</em></td> 
    </tr> 
    <tr> 
     <td><code>spark.sql.index.parquet.filter.eagerLoading</code></td> 
     <td align="center"><code>0.2.0</code></td> 
     <td>When set to <code>true</code>, read and load all filter statistics in memory the first time catalog is resolved, otherwise load them lazily as needed when evaluating predicate (<em>true, false</em>)</td> 
     <td><em>false</em></td> 
    </tr> 
    <tr> 
     <td><code>spark.sql.index.createIfNotExists</code></td> 
     <td align="center"><code>0.2.0</code></td> 
     <td>When set to true, create index if one does not exist in metastore for the table, and will use all available columns for indexing (<em>true, false</em>)</td> 
     <td><em>false</em></td> 
    </tr> 
   </tbody>
  </table> 
  <h2><a id="user-content-example" class="anchor" href="https://github.com/lightcopy/parquet-index#example" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Example</h2> 
  <h3><a id="user-content-scala-api" class="anchor" href="https://github.com/lightcopy/parquet-index#scala-api" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Scala API</h3> 
  <p>Most of the API is defined in <a href="https://github.com/lightcopy/parquet-index/blob/master/src/main/scala/org/apache/spark/sql/DataFrameIndexManager.scala" target="_blank">DataFrameIndexManager</a>. Usage is similar to Spark's <code>DataFrameReader</code>, but for <code>spark.index</code>.</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> Create dummy table "codes.parquet", use repartition to create more or less generic</span>
<span class="pl-c"><span class="pl-c">//</span> situation with value distribution</span>
spark.range(<span class="pl-c1">0</span>, <span class="pl-c1">1000000</span>).
  select($<span class="pl-s"><span class="pl-pds">"</span>id<span class="pl-pds">"</span></span>, $<span class="pl-s"><span class="pl-pds">"</span>id<span class="pl-pds">"</span></span>.cast(<span class="pl-s"><span class="pl-pds">"</span>string<span class="pl-pds">"</span></span>).as(<span class="pl-s"><span class="pl-pds">"</span>code<span class="pl-pds">"</span></span>), lit(<span class="pl-s"><span class="pl-pds">"</span>xyz<span class="pl-pds">"</span></span>).as(<span class="pl-s"><span class="pl-pds">"</span>name<span class="pl-pds">"</span></span>)).
  repartition(<span class="pl-c1">400</span>).
  write.partitionBy(<span class="pl-s"><span class="pl-pds">"</span>name<span class="pl-pds">"</span></span>).parquet(<span class="pl-s"><span class="pl-pds">"</span>temp/codes.parquet<span class="pl-pds">"</span></span>)

<span class="pl-k">import</span> <span class="pl-v">com.github.lightcopy.implicits.</span><span class="pl-v">_</span>
<span class="pl-c"><span class="pl-c">//</span> Create index for table, this will create index files in index_metastore,</span>
<span class="pl-c"><span class="pl-c">//</span> you can configure different options - see table above</span>

<span class="pl-c"><span class="pl-c">//</span> All Spark SQL modes are available ('append', 'overwrite', 'ignore', 'error')</span>
<span class="pl-c"><span class="pl-c">//</span> You can also use `.indexByAll` instead to choose all columns in schema that</span>
<span class="pl-c"><span class="pl-c">//</span> can be indexed</span>
spark.index.create.
  mode(<span class="pl-s"><span class="pl-pds">"</span>overwrite<span class="pl-pds">"</span></span>).indexBy($<span class="pl-s"><span class="pl-pds">"</span>id<span class="pl-pds">"</span></span>, $<span class="pl-s"><span class="pl-pds">"</span>code<span class="pl-pds">"</span></span>).parquet(<span class="pl-s"><span class="pl-pds">"</span>temp/codes.parquet<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">//</span> Check if index for table exists, should return "true"</span>
spark.index.exists.parquet(<span class="pl-s"><span class="pl-pds">"</span>temp/codes.parquet<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">//</span> Query table using index, should return 1 record, and will scan only small</span>
<span class="pl-c"><span class="pl-c">//</span> number of files (1 file usually if filter statistics are enabled). This</span>
<span class="pl-c"><span class="pl-c">//</span> example uses filters on both columns, though any filters can be used,</span>
<span class="pl-c"><span class="pl-c">//</span> e.g. only on id or code</span>
<span class="pl-c"><span class="pl-c">//</span> Metastore will cache index catalog to reduce time for subsequent calls</span>
<span class="pl-k">val</span> <span class="pl-en">df</span> <span class="pl-k">=</span> spark.index.parquet(<span class="pl-s"><span class="pl-pds">"</span>temp/codes.parquet<span class="pl-pds">"</span></span>).
  filter($<span class="pl-s"><span class="pl-pds">"</span>id<span class="pl-pds">"</span></span> <span class="pl-k">===</span> <span class="pl-c1">123</span> <span class="pl-k">&amp;&amp;</span> $<span class="pl-s"><span class="pl-pds">"</span>code<span class="pl-pds">"</span></span> <span class="pl-k">===</span> <span class="pl-s"><span class="pl-pds">"</span>123<span class="pl-pds">"</span></span>)
df.collect

<span class="pl-c"><span class="pl-c">//</span> Delete index in metastore, also invalidates cache</span>
<span class="pl-c"><span class="pl-c">//</span> no-op if there is such index does not exist</span>
<span class="pl-c"><span class="pl-c">//</span> (does NOT delete original table)</span>
spark.index.delete.parquet(<span class="pl-s"><span class="pl-pds">"</span>temp/codes.parquet<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">//</span> You can compare performance with this</span>
<span class="pl-k">val</span> <span class="pl-en">df</span> <span class="pl-k">=</span> spark.read.parquet(<span class="pl-s"><span class="pl-pds">"</span>temp/codes.parquet<span class="pl-pds">"</span></span>).
  filter($<span class="pl-s"><span class="pl-pds">"</span>id<span class="pl-pds">"</span></span> <span class="pl-k">===</span> <span class="pl-c1">123</span> <span class="pl-k">&amp;&amp;</span> $<span class="pl-s"><span class="pl-pds">"</span>code<span class="pl-pds">"</span></span> <span class="pl-k">===</span> <span class="pl-s"><span class="pl-pds">"</span>123<span class="pl-pds">"</span></span>)
df.collect</pre>
  </div> 
  <h2><a id="user-content-building-from-source" class="anchor" href="https://github.com/lightcopy/parquet-index#building-from-source" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Building From Source</h2> 
  <p>This library is built using <code>sbt</code>, to build a JAR file simply run <code>sbt package</code> from project root.</p> 
  <h2><a id="user-content-testing" class="anchor" href="https://github.com/lightcopy/parquet-index#testing" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Testing</h2> 
  <p>Run <code>sbt test</code> from project root. See <code>.travis.yml</code> for CI build matrix.</p> 
 </article>
</div>