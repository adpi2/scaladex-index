<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <p>#Apache Spark Renjin Executor (REX)</p> 
  <p>REX is an <a href="http://spark.apache.org/" target="_blank">Apache Spark</a> package offering access to the scientific computing power of the R programming language to Spark batch and streaming applications on the JVM. This library is built on top of the <a href="https://github.com/onetapbeyond/renjin-r-executor" target="_blank">renjin-r-executor</a> library, a lightweight solution for integrating R analytics executed on the <a href="http://www.renjin.org" target="_blank">Renjin R interpreter</a> into any application running on the JVM.</p> 
  <blockquote> 
   <p>IMPORTANT: The Renjin R interpreter for statistical computing is currently a work-in-progress and is not yet 100% compatible with GNU R. To find which CRAN R packages are currently supported by Renjin you can browse or search the <a href="http://packages.renjin.org/" target="_blank">Renjin package repository</a>. As Renjin compatibility with GNU R continues to improve, REX is ready to deliver those improvements directly to Apache Spark batch and streaming applications on the JVM. If Renjin does not meet your needs today then I recommend checking out <a href="https://github.com/onetapbeyond/opencpu-spark-executor" target="_blank">ROSE</a>, an alternative library that today offers access to the full scientific computing power of the R programming language to Apache Spark applications.</p> 
  </blockquote> 
  <h3><a href="https://github.com/onetapbeyond/renjin-spark-executor#rex-motivation" aria-hidden="true" class="anchor" id="user-content-rex-motivation" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>REX Motivation</h3> 
  <blockquote> 
   <p>Where Apache SparkR lets data scientists use Spark from R, REX is designed to let Scala and Java developers use R from Spark.</p> 
  </blockquote> 
  <p>The popular <a href="https://github.com/apache/spark/tree/master/R" target="_blank">Apache SparkR</a> package provides a lightweight front-end for data scientists to use Apache Spark from R. This approach is ideally suited to investigative analytics, such as ad-hoc and exploratory analysis at scale.</p> 
  <p>The REX library attempts to provide the same R analytics capabilities available to Apache SparkR applications within traditional Spark applications on the JVM. It does this by exposing new <code>analyze</code> operations that execute R analytics on compatible RDDs. This new facility is designed primarily for operational analytics and can be used alongside Spark core, SQL, Streaming, MLib and GraphX.</p> 
  <p>If you need to query R machine-learning models, score R prediction models or leverage any other aspect of the R library within your Spark applications on the JVM then the REX library may be for you.</p> 
  <h3><a href="https://github.com/onetapbeyond/renjin-spark-executor#rex-examples" aria-hidden="true" class="anchor" id="user-content-rex-examples" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>REX Examples</h3> 
  <p>A number of example applications are provided to demonstrate the use of the REX library to deliver R analytics capabilities within any Spark solution.</p> 
  <ul> 
   <li>Hello, World! [ <a href="https://github.com/onetapbeyond/renjin-spark-executor/blob/master/examples/scala/hello-world" target="_blank">Scala</a> ][ <a href="https://github.com/onetapbeyond/renjin-spark-executor/blob/master/examples/java/hello-world" target="_blank">Java</a> ]</li> 
  </ul> 
  <h3><a href="https://github.com/onetapbeyond/renjin-spark-executor#rex-sbt-dependency" aria-hidden="true" class="anchor" id="user-content-rex-sbt-dependency" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>REX SBT Dependency</h3> 
  <pre><code>libraryDependencies += "io.onetapbeyond" %% "renjin-spark-executor_2.10" % "1.0"
</code></pre> 
  <h3><a href="https://github.com/onetapbeyond/renjin-spark-executor#rex-gradle-dependency" aria-hidden="true" class="anchor" id="user-content-rex-gradle-dependency" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>REX Gradle Dependency</h3> 
  <pre><code>compile 'io.onetapbeyond:renjin-spark-executor_2.10:1.0'
</code></pre> 
  <h3><a href="https://github.com/onetapbeyond/renjin-spark-executor#rex-spark-package-dependency" aria-hidden="true" class="anchor" id="user-content-rex-spark-package-dependency" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>REX Spark Package Dependency</h3> 
  <p>Include the REX package in your Spark application using spark-shell, or spark-submit. For example:</p> 
  <pre><code>$SPARK_HOME/bin/spark-shell --packages io.onetapbeyond:renjin-spark-executor_2.10:1.0
</code></pre> 
  <h3><a href="https://github.com/onetapbeyond/renjin-spark-executor#rex-basic-usage" aria-hidden="true" class="anchor" id="user-content-rex-basic-usage" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>REX Basic Usage</h3> 
  <p>This library exposes new <code>analyze</code> transformations on Spark RDDs of type <code>RDD[RenjinTask]</code>. The following sections demonstrate how to use these new RDD operations to execute R analytics directly within Spark batch and streaming applications on the JVM.</p> 
  <p>See the <a href="https://github.com/onetapbeyond/renjin-r-executor" target="_blank">documentation</a> on the underlying <code>renjin-r-executor</code> library for details on building <code>RenjinTask</code> and handling <code>RenjinResult</code>.</p> 
  <h3><a href="https://github.com/onetapbeyond/renjin-spark-executor#rex-spark-batch-usage" aria-hidden="true" class="anchor" id="user-content-rex-spark-batch-usage" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>REX Spark Batch Usage</h3> 
  <p>For this example we assume an input <code>dataRDD</code>, then transform it to generate an RDD of type <code>RDD[RenjinTask]</code>. In this example each <code>RenjinTask</code> will execute a block of task specific R code when the RDD is eventually evaluated.</p> 
  <pre><code>import io.onetapbeyond.renjin.spark.executor.R._
import io.onetapbeyond.renjin.r.executor._

val rTaskRDD = dataRDD.map(data =&gt; {
  Renjin.R()
        .code(rCode)
        .input(data.asInput())
        .build()
  })
</code></pre> 
  <p>The set of <code>RenjinTask</code> within <code>rTaskRDD</code> can be scheduled for processing by calling the new <code>analyze</code> operation provided by REX on the RDD:</p> 
  <pre><code>val rResultRDD = rTaskRDD.analyze
</code></pre> 
  <p>When <code>rTaskRDD.analyze</code> is evaluated by Spark the resultant <code>rResultRDD</code> is of type <code>RDD[RenjinResult]</code>. The result returned by the block of the task specific R code for the original <code>RenjinTask</code> is available within these <code>RenjinResult</code>. These values can be optionally cached, further processed or persisted per the needs of your Spark application.</p> 
  <p>Note, the block of task specific R code can make use of any CRAN R package function or script that is supported by the Renjin R interpreter. To find which CRAN R packages are currently supported by Renjin you can browse or search the <a href="http://packages.renjin.org/" target="_blank">Renjin package repository</a>.</p> 
  <h3><a href="https://github.com/onetapbeyond/renjin-spark-executor#rex-spark-streaming-usage" aria-hidden="true" class="anchor" id="user-content-rex-spark-streaming-usage" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>REX Spark Streaming Usage</h3> 
  <p>For this example we assume an input stream <code>dataStream</code>, then transform it to generate a new stream with underlying RDDs of type <code>RDD[RenjinTask]</code>. In this example each <code>RenjinTask</code> will execute a block of task specific R code when the stream is eventually evaluated.</p> 
  <pre><code>import io.onetapbeyond.renjin.spark.executor.R._
import io.onetapbeyond.renjin.r.executor._

val rTaskStream = dataStream.transform(rdd =&gt; {
  rdd.map(data =&gt; {
    Renjin.R()
          .code(rCode)
          .input(data.asInput())
          .build()
    })	
  })
</code></pre> 
  <p>The set of <code>RenjinTask</code> within <code>rTaskStream</code> can be scheduled for processing by calling the new <code>analyze</code> operation provided by REX on each RDD within the stream:</p> 
  <pre><code>val rResultStream = rTaskStream.transform(rdd =&gt; rdd.analyze)
</code></pre> 
  <p>When <code>rTaskStream.transform</code> is evaluated by Spark the resultant <code>rResultStream</code> has underlying RDDs of type <code>RDD[RenjinResult]</code>. The result returned by the block of task specific R code for the original <code>RenjinTask</code> is available within these <code>RenjinResult</code>. These values can be optionally cached, further processed or persisted per the needs of your Spark application.</p> 
  <p>Note, the block of task specific R code can make use of any CRAN R package function or script that is supported by the Renjin R interpreter. To find which CRAN R packages are currently supported by Renjin you can browse or search the <a href="http://packages.renjin.org/" target="_blank">Renjin package repository</a>.</p> 
  <h3><a href="https://github.com/onetapbeyond/renjin-spark-executor#traditional-v-rex-spark-application-deployment" aria-hidden="true" class="anchor" id="user-content-traditional-v-rex-spark-application-deployment" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Traditional v REX Spark Application Deployment</h3> 
  <p>To understand how REX delivers the scientific computing power of the R programming language to Spark applications on the JVM the following sections compare and constrast the deployment of traditional Scala, Java, Python and SparkR applications with Spark applications powered by the REX library.</p> 
  <p>The sole deployment requirement when working with the REX library is to add the necessary <code>Java Archive (.jar)</code> dependencies to your Spark application for REX, for the Renjin interpreter itself and for any <a href="http://packages.renjin.org/" target="_blank">Renjin-compatible CRAN R packages</a> that your R code will use. This is discussed in greater detail in <code>Application Deployment</code> section 3. that follows below.</p> 
  <p>####1. Traditional Scala | Java | Python Spark Application Deployment</p> 
  <p><a href="https://camo.githubusercontent.com/810f3f094a80bc25403682db857a1c9a65343e85/68747470733a2f2f6f6e657461706265796f6e642e6769746875622e696f2f7265736f757263652f696d672f7265782f747261642d737061726b2d6465706c6f792e6a7067" target="_blank"><img src="https://camo.githubusercontent.com/810f3f094a80bc25403682db857a1c9a65343e85/68747470733a2f2f6f6e657461706265796f6e642e6769746875622e696f2f7265736f757263652f696d672f7265782f747261642d737061726b2d6465706c6f792e6a7067" alt="Traditional Deployment: Spark" data-canonical-src="https://onetapbeyond.github.io/resource/img/rex/trad-spark-deploy.jpg" style="max-width:100%;"></a></p> 
  <p>Without REX library support, neither data scientists nor application developers have access to R's analytic capabilities within these types of application deployments.</p> 
  <p>####2. Traditional SparkR Application Deployment</p> 
  <p><a href="https://camo.githubusercontent.com/15ab98a19fde0de22920d81873db56832eb29134/68747470733a2f2f6f6e657461706265796f6e642e6769746875622e696f2f7265736f757263652f696d672f7265782f747261642d737061726b722d6465706c6f792e6a7067" target="_blank"><img src="https://camo.githubusercontent.com/15ab98a19fde0de22920d81873db56832eb29134/68747470733a2f2f6f6e657461706265796f6e642e6769746875622e696f2f7265736f757263652f696d672f7265782f747261642d737061726b722d6465706c6f792e6a7067" alt="Traditional Deployment: SparkR" data-canonical-src="https://onetapbeyond.github.io/resource/img/rex/trad-sparkr-deploy.jpg" style="max-width:100%;"></a></p> 
  <p>While data scientists can leverage the computing power of Spark within R applications in these types of application deployments, these same R capabilities are not available to Scala, Java or Python developers.</p> 
  <p>Note, when working with Apache SparkR, the R runtime environment must be installed locally on each worker node on your cluster.</p> 
  <p>####3. Scala | Java + R (REX) Spark Application Deployment</p> 
  <p><a href="https://camo.githubusercontent.com/9fad6bfae5c8b3aa917eaccb80448fa853052588/68747470733a2f2f6f6e657461706265796f6e642e6769746875622e696f2f7265736f757263652f696d672f7265782f6e65772d7265782d6465706c6f792e6a7067" target="_blank"><img src="https://camo.githubusercontent.com/9fad6bfae5c8b3aa917eaccb80448fa853052588/68747470733a2f2f6f6e657461706265796f6e642e6769746875622e696f2f7265736f757263652f696d672f7265782f6e65772d7265782d6465706c6f792e6a7067" alt="New Deployment: renjin-spark-executor" data-canonical-src="https://onetapbeyond.github.io/resource/img/rex/new-rex-deploy.jpg" style="max-width:100%;"></a></p> 
  <p>Both data scientists and application developers working in either Scala or Java can leverage the power of R using the REX library within these types of application deployments.</p> 
  <p>As REX, the Renjin R interpreter and all <a href="http://packages.renjin.org/" target="_blank">Renjin-compatible CRAN R packages</a> all native JVM libraries these dependencies are made available as standard <code>JAR</code> artifacts available for download or inclusion as managed dependencies from a Maven repository.</p> 
  <p>For example, the basic Maven artifact dependency delcarations for a REX-powered Spark batch application using the <code>sbt</code> build tool look as follows:</p> 
  <pre><code>libraryDependencies ++= Seq(
  "org.apache.spark" % "spark-core_2.10" % "version" % "provided",
  "io.onetapbeyond" % "renjin-spark-executor" % "version",
  "org.renjin" % "renjin-script-engine" % "version"
)
</code></pre> 
  <p>As a further example, the Maven artifact dependencies for a REX-powered Spark streaming application that depends on the Renjin-compatible CRAN R <code>survey</code> package using the <code>sbt</code> build tool look as follows:</p> 
  <pre><code>libraryDependencies ++= Seq(
  "org.apache.spark" % "spark-streaming_2.10" % "version" % "provided",
  "io.onetapbeyond" % "renjin-spark-executor" % "version",
  "org.renjin" % "renjin-script-engine" % "version",
  "org.renjin.cran" % "survey" % "version"
)
</code></pre> 
  <p>All Renjin artifacts are maintained within a Maven repository managed by <a href="http://www.bedatadriven.com" target="_blank">BeDataDriven</a>, the creators of the Renjin interpreter. To use these artifacts you must identify the <code>BeDataDriven</code> Maven repository to your build tool. For example, when using <code>sbt</code> the required <code>resolver</code> is as follows:</p> 
  <pre><code>resolvers += 
  "BeDataDriven" at "https://nexus.bedatadriven.com/content/groups/public"
</code></pre> 
  <p>Note, as REX is powered by Renjin there is <em>no need</em> to install the R runtime environment locally on each worker node on your cluster. This means REX works out-of-the box with all new or existing Spark clusters.</p> 
  <h3><a href="https://github.com/onetapbeyond/renjin-spark-executor#license" aria-hidden="true" class="anchor" id="user-content-license" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>License</h3> 
  <p>See the <a href="https://github.com/onetapbeyond/renjin-spark-executor/blob/master/LICENSE" target="_blank">LICENSE</a> file for license rights and limitations (Apache License 2.0).</p> 
 </article>
</div>