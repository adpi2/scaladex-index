<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <p><a href="https://gitpitch.com/onetapbeyond/opencpu-spark-executor/master" target="_blank"><img src="https://camo.githubusercontent.com/b7570c72831d2046e0ef64d4a103aac057eb67a1/68747470733a2f2f67697470697463682e636f6d2f6173736574732f62616467652e737667" alt="GitPitch" data-canonical-src="https://gitpitch.com/assets/badge.svg" style="max-width:100%;"></a></p> 
  <p>#Apache Spark OpenCPU Executor (ROSE)</p> 
  <p><a href="https://gitter.im/onetapbeyond/opencpu-spark-executor?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge" target="_blank"><img src="https://camo.githubusercontent.com/04e9caabe9f917bf06c7d9c5e52060eda2ff048f/68747470733a2f2f6261646765732e6769747465722e696d2f6f6e657461706265796f6e642f6f70656e6370752d737061726b2d6578656375746f722e737667" alt="Join the chat at https://gitter.im/onetapbeyond/opencpu-spark-executor" data-canonical-src="https://badges.gitter.im/onetapbeyond/opencpu-spark-executor.svg" style="max-width:100%;"></a></p> 
  <p>ROSE is an <a href="http://spark.apache.org/" target="_blank">Apache Spark</a> package offering access to the full scientific computing power of the R programming language to Spark batch and streaming applications on the JVM. This library is built on top of the <a href="https://github.com/onetapbeyond/opencpu-r-executor" target="_blank">opencpu-r-executor</a> library, a lightweight solution for integrating R analytics executed on the <a href="https://www.opencpu.org/" target="_blank">OpenCPU server</a> into any application running on the JVM.</p> 
  <h3><a id="user-content-rose-motivation" class="anchor" href="https://github.com/onetapbeyond/opencpu-spark-executor#rose-motivation" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>ROSE Motivation</h3> 
  <blockquote> 
   <p>Where Apache SparkR lets data scientists use Spark from R, ROSE is designed to let Scala and Java developers use R from Spark.</p> 
  </blockquote> 
  <p>The popular <a href="https://github.com/apache/spark/tree/master/R" target="_blank">Apache SparkR</a> package provides a lightweight front-end for data scientists to use Apache Spark from R. This approach is ideally suited to investigative analytics, such as ad-hoc and exploratory analysis at scale.</p> 
  <p>The ROSE library attempts to provide the same R analytics capabilities available to Apache SparkR applications within traditional Spark applications on the JVM. It does this by exposing new <code>analyze</code> operations that execute R analytics on compatible RDDs. This new facility is designed primarily for operational analytics and can be used alongside Spark core, SQL, Streaming, MLib and GraphX.</p> 
  <p>If you need to query R machine-learning models, score R prediction models or leverage any other aspect of the R library within your Spark applications on the JVM then the ROSE library may be for you.</p> 
  <h3><a id="user-content-rose-examples" class="anchor" href="https://github.com/onetapbeyond/opencpu-spark-executor#rose-examples" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>ROSE Examples</h3> 
  <p>A number of example applications are provided to demonstrate the use of the ROSE library to deliver R analytics capabilities within any Spark solution.</p> 
  <ul> 
   <li>Hello, World! [ <a href="https://github.com/onetapbeyond/opencpu-spark-executor/blob/master/examples/scala/hello-world" target="_blank">Scala</a> ][ <a href="https://github.com/onetapbeyond/opencpu-spark-executor/blob/master/examples/java/hello-world" target="_blank">Java</a> ]</li> 
   <li>Batch Predictive Scoring Engine [ <a href="https://github.com/onetapbeyond/opencpu-spark-executor/blob/master/examples/scala/batch-scoring-engine" target="_blank">Scala</a> ][ <a href="https://github.com/onetapbeyond/opencpu-spark-executor/blob/master/examples/java/batch-scoring-engine" target="_blank">Java</a> ]</li> 
   <li>Streaming Predictive Scoring Engine [ <a href="https://github.com/onetapbeyond/opencpu-spark-executor/blob/master/examples/scala/streaming-scoring-engine" target="_blank">Scala</a> ][ <a href="https://github.com/onetapbeyond/opencpu-spark-executor/blob/master/examples/java/streaming-scoring-engine" target="_blank">Java</a> ]</li> 
   <li>Twitter Sentiment Analysis [ <a href="https://github.com/onetapbeyond/opencpu-spark-executor/blob/master/examples/scala/sentiment-analysis" target="_blank">Scala</a> ][ <a href="https://github.com/onetapbeyond/opencpu-spark-executor/blob/master/examples/java/sentiment-analysis" target="_blank">Java</a> ]</li> 
  </ul> 
  <h3><a id="user-content-rose-sbt-dependency" class="anchor" href="https://github.com/onetapbeyond/opencpu-spark-executor#rose-sbt-dependency" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>ROSE SBT Dependency</h3> 
  <pre><code>libraryDependencies += "io.onetapbeyond" %% "opencpu-spark-executor_2.10" % "1.0"
</code></pre> 
  <h3><a id="user-content-rose-gradle-dependency" class="anchor" href="https://github.com/onetapbeyond/opencpu-spark-executor#rose-gradle-dependency" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>ROSE Gradle Dependency</h3> 
  <pre><code>compile 'io.onetapbeyond:opencpu-spark-executor_2.10:1.0'
</code></pre> 
  <h3><a id="user-content-rose-spark-package-dependency" class="anchor" href="https://github.com/onetapbeyond/opencpu-spark-executor#rose-spark-package-dependency" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>ROSE Spark Package Dependency</h3> 
  <p>Include the ROSE package in your Spark application using spark-shell, or spark-submit. For example:</p> 
  <pre><code>$SPARK_HOME/bin/spark-shell --packages io.onetapbeyond:opencpu-spark-executor_2.10:1.0
</code></pre> 
  <h3><a id="user-content-rose-basic-usage" class="anchor" href="https://github.com/onetapbeyond/opencpu-spark-executor#rose-basic-usage" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>ROSE Basic Usage</h3> 
  <p>This library exposes new <code>analyze</code> transformations on Spark RDDs of type <code>RDD[OCPUTask]</code>. The following sections demonstrate how to use these new RDD operations to execute R analytics directly within Spark batch and streaming applications on the JVM.</p> 
  <p>See the <a href="https://github.com/onetapbeyond/opencpu-r-executor" target="_blank">documentation</a> on the underlying <code>opencpu-r-executor</code> library for details on building <code>OCPUTask</code> and handling <code>OCPUResult</code>.</p> 
  <h3><a id="user-content-rose-spark-batch-usage" class="anchor" href="https://github.com/onetapbeyond/opencpu-spark-executor#rose-spark-batch-usage" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>ROSE Spark Batch Usage</h3> 
  <p>For this example we assume an input <code>dataRDD</code>, then transform it to generate an RDD of type <code>RDD[OCPUTask]</code>. In this example each <code>OCPUTask</code> represents a fraud score prediction to be generated by the R function <code>fraud::score</code> when the RDD is eventually evaluated.</p> 
  <pre><code>import io.onetapbeyond.opencpu.spark.executor.R._
import io.onetapbeyond.opencpu.r.executor._

val rTaskRDD = dataRDD.map(data =&gt; {
	OCPU.R()
		.pkg("fraud")
		.function("score")
		.input(data.asInput())
		.library()
	})
</code></pre> 
  <p>The set of <code>OCPUTask</code> within <code>rTaskRDD</code> can be scheduled for processing by calling the new <code>analyze</code> operation provided by ROSE on the RDD:</p> 
  <pre><code>val rResultRDD = rTaskRDD.analyze
</code></pre> 
  <p>When <code>rTaskRDD.analyze</code> is evaluated by Spark the resultant <code>rResultRDD</code> is of type <code>RDD[OCPUResult]</code>. The fraud prediction score for the original <code>OCPUTask</code> are available within these <code>OCPUResult</code>. These values can be optionally cached, further processed or persisted per the needs of your Spark application.</p> 
  <p>Note, the use here of the R function <code>fraud::score</code> is simply representative of any R function or script available within the full set of R packages available on <a href="https://www.r-project.org" target="_blank">CRAN R</a>, <a href="http://bioconductor.org/" target="_blank">Bioconductor</a> or on <a href="https://github.com/" target="_blank">github</a>.</p> 
  <h3><a id="user-content-rose-spark-streaming-usage" class="anchor" href="https://github.com/onetapbeyond/opencpu-spark-executor#rose-spark-streaming-usage" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>ROSE Spark Streaming Usage</h3> 
  <p>For this example we assume an input stream <code>dataStream</code>, then transform it to generate a new stream with underlying RDDs of type <code>RDD[OCPUTask]</code>. In this example each <code>OCPUTask</code> represents a fraud score prediction to be generated by the R function <code>fraud::score</code> when the stream is eventually evaluated.</p> 
  <pre><code>import io.onetapbeyond.opencpu.spark.executor.R._
import io.onetapbeyond.opencpu.r.executor._

val rTaskStream = dataStream.transform(rdd =&gt; {
	rdd.map(data =&gt; {
		OCPU.R()
			.pkg("fraud")
			.function("score")
			.input(data.asInput())
			.library()
		})	
	})
</code></pre> 
  <p>The set of <code>OCPUTask</code> within <code>rTaskStream</code> can be scheduled for processing by calling the new <code>analyze</code> operation provided by ROSE on each RDD within the stream:</p> 
  <pre><code>val rResultStream = rTaskStream.transform(rdd =&gt; rdd.analyze)
</code></pre> 
  <p>When <code>rTaskStream.transform</code> is evaluated by Spark the resultant <code>rResultStream</code> has underlying RDDs of type <code>RDD[OCPUResult]</code>. The fraud prediction score for the original <code>OCPUTask</code> are available within these <code>OCPUResult</code>. These values can be optionally cached, further processed or persisted per the needs of your Spark application.</p> 
  <p>Note, the use here of the R function <code>fraud::score</code> is simply representative of any R function or script available within the full set of R packages available on <a href="https://www.r-project.org" target="_blank">CRAN R</a>, <a href="http://bioconductor.org/" target="_blank">Bioconductor</a> or on <a href="https://github.com/" target="_blank">github</a>.</p> 
  <h3><a id="user-content-traditional-v-rose-spark-application-deployment" class="anchor" href="https://github.com/onetapbeyond/opencpu-spark-executor#traditional-v-rose-spark-application-deployment" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Traditional v ROSE Spark Application Deployment</h3> 
  <p>To understand how ROSE delivers the full scientific computing power of the R programming language to Spark applications on the JVM the following sections compare and constrast the deployment of traditional Scala, Java, Python and SparkR applications with Spark applications powered by the ROSE library.</p> 
  <p>The principal deployment requirement when working with ROSE is that your Spark cluster have access to one or more <a href="https://www.opencpu.org/download.html" target="_blank">OpenCPU servers</a>. Deployment options for those servers in the context of Spark are discussed in <code>Application Deployment</code> sections 3. and 4. that follow below.</p> 
  <p>####1. Traditional Scala | Java | Python Spark Application Deployment</p> 
  <p><a href="https://camo.githubusercontent.com/e21edc707f4662803fe7ac0d3d00b8afb89635a8/68747470733a2f2f6f6e657461706265796f6e642e6769746875622e696f2f7265736f757263652f696d672f726f73652f747261642d737061726b2d6465706c6f792e6a7067" target="_blank"><img src="https://camo.githubusercontent.com/e21edc707f4662803fe7ac0d3d00b8afb89635a8/68747470733a2f2f6f6e657461706265796f6e642e6769746875622e696f2f7265736f757263652f696d672f726f73652f747261642d737061726b2d6465706c6f792e6a7067" alt="Traditional Deployment: Spark" data-canonical-src="https://onetapbeyond.github.io/resource/img/rose/trad-spark-deploy.jpg" style="max-width:100%;"></a></p> 
  <p>Without ROSE library support, neither data scientists nor application developers have access to R's analytic capabilities within these types of application deployments.</p> 
  <p>####2. Traditional SparkR Application Deployment</p> 
  <p><a href="https://camo.githubusercontent.com/e0c0914b74f4be086475247ad604670cbdd03e2a/68747470733a2f2f6f6e657461706265796f6e642e6769746875622e696f2f7265736f757263652f696d672f726f73652f747261642d737061726b722d6465706c6f792e6a7067" target="_blank"><img src="https://camo.githubusercontent.com/e0c0914b74f4be086475247ad604670cbdd03e2a/68747470733a2f2f6f6e657461706265796f6e642e6769746875622e696f2f7265736f757263652f696d672f726f73652f747261642d737061726b722d6465706c6f792e6a7067" alt="Traditional Deployment: SparkR" data-canonical-src="https://onetapbeyond.github.io/resource/img/rose/trad-sparkr-deploy.jpg" style="max-width:100%;"></a></p> 
  <p>While data scientists can leverage the computing power of Spark within R applications in these types of application deployments, these same R capabilities are not available to Scala, Java or Python developers.</p> 
  <p>Note, when working with Apache SparkR, the R runtime environment must be installed locally on each worker node on your cluster.</p> 
  <p>####3. Scala | Java + R (ROSE) Spark Application Deployment</p> 
  <p><a href="https://camo.githubusercontent.com/f85bc51094d0a219eae55867d6cfacb03c0acfcb/68747470733a2f2f6f6e657461706265796f6e642e6769746875622e696f2f7265736f757263652f696d672f726f73652f6e65772d726f73652d6465706c6f792e6a7067" target="_blank"><img src="https://camo.githubusercontent.com/f85bc51094d0a219eae55867d6cfacb03c0acfcb/68747470733a2f2f6f6e657461706265796f6e642e6769746875622e696f2f7265736f757263652f696d672f726f73652f6e65772d726f73652d6465706c6f792e6a7067" alt="New Deployment: opencpu-spark-executor" data-canonical-src="https://onetapbeyond.github.io/resource/img/rose/new-rose-deploy.jpg" style="max-width:100%;"></a></p> 
  <p>Both data scientists and application developers working in either Scala or Java can leverage the full power of R using the ROSE library within these types of application deployments.</p> 
  <p>Using this deployment configuration, each worker node on the Spark cluster has its own dedicated <code>OpenCPU server</code> installed locally on the node. This configuration delivers optimal runtime throughput on the cluster. Note, this deployment configuration mirrors the configuration required by Apache SparkR, where the R runtime environment must be installed locally on each worker node on the cluster.</p> 
  <p>####4. Scala | Java + R (ROSE) Spark Application Deployment (Alternative)</p> 
  <p><a href="https://camo.githubusercontent.com/7b81b90f7ee3f62310351ae23a5949be008bc481/68747470733a2f2f6f6e657461706265796f6e642e6769746875622e696f2f7265736f757263652f696d672f726f73652f616c742d726f73652d6465706c6f792e6a7067" target="_blank"><img src="https://camo.githubusercontent.com/7b81b90f7ee3f62310351ae23a5949be008bc481/68747470733a2f2f6f6e657461706265796f6e642e6769746875622e696f2f7265736f757263652f696d672f726f73652f616c742d726f73652d6465706c6f792e6a7067" alt="Alt Deployment: opencpu-spark-executor" data-canonical-src="https://onetapbeyond.github.io/resource/img/rose/alt-rose-deploy.jpg" style="max-width:100%;"></a></p> 
  <p>Both data scientists and application developers working in either Scala or Java can leverage the full power of R using the ROSE library within these types of application deployments.</p> 
  <p>Using this deployment configuration, a cluster of one or more <code>OpenCPU servers</code> is maintained external to the Spark cluster. While maintaining these servers external to the Spark cluster potentially introduces runtime costs associated with networking latencies this approach does allow fast prototyping for ROSE-enabled Spark applications as no configuration changes need to be made to an existing Spark cluster to get up and running.</p> 
  <p>To take advantage of an external <code>OpenCPU server</code> cluster when working with ROSE simply pass an <code>Array[String]</code> of one or more server endpoints to the <code>analyze</code> transformation. For example, identify an external cluster of 3 <code>OpenCPU servers</code> for use by your Spark application:</p> 
  <pre><code>val ocpuCluster = sc.broadcast(Array("http://1.1.x.x/ocpu",
									 "http://1.1.y.y/ocpu",
									 "http://1.1.z.z/ocpu"))
val rResultRDD = rTaskRDD.analyze(ocpuCluster.value)
</code></pre> 
  <p>As shown, the array of server endpoints should be maintained as a broadcast variable within your Spark application. Each <code>OCPUTask</code> within your ROSE application will automatically be distributed for execution at random across the <code>OpenCPU server</code> cluster.</p> 
  <h3><a id="user-content-license" class="anchor" href="https://github.com/onetapbeyond/opencpu-spark-executor#license" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>License</h3> 
  <p>See the <a href="https://github.com/onetapbeyond/opencpu-spark-executor/blob/master/LICENSE" target="_blank">LICENSE</a> file for license rights and limitations (Apache License 2.0).</p> 
 </article>
</div>