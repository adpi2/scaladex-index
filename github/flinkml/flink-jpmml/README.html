<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <p><a href="https://travis-ci.org/FlinkML/flink-jpmml" target="_blank"><img src="https://camo.githubusercontent.com/f910be140680d152250160388ed1a3cd9710d10d/68747470733a2f2f7472617669732d63692e6f72672f466c696e6b4d4c2f666c696e6b2d6a706d6d6c2e737667" alt="Build Status" data-canonical-src="https://travis-ci.org/FlinkML/flink-jpmml.svg" style="max-width:100%;"></a> <a href="http://search.maven.org/#search%7Cga%7C1%7Ca%3A%22flink-jpmml-scala_2.10%22" target="_blank"><img src="https://camo.githubusercontent.com/fee29098c77f9320e6135817e4e5d76c6f56c2e0/68747470733a2f2f696d672e736869656c64732e696f2f6d6176656e2d63656e7472616c2f762f696f2e7261646963616c6269742f666c696e6b2d6a706d6d6c2d7363616c615f322e31302e7376673f6c6162656c3d6c617465737425323072656c65617365253230666f72253230322e3130" data-canonical-src="https://img.shields.io/maven-central/v/io.radicalbit/flink-jpmml-scala_2.10.svg?label=latest%20release%20for%202.10" style="max-width:100%;"></a> <a href="http://search.maven.org/#search%7Cga%7C1%7Ca%3A%22flink-jpmml-scala_2.11%22" target="_blank"><img src="https://camo.githubusercontent.com/314436a05b05fbcef3638d1e97fa66d9f485d6bf/68747470733a2f2f696d672e736869656c64732e696f2f6d6176656e2d63656e7472616c2f762f696f2e7261646963616c6269742f666c696e6b2d6a706d6d6c2d7363616c615f322e31312e7376673f6c6162656c3d6c617465737425323072656c65617365253230666f72253230322e3131" data-canonical-src="https://img.shields.io/maven-central/v/io.radicalbit/flink-jpmml-scala_2.11.svg?label=latest%20release%20for%202.11" style="max-width:100%;"></a></p> 
  <h1><a href="https://github.com/flinkml/flink-jpmml#flink-jpmml" aria-hidden="true" class="anchor" id="user-content-flink-jpmml" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>flink-jpmml</h1> 
  <p>Welcome! <code>flink-jpmml</code> is a fresh-made library for dynamic <strong>real time</strong> machine learning predictions built on top of <a href="http://dmg.org/pmml/v4-3/GeneralStructure.html" target="_blank">PMML</a> standard models and <a href="https://flink.apache.org/" target="_blank">Apache Flink</a> streaming engine.</p> 
  <p><code>flink-jpmml</code>is ease to use, running at <strong>serious</strong> scale, backend <strong>independent</strong> and naturally shaped to streaming scenario.</p> 
  <h2><a href="https://github.com/flinkml/flink-jpmml#prerequisites" aria-hidden="true" class="anchor" id="user-content-prerequisites" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Prerequisites</h2> 
  <p>In order to getting started, you only need</p> 
  <ul> 
   <li>any well-known version of a PMML model (<strong>3.2</strong> or above)</li> 
   <li>flink-jpmml is tested with the latest Flink (i.e. 1.3.2), but any working Apache Flink version (<a href="https://github.com/apache/flink" target="_blank">repo</a>) should work properly.</li> 
  </ul> 
  <h2><a href="https://github.com/flinkml/flink-jpmml#adding-flink-jpmml-dependency" aria-hidden="true" class="anchor" id="user-content-adding-flink-jpmml-dependency" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Adding <code>flink-jpmml</code> dependency</h2> 
  <ul> 
   <li> <p>if you employ sbt add the following dependecy to your project:</p> 
    <ul> 
     <li>Snapshot: <code>"io.radicalbit" %% "flink-jpmml-scala" % "0.7.0-SNAPSHOT"</code></li> 
     <li>Stable: <code>"io.radicalbit" %% "flink-jpmml-scala" % "0.6.1"</code></li> 
    </ul> </li> 
   <li> <p>For <a href="https://maven.apache.org/" target="_blank">maven</a> users instead:</p> 
    <ul> 
     <li>Snapshot</li> 
    </ul> <pre><code>&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;io.radicalbit&lt;/groupId&gt;
        &lt;artifactId&gt;flink-jpmml-scala&lt;/artifactId&gt;
        &lt;version&gt;0.7.0-SNAPSHOT&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre> 
    <ul> 
     <li>Stable:</li> 
    </ul> <pre><code>&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;io.radicalbit&lt;/groupId&gt;
        &lt;artifactId&gt;flink-jpmml-scala&lt;/artifactId&gt;
        &lt;version&gt;0.6.1&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre> </li> 
  </ul> 
  <p>Eventually, you can publish <code>flink-jpmml</code> on your local repository. Then</p> 
  <ol> 
   <li>execute within the flink-jpmml root</li> 
  </ol> 
  <pre><code>&gt; sbt
</code></pre> 
  <ol start="2"> 
   <li>select flink-jpmml-scala project</li> 
  </ol> 
  <pre><code>&gt; project flink-jpmml-scala
</code></pre> 
  <ol start="3"> 
   <li>publish the library to your local repo</li> 
  </ol> 
  <pre><code>&gt; publishLocal
</code></pre> 
  <p>Keep in mind you will need also Flink <code>scala-core</code> <code>flink-streaming</code> and <code>flink-clients</code> libraries.</p> 
  <p>Lets start.</p> 
  <h2><a href="https://github.com/flinkml/flink-jpmml#getting-started" aria-hidden="true" class="anchor" id="user-content-getting-started" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Getting Started</h2> 
  <p><code>flink-jpmml</code> enables Flink users to execute real time predictions based on machine learning models trained by any system supporting the PMML standard; this allows efficient streaming model serving along with the <strong>powerful</strong> Flink engine features.</p> 
  <h3><a href="https://github.com/flinkml/flink-jpmml#dynamic-models-evaluation" aria-hidden="true" class="anchor" id="user-content-dynamic-models-evaluation" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Dynamic Models Evaluation</h3> 
  <p>Since <code>0.6.0</code> the project supports dynamic streaming model serving efficiently. For more information we suggest to watch the <a href="https://www.youtube.com/watch?v=0rWvMZ6JSD8&amp;t=7s" target="_blank">related talk</a> presented at last Flink Forward 2017 in Berlin.</p> 
  <p>First of all, we indentify univocally models by the <code>ModelId</code> abstraction, made of an <em>applicationName</em> and a <em>version</em>.</p> 
  <blockquote> 
   <p><strong>e.g.</strong> Suppose you have two <em>ensemble</em> models A and B (PMML based) where A has a depth level 10 on width 100 and B depth 5 on width 200, and you desire to have a comparison between them, so likely you can identify <code>applicationName</code> SVM and <code>versions</code> A and B.</p> 
  </blockquote> 
  <p><code>flink-jpmml</code> does not store models within its operator state, but related metadata information. The operator is able to retrieve models from your distributed backend exploiting the concept of metadata table. Then, your PMML models have to be persisted in a backend system (see <a href="https://github.com/flinkml/flink-jpmml#dist-backend" target="_blank">here</a> for supported systems).</p> 
  <p>If you want to use dynamic model evaluation you're going to define the following streams:</p> 
  <ul> 
   <li><code>DataStream[ServingMessage]</code> this stream is the main user tool to feed the operator with necessary model information; here, the user is not demanded to send by stream its PMML models but only the requested descriptive metadata. The user should employ <code>ServingMessage</code> ADT in order to feed this stream. By now, the user can define the following two messages: 
    <ul> 
     <li><code>AddMessage</code> it requires an <code>applicationName</code> Java UUID formatted, a <code>version</code>, the model source <code>path</code> and a timestamp</li> 
     <li><code>DelMessage</code> it requires an <code>applicationName</code> Java UUID formatted, a <code>version</code> and a timestamp</li> 
    </ul> </li> 
   <li><code>DataStream[BaseEvent]</code> your input stream should extend the <code>BaseEvent</code> trait and defining the string <code>modelId</code> formatted as <code>"&lt;modelApplication&gt;_&lt;modelVersion&gt;"</code> and a timestamp.</li> 
  </ul> 
  <h3><a href="https://github.com/flinkml/flink-jpmml#the-syntax" aria-hidden="true" class="anchor" id="user-content-the-syntax" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>The syntax</h3> 
  <p>Given the streams above you can achieve predictions way easily.</p> 
  <pre><code>import io.radicalbit.flink.pmml.scala._
import org.apache.flink.ml.math.Vector
import org.apache.flink.streaming.api.scala._
import io.radicalbit.flink.pmml.scala.models.control.ServingMessage

... 

val inputStream: DataStream[_ &lt;: BaseEvent] = yourInputStream
val controlStream: DataStream[ServingMessage] = yourControlStream

val predictions = 
    inputStream
        .withSupportStream(controlStream)
        .evaluate&nbsp;{ (event, model) =&gt;
            val vector = event.toVector
            val prediction = model.predict(vector)
            
            prediction
        }
</code></pre> 
  <p>The features of flink-jpmml PMML models are better discussed <a href="https://github.com/flinkml/flink-jpmml#single-model" target="_blank">here</a>: you will find several ways to handle your predictions. All the concepts introduced along the first <code>flink-jpmml</code>, i.e. how the model is built within the operator, the operator configuration and so forth have been retained and are well described below.</p> 
  <p>We kept also the single operator model explained later if you want to bind a specific model to an operator instance.</p> 
  <h3><a href="https://github.com/flinkml/flink-jpmml#what-happens-internally" aria-hidden="true" class="anchor" id="user-content-what-happens-internally" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>What happens internally</h3> 
  <p><a href="https://github.com/flinkml/flink-jpmml/blob/master/images/architecture.png" target="_blank"><img src="https://github.com/flinkml/flink-jpmml/raw/master/images/architecture.png" alt="flink-jpmml-architecture" style="max-width:100%;"></a></p> 
  <p>When an event <strong>A</strong> comes, it declares by its <code>modelId</code> which is the model it needs to be evaluated against. If the model has not been uploaded within the operator yet, the latter will exploit the <strong>metadata</strong> information to lazily retrieve the targeted model from the underlying distributed backend.</p> 
  <p>The control stream is the right tool for the user to provide the global picture of the models available to your platform (this well fits a <strong>model repository server</strong> concept). <strong>You will use this stream to feed the operator with the information useful to your input events in order to let them grab easily the models.</strong></p> 
  <p>If the events are able to find the targeted models, the prediction is computed and a <code>Prediction</code> (based on ADT) outcome is returned, otherwise the outcome will be an <code>EmptyPrediction</code>.</p> 
  <h3><a href="https://github.com/flinkml/flink-jpmml#-single-model-operator" aria-hidden="true" class="anchor" id="user-content--single-model-operator" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a><a name="user-content-single-model" target="_blank" href=""></a> Single Model Operator</h3> 
  <p>Supposing you have your focused <code>InputStream</code> and you want to score related data</p> 
  <pre><code>import org.apache.flink.streaming.api.scala._

case class InputEvent(data: Array)

val env = StreamExecutionEnvironment.getExecutionEnvironment
val events: DataStream[InputEvent] = env.yourInputStream
</code></pre> 
  <p>So you can achieve it easily with the following</p> 
  <pre><code>// This will be all that you need
import io.radicalbit.flink.pmml.scala._

import org.apache.flink.ml.math.Vector
import org.apache.flink.streaming.api.scala._


object FlinkJpmmlExample&nbsp;{
  def main(args: Array[String]): Unit = {

    // your model can reside in any Flink supported backend
    val pathToPmml = "/even/to/distributed/systems"

    val env = StreamExecutionEnvironment.getExecutionEnvironment
    val events = env.yourInputStream

    //  a lazy reader implementation
    val reader = ModelReader(pathToPmml)

    // lets go with predictions
    events.evaluate(reader) { (event, model) =&gt;
      // FlinkML Vector abstraction is used
      val toBePredicted = vectorize(event)

      // and here we are
      val prediction: Prediction = model.predict(toBePredicted)
      val result = prediction.value

      // finally custom returns
      (event, result)
    }

    env.execute("Awesome predictions with flink-jpmml")
  }
}


</code></pre> 
  <p>Some useful insights from the code:</p> 
  <ul> 
   <li>in order to load the PMML model, you need to specify only the PMML source path</li> 
   <li><code>ModelReader</code> is a lazy reader and it provides the right reading abstraction to TaskManagers</li> 
   <li>The resulting <code>PMMLModel</code> will be <strong>loaded by once</strong> factory for each TaskManager running on your architecture at <em>construction time</em></li> 
   <li>the <code>PmmlModel.predict</code> method expects Flink Vectors as input event and, if you want to manage NaNs, an optional replace value;</li> 
   <li><code>Prediction</code> provides the result of the input event evaluation against the PMML model as a <code>Prediction[Double]</code> ADT, so if the model can't manage a prediction it will return a <code>EmptyPrediction</code> value.</li> 
  </ul> 
  <p><code>flink-jpmml</code> provides also a quick prediction function if it can run against a Stream of Flink Vectors</p> 
  <pre><code>...
val vectorStream: DataStream[Vector] = events.map(event =&gt; vectorize(event))
val predictions: DataStream[Prediction, Vector] = vectorStream.evaluate(reader)

predictions.map(_.target).print()

env.execute("flink-jpmml quick predictions")
</code></pre> 
  <p>These really basic examples show you how to interact with the library. The following sections try to address some interesting details which worth a deeper analysis.</p> 
  <h2><a href="https://github.com/flinkml/flink-jpmml#behind-the-scenes" aria-hidden="true" class="anchor" id="user-content-behind-the-scenes" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Behind the scenes&nbsp;</h2> 
  <p><code>flink-jpmml</code> main effort is to retain all the streaming concepts:</p> 
  <ul> 
   <li><a name="user-content-dist-backend" target="_blank" href=""></a>since Flink is able to run against several <strong>distributed backend</strong>, users need to specify only the PMML source path: the library will take care how to load the model in full compliance of the underlying distributed system (e.g. HDFS, Alluxio, S3, localFS)</li> 
   <li><code>ModelReader</code> is the object implementing the previous behavior; it will provide the loading methods but will read it <em>lazily</em>, <em>i.e.</em> only when the transformation will be applied</li> 
   <li>The <code>PMMLModel</code> will be loaded by a singleton model factory for each TaskManager running on your architecture; that means if you have an active TaskManager <em>A</em> made up of 4 TaskSlots, your TM will load the model from a single loader entity; this is crucial in order to let the system scale in thread-safety (still simple PMML models can grow to several hundreds of MegaBytes proportionally to the model size, meaning a big load in memory terms)</li> 
   <li>the <code>PmmlModel.predict</code> method expects Flink Vectors as input events; this choice let us to leverage the underlying Breeze implementation and <strong>no reflection</strong> will be applied at all; moreover, the user don't have to specify any key-value structure: you have data matching a feature vector, so the former will be used against the latter; (see <a href="https://github.com/flinkml/flink-jpmml#input-abstraction" target="_blank">input discussion</a> section for further details)</li> 
   <li><code>flink-jpmml</code> can also handle sparse data, thus you can just pass the desired <em>replace value</em> as argument to the discussed method (here you will need a SparseVector) <code>val prediction = model.predict(sparseData, replaceValue)</code></li> 
   <li><code>Prediction</code> is the output case class: it returns the result of the input event evaluation against the PMML model as a <code>Score[Double]</code> ADT, so if the model can't manage a prediction it will return a <code>EmptyScore</code>.</li> 
  </ul> 
  <p>The design worths bit more focus: the choice to have a UDF as input prediction method is justified by the need of handling a Machine Learning task (a prediction task) along with a pure Streaming application; in this way the user can manage predictions in the body of the function with the primitive event.</p> 
  <h2><a href="https://github.com/flinkml/flink-jpmml#input-vectors-abstraction" aria-hidden="true" class="anchor" id="user-content-input-vectors-abstraction" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Input Vectors Abstraction</h2> 
  <p><a name="user-content-input-abstraction" target="_blank" href=""></a></p> 
  <p>Assume this is the considered PMML feature vector</p> 
  <pre><code>["sepal_width", "sepal_length", "petal_width", "petal_length"]
</code></pre> 
  <p>and you have values for all these fields; so, just create a DenseVector</p> 
  <pre><code>val vector: DenseVector = DenseVector(value1, value2, value3, value4)
</code></pre> 
  <p>Suppose you missed value2, so you will need a SparseVector</p> 
  <pre><code>val vector: SparseVector = SparseVector(4, Array(0, 2, 3), Array(value1, value2, value4))
</code></pre> 
  <p><code>flink-jpmml</code> will recognize missing values and it will replace them with <code>replaceValue</code> if specified (as second argument of the <code>PmmlModel.predict</code> method), otherwise the NaNs handling is demanded to the PMML model.</p> 
  <p>Note also <code>flink-jpmml</code> assumes that if you employ a DenseVector, it means that the dense instance size is your model size and it will not predict anything (i.e. returns <code>Score.Empty</code>); in case of sparse instances, the library reads the sparse size value.</p> 
  <h2><a href="https://github.com/flinkml/flink-jpmml#how-flink-jpmml-handles-prediction-issues" aria-hidden="true" class="anchor" id="user-content-how-flink-jpmml-handles-prediction-issues" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>How <code>flink-jpmml</code> handles prediction issues</h2> 
  <p><code>flink-jpmml</code> won't break your job if something goes wrong but the model loading step; it is such a crucial action (it's mandatory for predictions), then in case of failure it raises a <code>ModelLoadingException</code>. Each other issue is detailed as log messages.</p> 
  <p>The handled failures are:</p> 
  <ul> 
   <li><em>Input Validation failure</em> - The input is not corresponding to the feature vector in size terms (either too big or too short)</li> 
   <li><em>Input Preparation failure</em> - JPMML library fails to prepare internal data format</li> 
   <li><em>Evaluation step failure</em> - JPMML fails to evaluate the input against the PMML</li> 
   <li><em>JPMML Result Extraction failure</em> - The job fails to retrieve the result from the PMML model</li> 
  </ul> 
  <h2><a href="https://github.com/flinkml/flink-jpmml#how-to-contribute" aria-hidden="true" class="anchor" id="user-content-how-to-contribute" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>How to Contribute</h2> 
  <p>If you want to contribute to the project send an email to <a href="https://github.com/flinkml/flink-jpmml/blob/master/info@radicalbit.io" target="_blank">info@radicalbit.io</a> or just open an issue here. <code>flink-jpmml</code> community is looking for you!</p> 
  <h2><a href="https://github.com/flinkml/flink-jpmml#authors" aria-hidden="true" class="anchor" id="user-content-authors" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Authors</h2> 
  <ul> 
   <li><strong>Andrea Spina</strong> - <a href="mailto:andrea.spina@radicalbit.io" target="_blank">andrea.spina@radicalbit.io</a> <a href="https://github.com/spi-x-i" target="_blank">@spi-x-i</a></li> 
   <li><strong>Francesco Frontera</strong> - <a href="mailto:francesco.frontera@radicalbit.io" target="_blank">francesco.frontera@radicalbit.io</a> <a href="https://github.com/francescofrontera" target="_blank">@francescofrontera</a></li> 
   <li><strong>Riccardo Diomedi</strong> - <a href="mailto:riccardo.diomedi@radicalbit.io" target="_blank">riccardo.diomedi@radicalbit.io</a> <a href="https://github.com/riccardo14" target="_blank">@riccardo14</a></li> 
   <li><strong>Mauro Cortellazzi</strong> - <a href="mailto:mauro.cortellazzi@radicalbit.io" target="_blank">mauro.cortellazzi@radicalbit.io</a> <a href="https://github.com/maocorte" target="_blank">@maocorte</a></li> 
   <li><strong>Simone Robutti</strong> - <em>Initial prototype</em> <a href="mailto:simone.robutti@gmail.com" target="_blank">simone.robutti@gmail.com</a> <a href="https://github.com/chobeat" target="_blank">@chobeat</a></li> 
   <li><strong>Stefano Baghino</strong> - <em>Initial prototype</em> <a href="https://github.com/stefanobaghino" target="_blank">@stefanobaghino</a></li> 
  </ul> 
  <h2><a href="https://github.com/flinkml/flink-jpmml#disclaimer" aria-hidden="true" class="anchor" id="user-content-disclaimer" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Disclaimer</h2> 
  <ul> 
   <li>Apache®, Apache Flink™, Flink™, and the Apache feather logo are trademarks of <a href="http://apache.org/" target="_blank">The Apache Software Foundation</a>.</li> 
   <li>PMML standard is a trademark of The <a href="https://github.com/flinkml/flink-jpmml/blob/master/www.dmg.org" target="_blank">Data Mining Group</a>. All rights reserved.</li> 
   <li>JPMML-Evaluator is licensed under the GNU Affero General Public License (AGPL) version 3.0. Other licenses are available on request.</li> 
  </ul> 
  <h2><a href="https://github.com/flinkml/flink-jpmml#license" aria-hidden="true" class="anchor" id="user-content-license" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>License</h2> 
  <p>This library has been published under the GNU Affero General Public License (AGPL) version 3.0 following and respecting <a href="https://www.apache.org/licenses/GPL-compatibility.html" target="_blank">the official advices coming from the Apache Software Foundation</a> about the compatibility between the Apache License, Version 2.0 and the GNU General Public License, Version 3.0</p> 
  <hr> 
  <p><sub>THIS STANDARD IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS RELEASE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</sub></p> 
 </article>
</div>