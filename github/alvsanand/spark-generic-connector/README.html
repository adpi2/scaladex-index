<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a href="https://github.com/alvsanand/spark-generic-connector#generic-connector-for-apache-spark" aria-hidden="true" class="anchor" id="user-content-generic-connector-for-apache-spark" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Generic Connector for Apache Spark</h1> 
  <p><a href="https://travis-ci.org/alvsanand/spark-generic-connector" target="_blank"><img src="https://camo.githubusercontent.com/d8b59c5e1e80d60cd2f16f39ab8698503595aec6/68747470733a2f2f7472617669732d63692e6f72672f616c7673616e616e642f737061726b2d67656e657269632d636f6e6e6563746f722e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/alvsanand/spark-generic-connector.svg?branch=master" style="max-width:100%;"></a></p> 
  <p>This library simplifies the connection of a external system with <a href="http://spark.apache.org/" target="_blank">Apache Spark</a>. Its main idea is to use a core functionality that is responsible of working with Apache Spark and implement specific connectors for any system. It can be used in batch or streaming scenarios which is awesome. From the first time, the idea is to be a <em>read only</em> connector library. So any write operations will not be implemented.</p> 
  <p>This is are the ideas behind the library:</p> 
  <ul> 
   <li>The Spark core of the library is shared by all the connectors.</li> 
   <li>Batch and streaming scenarios are compatible with the library.</li> 
   <li>It is very easy and fast to integrate with a new system. Just extends <em>SgcConnector</em>.</li> 
   <li><em>SgcConnector</em> has two operation:</li> 
   <li><code>def list(): Seq[SgcSlot]</code>: list all the slots available to fetch.</li> 
   <li><code>def fetch(slot: SgcSlot, out: OutputStream)</code>: fetch a slot to memory.</li> 
   <li>A slot is the smallest part than a <em>SgcConnector</em> can fetch in a single time. That means that the data of a slot cannot be split.</li> 
   <li>In order to be streaming compatible the slot returned by the <em>SgcConnector</em> must contains date information (<em>SgcDateSlot</em>) in order to be sorted by time.</li> 
  </ul> 
  <blockquote> 
   <p>NOTE: Generic Connector is with Apache Spark &gt; 1.5.X and only for the Scala/Java interpreter.</p> 
  </blockquote> 
  <h2><a href="https://github.com/alvsanand/spark-generic-connector#requirements" aria-hidden="true" class="anchor" id="user-content-requirements" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Requirements</h2> 
  <p>This library requires <em>Spark 1.5+</em></p> 
  <h2><a href="https://github.com/alvsanand/spark-generic-connector#using-in-apache-spark-as-a-package" aria-hidden="true" class="anchor" id="user-content-using-in-apache-spark-as-a-package" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Using in Apache Spark as a package</h2> 
  <p>You can use <em>Generic Connector</em> in the <em>Spark Shell</em> adding the packages dependencies:</p> 
  <ul> 
   <li> <p>Spark 1.x:</p> 
    <ul> 
     <li> <p>Scala 2.10</p> <pre><code>  ./bin/spark-shell --packages alvsanand:spark-generic-connector:0.2.0-spark_1x-s_2.10
</code></pre> </li> 
     <li> <p>Scala 2.11</p> <pre><code>  ./bin/spark-shell --packages alvsanand:spark-generic-connector:0.2.0-spark_1x-s_2.11
</code></pre> </li> 
    </ul> </li> 
   <li> <p>Spark 2.x:</p> 
    <ul> 
     <li> <p>Scala 2.10</p> <pre><code>  ./bin/spark-shell --packages alvsanand:spark-generic-connector:0.2.0-spark_2x-s_2.10
</code></pre> </li> 
     <li> <p>Scala 2.11</p> <pre><code>  ./bin/spark-shell --packages alvsanand:spark-generic-connector:0.2.0-spark_2x-s_2.11
</code></pre> </li> 
    </ul> </li> 
  </ul> 
  <h2><a href="https://github.com/alvsanand/spark-generic-connector#linking-not-yet-released-as-a-scala-library" aria-hidden="true" class="anchor" id="user-content-linking-not-yet-released-as-a-scala-library" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Linking [Not yet released] as a Scala Library</h2> 
  <p>You can link against this library in your program at the following coordinates:</p> 
  <h3><a href="https://github.com/alvsanand/spark-generic-connector#generic-connector-core" aria-hidden="true" class="anchor" id="user-content-generic-connector-core" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Generic Connector core</h3> 
  <ul> 
   <li> <p>Scala 2.10</p> <pre><code> groupId: es.alvsanand
 artifactId: spark-generic-connector-main_2.10
 version: 0.2.0
</code></pre> </li> 
   <li> <p>Scala 2.11</p> <pre><code> groupId: es.alvsanand
 artifactId: spark-generic-connector-main_2.11
 version: 0.2.0
</code></pre> </li> 
  </ul> 
  <h3><a href="https://github.com/alvsanand/spark-generic-connector#generic-connector-for-apache-spark-1x" aria-hidden="true" class="anchor" id="user-content-generic-connector-for-apache-spark-1x" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Generic Connector for Apache Spark 1.X</h3> 
  <ul> 
   <li> <p>Scala 2.10</p> <pre><code> groupId: es.alvsanand
 artifactId: spark-generic-connector-spark_1x_2.10
 version: 0.2.0
</code></pre> </li> 
   <li> <p>Scala 2.11</p> <pre><code> groupId: es.alvsanand
 artifactId: spark-generic-connector-spark_1x_2.11
 version: 0.2.0
</code></pre> </li> 
  </ul> 
  <h3><a href="https://github.com/alvsanand/spark-generic-connector#generic-connector-for-apache-spark-2x" aria-hidden="true" class="anchor" id="user-content-generic-connector-for-apache-spark-2x" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Generic Connector for Apache Spark 2.X</h3> 
  <ul> 
   <li> <p>Scala 2.10</p> <pre><code> groupId: es.alvsanand
 artifactId: spark-generic-connector-spark_2x_2.10
 version: 0.2.0
</code></pre> </li> 
   <li> <p>Scala 2.11</p> <pre><code> groupId: es.alvsanand
 artifactId: spark-generic-connector-spark_2x_2.11
 version: 0.2.0
</code></pre> </li> 
  </ul> 
  <h3><a href="https://github.com/alvsanand/spark-generic-connector#google-connectors-google-cloud-storage--doubleclick-datatranfers" aria-hidden="true" class="anchor" id="user-content-google-connectors-google-cloud-storage--doubleclick-datatranfers" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Google connectors [Google Cloud Storage / Doubleclick Datatranfers]</h3> 
  <ul> 
   <li> <p>Scala 2.10</p> <pre><code> groupId: es.alvsanand
 artifactId: spark-generic-connector-google_2.10
 version: 0.2.0
</code></pre> </li> 
   <li> <p>Scala 2.11</p> <pre><code> groupId: es.alvsanand
 artifactId: spark-generic-connector-google_2.11
 version: 0.2.0
</code></pre> </li> 
  </ul> 
  <h3><a href="https://github.com/alvsanand/spark-generic-connector#ftp-connectors-ftp--sftp--ftps" aria-hidden="true" class="anchor" id="user-content-ftp-connectors-ftp--sftp--ftps" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>FTP connectors [FTP / SFTP / FTPS]</h3> 
  <ul> 
   <li> <p>Scala 2.10</p> <pre><code> groupId: es.alvsanand
 artifactId: spark-generic-connector-ftp_2.10
 version: 0.2.0
</code></pre> </li> 
   <li> <p>Scala 2.11</p> <pre><code> groupId: es.alvsanand
 artifactId: spark-generic-connector-ftp_2.11
 version: 0.2.0
</code></pre> </li> 
  </ul> 
  <h2><a href="https://github.com/alvsanand/spark-generic-connector#how-to-use-it" aria-hidden="true" class="anchor" id="user-content-how-to-use-it" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>How to use it</h2> 
  <p>Currently <em>Sgc</em> supports two scenarios:</p> 
  <ul> 
   <li>Batch</li> 
   <li>Streaming</li> 
  </ul> 
  <h3><a href="https://github.com/alvsanand/spark-generic-connector#batch-scenario" aria-hidden="true" class="anchor" id="user-content-batch-scenario" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Batch scenario</h3> 
  <p>In order to use the library with <em>Apache Spark</em> in batch mode, you must follow the next steps:</p> 
  <ul> 
   <li> <p>Import dependencies:</p> <pre><code>  import org.apache.spark.streaming.sgc._
  import es.alvsanand.sgc.ftp.{FTPCredentials, FTPSlot}
  import es.alvsanand.sgc.ftp.normal.{FTPSgcConnectorFactory, FTPParameters}
</code></pre> </li> 
   <li> <p>Create a parameters object:</p> <pre><code>  val parameters = FTPParameters("HOST", PORT, "DIRECTORY", FTPCredentials("USER", Option("PASSWORD"))
</code></pre> </li> 
   <li> <p>Create the RDD passing the SgcConnectorFactory and the parameters:</p> <pre><code>  val rdd = sc.createSgcRDD(FTPSgcConnectorFactory, parameters)
</code></pre> </li> 
   <li> <p>Use the RDD as desired:</p> <pre><code>  rdd.partitions.map(_.asInstanceOf[SgcRDDPartition[SgcSlot]].slot)
  rdd.saveAsTextFile("hdfs://...")
</code></pre> </li> 
  </ul> 
  <h3><a href="https://github.com/alvsanand/spark-generic-connector#streaming-scenario" aria-hidden="true" class="anchor" id="user-content-streaming-scenario" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Streaming scenario</h3> 
  <p>In order to use the library with <em>Apache Spark</em> in streaming mode, you must follow the next steps:</p> 
  <ul> 
   <li> <p>Import dependencies:</p> <pre><code>  import org.apache.spark.streaming.sgc._
  import es.alvsanand.sgc.ftp.{FTPCredentials, FTPSlot}
  import es.alvsanand.sgc.ftp.normal.{FTPSgcConnectorFactory, FTPParameters}
</code></pre> </li> 
   <li> <p>Create a parameters object:</p> <pre><code>  val parameters = FTPParameters("HOST", PORT, "DIRECTORY", FTPCredentials("USER", Option("PASSWORD"))
</code></pre> </li> 
   <li> <p>Create the InputDStream passing the SgcConnectorFactory and the parameters:</p> <pre><code>  val ssc = new StreamingContext(sc, batchTime)
 
  val ds = ssc.createSgcInputDStream(FTPSgcConnectorFactory, parameters, range)
 
  ds.checkpoint(checkpointTime)
 
  ssc.checkpoint(checkPointDirectory)
</code></pre> </li> 
   <li> <p>Use the InputDStream as desired:</p> <pre><code>  ds.foreachRDD { rdd =&gt;
      rddrdd.saveAsTextFile("hdfs://...")
  }
</code></pre> </li> 
  </ul> 
  <h2><a href="https://github.com/alvsanand/spark-generic-connector#sgcconnector-ready-to-use" aria-hidden="true" class="anchor" id="user-content-sgcconnector-ready-to-use" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>SgcConnector ready to use</h2> 
  <p>Nowadays, Sgc has implemented the following connectors:</p> 
  <ul> 
   <li> <p>Google services:</p> 
    <ul> 
     <li>CloudStorageSgcConnector: is able to fetch files from <a href="https://cloud.google.com/storage" target="_blank">Google Cloud Storage</a>.</li> 
     <li>DataTransferSgcConnector: is able to fetch files from <a href="https://support.google.com/dcm/partner/answer/165589?hl=en" target="_blank">DoubleClick Data Transfer</a>.</li> 
    </ul> </li> 
   <li> <p>FTP servers like:</p> 
    <ul> 
     <li>FTPSgcConnector: is able to fetch files from a FTP server.</li> 
     <li>FTPSSgcConnector: is able to fetch files from a FTPS server</li> 
     <li>SFTPSgcConnector: is able to fetch files from a SFTP server</li> 
    </ul> </li> 
  </ul> 
  <blockquote> 
   <p>Note: for more details of every connectors visit <a href="https://github.com/alvsanand/spark-generic-connector#examples" target="_blank">Examples section</a></p> 
  </blockquote> 
  <h2><a href="https://github.com/alvsanand/spark-generic-connector#how-to-create-new-connectors" aria-hidden="true" class="anchor" id="user-content-how-to-create-new-connectors" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>How to create new Connectors</h2> 
  <ul> 
   <li> <p>Import dependencies:</p> <pre><code>  import java.io._
  import com.wix.accord.Validator
  import com.wix.accord.dsl.{be, _}
  import es.alvsanand.sgc.core.connector.{SgcConnector, SgcConnectorException, SgcConnectorParameters}
  
  // Every other required dependency
</code></pre> </li> 
   <li> <p>Create a new type of <em>SgcConnectorParameters</em>:</p> <pre><code>  case class RssParameters(url: String) extends SgcConnectorParameters
</code></pre> </li> 
   <li> <p>Create a new type of <em>SgcSlot</em>:</p> <pre><code>  case class RssSlot(title: String, description: String, link: String, date: Date) extends SgcDateSlot
</code></pre> </li> 
  </ul> 
  <blockquote> 
   <p>Note: in case to be streaming compatible the slot must extend <em>SgcDateSlot</em>. If not, <em>SgcSlot</em>.</p> 
  </blockquote> 
  <ul> 
   <li> <p>Create a new type of <em>SgcConnector</em>:</p> <pre><code>  class RssSgcConnector(parameters: RssParameters)
    extends SgcConnector[RssSlot, RssParameters](parameters) {
    
    ......
  
  }
</code></pre> </li> 
   <li> <p>Implement the <em>SgcConnector</em>:</p> 
    <ol> 
     <li> <p>Override <em>getValidator</em> in order to validates the parameters:</p> <pre><code>  override def getValidator(): Validator[RssParameters] = {
      validator[RssParameters] { p =&gt;
        p.url is notNull
        p.url is notEmpty
      }
   }
</code></pre> </li> 
     <li> <p>Create a client and be sure it is <em>Thread Safe</em> or there is one instance for every Thread:</p> <pre><code>  private lazy val client: RSSClient = initClient()
  
  private def initClient(): RSSClient = synchronized {
      var client: RSSClient = null
  
      // Initialize client
  }
</code></pre> </li> 
     <li> <p>It is also recommendable to create helper methods to use the client:</p> <pre><code>  private def connect(): Unit = {
    if (!client.isConnected) {
      Try(client.connect()) match {
        case Failure(e) =&gt; throw SgcConnectorException(s"Error connecting to server", e)
        case _ =&gt;
      }
    }
  }
 
  private def disconnect(): Unit = {
    if (client.isConnected) {
      client.disconnect()
    }
  }
  
  private def useClient[T](func: () =&gt; T): T = {
    Try(connect()) match {
      case Failure(e) =&gt; throw e
      case _ =&gt;
    }
  
   val value = Try(func())
  
    Try(disconnect()) // Ignore exception in disconnecting
  
    value match {
      case Success(s) =&gt; s
      case Failure(e) =&gt; throw e
    }
  }
</code></pre> </li> 
     <li> <p>Override <em>list</em> in order to list the slots available:</p> <pre><code>  @throws(classOf[SgcConnectorException])
  def list(): Seq[RssSlot] = {
      var entries: Array[FeedMessage] = Array.empty
  
      Try({
        files = useClient[Array[RssSlot]](() =&gt; {
          client.listFiles(".").map(x =&gt; RssSlot(x.title, x.description, x.link, x.date: Date))
                .sortBy(_.name).toSeq
        })
      })
      match {
        case Success(v) =&gt; v
        case Failure(e) =&gt; {
          throw SgcConnectorException(s"Error listing messages", e)
        }
      }
  }
</code></pre> </li> 
     <li> <p>Override <em>list</em> in order to validates the parameters:</p> <pre><code>  @throws(classOf[SgcConnectorException])
    override def fetch(slot: FTPSlot, out: OutputStream): Unit = {
      Try({
        val in = useClient[InputStream](() =&gt; {
          client.retrieveFeedMessage(slot.link)
        })
  
        if (in != null) {
          IOUtils.copy(in, out)
  
          in.close()
        }
      })
      match {
        case Success(v) =&gt;
        case Failure(e) =&gt; {
          val msg = 
          throw SgcConnectorException(s"Error fetching slot[$slot]", e)
        }
      }
  }
</code></pre> </li> 
    </ol> </li> 
   <li> <p>Create a new type of <em>SgcConnectorFactory</em>:</p> <pre><code>   object RssSgcConnectorFactory extends SgcConnectorFactory[RssSlot, RssParameters] {
   
     override def get(parameters: RssParameters): SgcConnector[RssSlot, RssParameters] = {
       new RssSgcConnector(parameters)
     }
   }
</code></pre> </li> 
  </ul> 
  <h2><a href="https://github.com/alvsanand/spark-generic-connector#scaladoc" aria-hidden="true" class="anchor" id="user-content-scaladoc" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Scaladoc</h2> 
  <p><a href="https://github.com/alvsanand/spark-generic-connector/blob/master/docs/scaladoc/index.html" target="_blank">Here</a> you can see the Scala API documentation of the project.</p> 
  <h2><a href="https://github.com/alvsanand/spark-generic-connector#examples" aria-hidden="true" class="anchor" id="user-content-examples" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Examples</h2> 
  <p>There are multiple <a href="https://github.com/alvsanand/spark-generic-connector/tree/master/examples" target="_blank">notebooks</a> that show the features of the Library and how to use it correctly.</p> 
  <h2><a href="https://github.com/alvsanand/spark-generic-connector#building-from-source" aria-hidden="true" class="anchor" id="user-content-building-from-source" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Building From Source</h2> 
  <p>To build the JAR slots simply run <code>sbt package</code> from the project root. The build configuration includes support for both Scala 2.10 and 2.11.</p> 
 </article>
</div>