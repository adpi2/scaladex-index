<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
  <parent>
    <artifactId>zeppelin</artifactId>
    <groupId>org.apache.zeppelin</groupId>
    <version>0.7.1</version>
  </parent>
  <modelVersion>4.0.0</modelVersion>
  <groupId>org.apache.zeppelin</groupId>
  <artifactId>zeppelin-spark_2.10</artifactId>
  <name>Zeppelin: Spark</name>
  <version>0.7.1</version>
  <description>Zeppelin spark support</description>
  <build>
    <plugins>
      <plugin>
        <artifactId>maven-enforcer-plugin</artifactId>
        <executions>
          <execution>
            <id>enforce</id>
            <phase>none</phase>
          </execution>
        </executions>
      </plugin>
      <plugin>
        <artifactId>maven-surefire-plugin</artifactId>
        <configuration>
          <forkCount>1</forkCount>
          <reuseForks>false</reuseForks>
          <argLine>-Xmx1024m -XX:MaxPermSize=256m</argLine>
          <excludes>
            <exclude>**/SparkRInterpreterTest.java</exclude>
            <exclude>${pyspark.test.exclude}</exclude>
          </excludes>
        </configuration>
      </plugin>
      <plugin>
        <artifactId>maven-shade-plugin</artifactId>
        <version>${plugin.shade.version}</version>
        <executions>
          <execution>
            <phase>package</phase>
            <goals>
              <goal>shade</goal>
            </goals>
          </execution>
        </executions>
        <configuration>
          <filters>
            <filter>
              <artifact>*:*</artifact>
              <excludes>
                <exclude>META-INF/*.SF</exclude>
                <exclude>META-INF/*.DSA</exclude>
                <exclude>META-INF/*.RSA</exclude>
              </excludes>
            </filter>
          </filters>
          <transformers>
            <transformer />
            <transformer>
              <resource>reference.conf</resource>
            </transformer>
          </transformers>
        </configuration>
      </plugin>
      <plugin>
        <artifactId>maven-dependency-plugin</artifactId>
        <executions>
          <execution>
            <phase>package</phase>
            <goals>
              <goal>copy</goal>
            </goals>
            <configuration>
              <outputDirectory>${project.build.directory}/../../interpreter/spark</outputDirectory>
              <overWriteReleases>false</overWriteReleases>
              <overWriteSnapshots>false</overWriteSnapshots>
              <overWriteIfNewer>true</overWriteIfNewer>
              <includeScope>runtime</includeScope>
              <artifactItems>
                <artifactItem>
                  <groupId>${project.groupId}</groupId>
                  <artifactId>${project.artifactId}</artifactId>
                  <version>${project.version}</version>
                  <type>${project.packaging}</type>
                </artifactItem>
              </artifactItems>
            </configuration>
          </execution>
        </executions>
      </plugin>
      <plugin>
        <groupId>org.scala-tools</groupId>
        <artifactId>maven-scala-plugin</artifactId>
        <version>${plugin.scala.version}</version>
        <executions>
          <execution>
            <id>compile</id>
            <phase>compile</phase>
            <goals>
              <goal>compile</goal>
            </goals>
          </execution>
          <execution>
            <id>test-compile</id>
            <phase>test-compile</phase>
            <goals>
              <goal>testCompile</goal>
            </goals>
          </execution>
          <execution>
            <phase>process-resources</phase>
            <goals>
              <goal>compile</goal>
            </goals>
          </execution>
        </executions>
        <configuration>
          <excludes>
            <exclude>**/ZeppelinR.scala</exclude>
            <exclude>**/SparkRBackend.scala</exclude>
          </excludes>
        </configuration>
      </plugin>
      <plugin>
        <artifactId>maven-compiler-plugin</artifactId>
        <configuration>
          <excludes>
            <exclude>**/SparkRInterpreter.java</exclude>
          </excludes>
          <testExcludes>
            <testExclude>${pyspark.test.exclude}</testExclude>
            <testExclude>**/SparkRInterpreterTest.java</testExclude>
            <testExclude>**/ZeppelinRTest.java</testExclude>
          </testExcludes>
        </configuration>
      </plugin>
      <plugin>
        <groupId>org.scala-tools</groupId>
        <artifactId>maven-scala-plugin</artifactId>
        <configuration>
          <excludes>
            <exclude>**/ZeppelinR.scala</exclude>
            <exclude>**/SparkRBackend.scala</exclude>
          </excludes>
        </configuration>
      </plugin>
      <plugin>
        <artifactId>maven-surefire-plugin</artifactId>
        <configuration>
          <includes>
            <include>${pyspark.test.include}</include>
          </includes>
          <excludes>
            <exclude>${pyspark.test.exclude}</exclude>
            <exclude>**/SparkRInterpreterTest.java</exclude>
          </excludes>
        </configuration>
      </plugin>
    </plugins>
  </build>
  <profiles>
    <profile>
      <id>spark-1.4</id>
      <properties>
        <spark.version>1.4.1</spark.version>
      </properties>
    </profile>
    <profile>
      <id>spark-1.5</id>
      <properties>
        <protobuf.version>2.5.0</protobuf.version>
        <akka.version>2.3.11</akka.version>
        <akka.group>com.typesafe.akka</akka.group>
        <spark.version>1.5.2</spark.version>
      </properties>
    </profile>
    <profile>
      <id>spark-1.6</id>
      <properties>
        <protobuf.version>2.5.0</protobuf.version>
        <akka.version>2.3.11</akka.version>
        <akka.group>com.typesafe.akka</akka.group>
        <py4j.version>0.9</py4j.version>
        <spark.version>1.6.3</spark.version>
      </properties>
    </profile>
    <profile>
      <id>spark-2.0</id>
      <properties>
        <protobuf.version>2.5.0</protobuf.version>
        <scala.version>2.11.8</scala.version>
        <py4j.version>0.10.3</py4j.version>
        <spark.version>2.0.2</spark.version>
      </properties>
    </profile>
    <profile>
      <id>spark-2.1</id>
      <properties>
        <protobuf.version>2.5.0</protobuf.version>
        <scala.version>2.11.8</scala.version>
        <py4j.version>0.10.4</py4j.version>
        <spark.version>2.1.0</spark.version>
      </properties>
    </profile>
    <profile>
      <id>hadoop-0.23</id>
      <dependencies>
        <dependency>
          <groupId>org.apache.avro</groupId>
          <artifactId>avro</artifactId>
        </dependency>
      </dependencies>
      <properties>
        <hadoop.version>0.23.10</hadoop.version>
      </properties>
    </profile>
    <profile>
      <id>hadoop-1</id>
      <properties>
        <codehaus.jackson.version>1.8.8</codehaus.jackson.version>
        <akka.group>org.spark-project.akka</akka.group>
        <hadoop.version>1.0.4</hadoop.version>
        <avro.mapred.classifier>hadoop1</avro.mapred.classifier>
      </properties>
    </profile>
    <profile>
      <id>hadoop-2.2</id>
      <properties>
        <protobuf.version>2.5.0</protobuf.version>
        <hadoop.version>2.2.0</hadoop.version>
        <avro.mapred.classifier>hadoop2</avro.mapred.classifier>
      </properties>
    </profile>
    <profile>
      <id>hadoop-2.3</id>
      <properties>
        <protobuf.version>2.5.0</protobuf.version>
        <jets3t.version>0.9.3</jets3t.version>
        <hadoop.version>2.3.0</hadoop.version>
        <avro.mapred.classifier>hadoop2</avro.mapred.classifier>
      </properties>
    </profile>
    <profile>
      <id>hadoop-2.4</id>
      <properties>
        <protobuf.version>2.5.0</protobuf.version>
        <jets3t.version>0.9.3</jets3t.version>
        <hadoop.version>2.4.0</hadoop.version>
        <avro.mapred.classifier>hadoop2</avro.mapred.classifier>
      </properties>
    </profile>
    <profile>
      <id>hadoop-2.6</id>
      <properties>
        <protobuf.version>2.5.0</protobuf.version>
        <jets3t.version>0.9.3</jets3t.version>
        <hadoop.version>2.6.0</hadoop.version>
        <avro.mapred.classifier>hadoop2</avro.mapred.classifier>
      </properties>
    </profile>
    <profile>
      <id>hadoop-2.7</id>
      <properties>
        <protobuf.version>2.5.0</protobuf.version>
        <jets3t.version>0.9.0</jets3t.version>
        <hadoop.version>2.7.2</hadoop.version>
        <avro.mapred.classifier>hadoop2</avro.mapred.classifier>
      </properties>
    </profile>
    <profile>
      <id>sparkr</id>
      <build>
        <resources>
          <resource>
            <directory>/private/tmp/zeppelin-release/zeppelin/spark/src/main/resources</directory>
            <excludes>
              <exclude>interpreter-setting.json</exclude>
            </excludes>
          </resource>
          <resource>
            <directory>/private/tmp/zeppelin-release/zeppelin/spark/src/main/sparkr-resources</directory>
          </resource>
        </resources>
        <plugins>
          <plugin>
            <artifactId>maven-compiler-plugin</artifactId>
            <configuration>
              <excludes />
              <testExcludes>
                <testExclude>${pyspark.test.exclude}</testExclude>
              </testExcludes>
            </configuration>
          </plugin>
          <plugin>
            <groupId>org.scala-tools</groupId>
            <artifactId>maven-scala-plugin</artifactId>
            <configuration>
              <excludes />
            </configuration>
          </plugin>
          <plugin>
            <artifactId>maven-surefire-plugin</artifactId>
            <configuration>
              <excludes>
                <exclude>${pyspark.test.exclude}</exclude>
              </excludes>
            </configuration>
          </plugin>
        </plugins>
      </build>
    </profile>
  </profiles>
  <dependencies>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-repl_2.10</artifactId>
      <version>2.1.0</version>
      <scope>provided</scope>
      <exclusions>
        <exclusion>
          <artifactId>spark-core_2.10</artifactId>
          <groupId>org.apache.spark</groupId>
        </exclusion>
        <exclusion>
          <artifactId>spark-mllib_2.10</artifactId>
          <groupId>org.apache.spark</groupId>
        </exclusion>
        <exclusion>
          <artifactId>spark-sql_2.10</artifactId>
          <groupId>org.apache.spark</groupId>
        </exclusion>
        <exclusion>
          <artifactId>jline</artifactId>
          <groupId>org.scala-lang</groupId>
        </exclusion>
        <exclusion>
          <artifactId>jul-to-slf4j</artifactId>
          <groupId>org.slf4j</groupId>
        </exclusion>
        <exclusion>
          <artifactId>spark-tags_2.10</artifactId>
          <groupId>org.apache.spark</groupId>
        </exclusion>
        <exclusion>
          <artifactId>xbean-asm5-shaded</artifactId>
          <groupId>org.apache.xbean</groupId>
        </exclusion>
        <exclusion>
          <artifactId>unused</artifactId>
          <groupId>org.spark-project.spark</groupId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-hive_2.10</artifactId>
      <version>2.1.0</version>
      <scope>provided</scope>
      <exclusions>
        <exclusion>
          <artifactId>parquet-hadoop-bundle</artifactId>
          <groupId>com.twitter</groupId>
        </exclusion>
        <exclusion>
          <artifactId>hive-exec</artifactId>
          <groupId>org.spark-project.hive</groupId>
        </exclusion>
        <exclusion>
          <artifactId>hive-metastore</artifactId>
          <groupId>org.spark-project.hive</groupId>
        </exclusion>
        <exclusion>
          <artifactId>avro</artifactId>
          <groupId>org.apache.avro</groupId>
        </exclusion>
        <exclusion>
          <artifactId>avro-mapred</artifactId>
          <groupId>org.apache.avro</groupId>
        </exclusion>
        <exclusion>
          <artifactId>calcite-avatica</artifactId>
          <groupId>org.apache.calcite</groupId>
        </exclusion>
        <exclusion>
          <artifactId>calcite-core</artifactId>
          <groupId>org.apache.calcite</groupId>
        </exclusion>
        <exclusion>
          <artifactId>jackson-mapper-asl</artifactId>
          <groupId>org.codehaus.jackson</groupId>
        </exclusion>
        <exclusion>
          <artifactId>joda-time</artifactId>
          <groupId>joda-time</groupId>
        </exclusion>
        <exclusion>
          <artifactId>jodd-core</artifactId>
          <groupId>org.jodd</groupId>
        </exclusion>
        <exclusion>
          <artifactId>jsr305</artifactId>
          <groupId>com.google.code.findbugs</groupId>
        </exclusion>
        <exclusion>
          <artifactId>libfb303</artifactId>
          <groupId>org.apache.thrift</groupId>
        </exclusion>
        <exclusion>
          <artifactId>spark-core_2.10</artifactId>
          <groupId>org.apache.spark</groupId>
        </exclusion>
        <exclusion>
          <artifactId>spark-sql_2.10</artifactId>
          <groupId>org.apache.spark</groupId>
        </exclusion>
        <exclusion>
          <artifactId>spark-tags_2.10</artifactId>
          <groupId>org.apache.spark</groupId>
        </exclusion>
        <exclusion>
          <artifactId>unused</artifactId>
          <groupId>org.spark-project.spark</groupId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.scala-lang</groupId>
      <artifactId>scala-library</artifactId>
      <version>2.11.8</version>
      <scope>provided</scope>
    </dependency>
    <dependency>
      <groupId>org.scala-lang</groupId>
      <artifactId>scala-compiler</artifactId>
      <version>2.11.8</version>
      <scope>provided</scope>
      <exclusions>
        <exclusion>
          <artifactId>scala-xml_2.11</artifactId>
          <groupId>org.scala-lang.modules</groupId>
        </exclusion>
        <exclusion>
          <artifactId>scala-parser-combinators_2.11</artifactId>
          <groupId>org.scala-lang.modules</groupId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.scala-lang</groupId>
      <artifactId>scala-reflect</artifactId>
      <version>2.11.8</version>
      <scope>provided</scope>
    </dependency>
    <dependency>
      <groupId>commons-lang</groupId>
      <artifactId>commons-lang</artifactId>
      <version>2.5</version>
      <scope>provided</scope>
    </dependency>
    <dependency>
      <groupId>org.apache.commons</groupId>
      <artifactId>commons-compress</artifactId>
      <version>1.9</version>
      <scope>provided</scope>
    </dependency>
    <dependency>
      <groupId>org.scalatest</groupId>
      <artifactId>scalatest_2.10</artifactId>
      <version>2.2.4</version>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>junit</groupId>
      <artifactId>junit</artifactId>
      <version>4.12</version>
      <scope>test</scope>
      <exclusions>
        <exclusion>
          <artifactId>hamcrest-core</artifactId>
          <groupId>org.hamcrest</groupId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.datanucleus</groupId>
      <artifactId>datanucleus-core</artifactId>
      <version>3.2.10</version>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.datanucleus</groupId>
      <artifactId>datanucleus-api-jdo</artifactId>
      <version>3.2.6</version>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.datanucleus</groupId>
      <artifactId>datanucleus-rdbms</artifactId>
      <version>3.2.9</version>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.mockito</groupId>
      <artifactId>mockito-core</artifactId>
      <version>1.10.19</version>
      <scope>test</scope>
      <exclusions>
        <exclusion>
          <artifactId>objenesis</artifactId>
          <groupId>org.objenesis</groupId>
        </exclusion>
        <exclusion>
          <artifactId>hamcrest-core</artifactId>
          <groupId>org.hamcrest</groupId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.powermock</groupId>
      <artifactId>powermock-api-mockito</artifactId>
      <version>1.6.4</version>
      <scope>test</scope>
      <exclusions>
        <exclusion>
          <artifactId>powermock-api-support</artifactId>
          <groupId>org.powermock</groupId>
        </exclusion>
        <exclusion>
          <artifactId>hamcrest-core</artifactId>
          <groupId>org.hamcrest</groupId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.powermock</groupId>
      <artifactId>powermock-module-junit4</artifactId>
      <version>1.6.4</version>
      <scope>test</scope>
      <exclusions>
        <exclusion>
          <artifactId>powermock-module-junit4-common</artifactId>
          <groupId>org.powermock</groupId>
        </exclusion>
      </exclusions>
    </dependency>
  </dependencies>
  <properties>
    <pyspark.test.include>**/*Test.*</pyspark.test.include>
    <commons.exec.version>1.3</commons.exec.version>
    <wagon.version>1.0</wagon.version>
    <aether.version>1.12</aether.version>
    <datanucleus.rdbms.version>3.2.9</datanucleus.rdbms.version>
    <guava.version>14.0.1</guava.version>
    <plugin.shade.version>2.3</plugin.shade.version>
    <maven.aeither.provider.version>3.0.3</maven.aeither.provider.version>
    <jsoup.version>1.8.2</jsoup.version>
    <datanucleus.core.version>3.2.10</datanucleus.core.version>
    <datanucleus.apijdo.version>3.2.6</datanucleus.apijdo.version>
    <plugin.scala.version>2.15.2</plugin.scala.version>
    <pyspark.test.exclude>**/PySparkInterpreterMatplotlibTest.java</pyspark.test.exclude>
    <maven.plugin.api.version>3.0</maven.plugin.api.version>
    <commons.compress.version>1.9</commons.compress.version>
    <spark.version>2.0.2</spark.version>
  </properties>
</project>

